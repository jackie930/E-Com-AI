{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PaddlePaddle BYOS\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "This notebook shows how to use the SageMaker Python SDK to run your code in a local container before deploying to SageMaker's managed training or hosting environments.  This can speed up iterative testing and debugging while using the same familiar Python SDK interface.  Just change your estimator's `train_instance_type` to `local` (or `local_gpu` if you're using an ml.p2 or ml.p3 notebook instance).\n",
    "\n",
    "In order to use this feature you'll need to install docker-compose (and nvidia-docker if training with a GPU).\n",
    "\n",
    "**Note, you can only run a single local notebook at one time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/bin/bash ./utils/setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting paddlepaddle\n",
      "  Downloading paddlepaddle-2.3.2-cp38-cp38-manylinux1_x86_64.whl (112.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/112.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting paddlenlp\n",
      "  Downloading paddlenlp-2.4.1-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting opt-einsum==3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlepaddle) (5.1.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlepaddle) (1.16.0)\n",
      "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlepaddle) (3.19.4)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlepaddle) (9.0.1)\n",
      "Requirement already satisfied: numpy>=1.13 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlepaddle) (1.21.2)\n",
      "Collecting paddle-bfloat==0.1.7\n",
      "  Downloading paddle_bfloat-0.1.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.5/385.5 KB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlepaddle) (2.26.0)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting paddlefsl\n",
      "  Downloading paddlefsl-1.1.0-py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.0/101.0 KB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlenlp) (0.4.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlenlp) (4.62.3)\n",
      "Requirement already satisfied: dill<0.3.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlenlp) (0.3.4)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting paddle2onnx\n",
      "  Downloading paddle2onnx-1.0.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting visualdl\n",
      "  Downloading visualdl-2.4.1-py3-none-any.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multiprocess<=0.70.12.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlenlp) (0.70.12.2)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting datasets>=2.0.0\n",
      "  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.9/441.9 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (7.0.0)\n",
      "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 KB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (21.3)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (3.8.1)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (5.4.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (2021.11.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (1.3.4)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 KB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (3.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from seqeval->paddlenlp) (1.0.1)\n",
      "Collecting bce-python-sdk\n",
      "  Downloading bce_python_sdk-0.8.74-py3-none-any.whl (204 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.6/204.6 KB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flask>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from visualdl->paddlenlp) (2.0.2)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from visualdl->paddlenlp) (3.5.0)\n",
      "Collecting Flask-Babel>=1.0.0\n",
      "  Downloading Flask_Babel-2.0.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (2.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (3.0.3)\n",
      "Requirement already satisfied: click>=7.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (8.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied: Babel>=2.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.9.1)\n",
      "Requirement already satisfied: pytz in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2021.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets>=2.0.0->paddlenlp) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets>=2.0.0->paddlenlp) (4.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from packaging->datasets>=2.0.0->paddlenlp) (3.0.6)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.7.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (3.0.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.7.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (5.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (21.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (4.0.1)\n",
      "Requirement already satisfied: future>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.2)\n",
      "Collecting pycryptodome>=3.8.0\n",
      "  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->visualdl->paddlenlp) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->visualdl->paddlenlp) (4.28.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->visualdl->paddlenlp) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->visualdl->paddlenlp) (1.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from Jinja2>=3.0->flask>=1.1.1->visualdl->paddlenlp) (2.0.1)\n",
      "Building wheels for collected packages: jieba, seqeval\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314476 sha256=205d343feb7f9d568167819df505448ea7eeceefa590ecc2862c3d18e171ea58\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/ca/38/d8/dfdfe73bec1d12026b30cb7ce8da650f3f0ea2cf155ea018ae\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=f350a04f9a3ed11ccedd8699f872b736e93f5a88b6520759e69af6bf5fe4c46f\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "Successfully built jieba seqeval\n",
      "Installing collected packages: sentencepiece, paddle2onnx, paddle-bfloat, jieba, xxhash, pycryptodome, opt-einsum, colorlog, astor, responses, paddlepaddle, paddlefsl, huggingface-hub, bce-python-sdk, seqeval, Flask-Babel, visualdl, datasets, paddlenlp\n",
      "Successfully installed Flask-Babel-2.0.0 astor-0.8.1 bce-python-sdk-0.8.74 colorlog-6.7.0 datasets-2.6.1 huggingface-hub-0.10.1 jieba-0.42.1 opt-einsum-3.3.0 paddle-bfloat-0.1.7 paddle2onnx-1.0.1 paddlefsl-1.1.0 paddlenlp-2.4.1 paddlepaddle-2.3.2 pycryptodome-3.15.0 responses-0.18.0 sentencepiece-0.1.97 seqeval-1.2.2 visualdl-2.4.1 xxhash-3.1.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install paddlepaddle paddlenlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The **SageMaker Python SDK** helps you deploy your models for training and hosting in optimized, productions ready containers in SageMaker. The SageMaker Python SDK is easy to use, modular, extensible and compatible with TensorFlow, MXNet, PyTorch and Chainer. This tutorial focuses on how to create a convolutional neural network model to train the [Cifar10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) using **PyTorch in local mode**.\n",
    "\n",
    "### Set up the environment\n",
    "\n",
    "This notebook was created and tested on a single ml.p2.xlarge notebook instance.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the sagemaker.get_execution_role() with appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/shulex-jackie'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鞋-标注.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls ./shulex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first upload the labeled data to local path ./shulex\n",
    "!python prepare_shulex.py \\\n",
    "    --input_path './shulex/鞋-标注.jsonl' \\\n",
    "    --output_folder './output_shulex'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-10-25 05:46:19,809] [    INFO]\u001b[0m - Converting doccano data...\u001b[0m\n",
      "100%|████████████████████████████████████████| 18/18 [00:00<00:00, 31068.92it/s]\n",
      "\u001b[32m[2022-10-25 05:46:19,812] [    INFO]\u001b[0m - Adding negative samples for first stage prompt...\u001b[0m\n",
      "100%|███████████████████████████████████████| 18/18 [00:00<00:00, 142179.80it/s]\n",
      "\u001b[32m[2022-10-25 05:46:19,812] [    INFO]\u001b[0m - Converting doccano data...\u001b[0m\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 17886.16it/s]\n",
      "\u001b[32m[2022-10-25 05:46:19,813] [    INFO]\u001b[0m - Adding negative samples for first stage prompt...\u001b[0m\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 43018.50it/s]\n",
      "\u001b[32m[2022-10-25 05:46:19,813] [    INFO]\u001b[0m - Converting doccano data...\u001b[0m\n",
      "0it [00:00, ?it/s]\n",
      "\u001b[32m[2022-10-25 05:46:19,814] [    INFO]\u001b[0m - Adding negative samples for first stage prompt...\u001b[0m\n",
      "0it [00:00, ?it/s]\n",
      "\u001b[32m[2022-10-25 05:46:19,815] [    INFO]\u001b[0m - Save 90 examples to ./data_shulex/train.txt.\u001b[0m\n",
      "\u001b[32m[2022-10-25 05:46:19,816] [    INFO]\u001b[0m - Save 10 examples to ./data_shulex/dev.txt.\u001b[0m\n",
      "\u001b[32m[2022-10-25 05:46:19,816] [    INFO]\u001b[0m - Save 0 examples to ./data_shulex/test.txt.\u001b[0m\n",
      "\u001b[32m[2022-10-25 05:46:19,816] [    INFO]\u001b[0m - Finished! It takes 0.01 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python doccano.py \\\n",
    "    --folder_path ./output_shulex \\\n",
    "    --task_type ext \\\n",
    "    --save_dir ./data_shulex \\\n",
    "    --splits 0.9 0.1 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = sagemaker.Session().upload_data(path = \"./data_shulex\", key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-726335585155/sagemaker/shulex-jackie'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Functions\n",
    "\n",
    "SageMaker invokes the main function defined within your training script for training. When deploying your trained model to an endpoint, the model_fn() is called to determine how to load your trained model. The model_fn() along with a few other functions list below are called to enable predictions on SageMaker.\n",
    "\n",
    "### [Predicting Functions](https://github.com/aws/sagemaker-pytorch-containers/blob/master/src/sagemaker_pytorch_container/serving.py)\n",
    "* model_fn(model_dir) - loads your model.\n",
    "* input_fn(serialized_input_data, content_type) - deserializes predictions to predict_fn.\n",
    "* output_fn(prediction_output, accept) - serializes predictions from predict_fn.\n",
    "* predict_fn(input_data, model) - calls a model on data deserialized in input_fn.\n",
    "\n",
    "The model_fn() is the only function that doesn't have a default implementation and is required by the user for using PyTorch on SageMaker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training job using the sagemaker.PyTorch estimator\n",
    "\n",
    "The `PyTorch` class allows us to run our training function on SageMaker. We need to configure it with our training script, an IAM role, the number of training instances, and the training instance type. For local training with GPU, we could set this to \"local_gpu\".  In this case, `instance_type` was set above based on your whether you're running a GPU instance.\n",
    "\n",
    "After we've constructed our `PyTorch` object, we fit it using the data we uploaded to S3. Even though we're in local mode, using S3 as our data source makes sense because it maintains consistency with how SageMaker's distributed, managed training ingests data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training using GPU instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': 's3://sagemaker-us-east-1-726335585155/sagemaker/shulex-jackie'}\n"
     ]
    }
   ],
   "source": [
    "inputs = {'training': data_location}\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-10-25 05:47:39,444] [    INFO]\u001b[0m - Downloading model_state.pdparams from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base_en_v1.1/model_state.pdparams\u001b[0m\n",
      "100%|██████████| 418M/418M [00:58<00:00, 7.52MB/s]    \n",
      "\u001b[32m[2022-10-25 05:48:40,673] [    INFO]\u001b[0m - Downloading model_config.json from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base_en/model_config.json\u001b[0m\n",
      "100%|██████████| 347/347 [00:00<00:00, 325kB/s]\n",
      "\u001b[32m[2022-10-25 05:48:41,793] [    INFO]\u001b[0m - Downloading vocab.txt from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base_en/vocab.txt\u001b[0m\n",
      "100%|██████████| 226k/226k [00:03<00:00, 58.3kB/s] \n",
      "\u001b[32m[2022-10-25 05:48:47,217] [    INFO]\u001b[0m - Downloading special_tokens_map.json from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base_en/special_tokens_map.json\u001b[0m\n",
      "100%|██████████| 112/112 [00:00<00:00, 98.8kB/s]\n",
      "\u001b[32m[2022-10-25 05:48:48,402] [    INFO]\u001b[0m - Downloading tokenizer_config.json from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base_en/tokenizer_config.json\u001b[0m\n",
      "100%|██████████| 172/172 [00:00<00:00, 154kB/s]\n",
      "\u001b[32m[2022-10-25 05:48:57,726] [    INFO]\u001b[0m - Converting to the inference model cost a little time.\u001b[0m\n",
      "\u001b[32m[2022-10-25 05:49:09,327] [    INFO]\u001b[0m - The inference model save in the path:../uie-base-en/taskflow/information_extraction/uie-base-en/static/inference\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_add with relu activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_add with tanh activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_add with leaky_relu activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_add with swish activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_add with hardswish activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_add with sqrt activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_add with abs activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_add with clip activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_add with gelu activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_add with relu6 activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_add with sigmoid activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_sub with relu activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_sub with tanh activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_sub with leaky_relu activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_sub with swish activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_sub with hardswish activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_sub with sqrt activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_sub with abs activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_sub with clip activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_sub with gelu activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_sub with relu6 activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_sub with sigmoid activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_mul with relu activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_mul with tanh activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_mul with leaky_relu activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_mul with swish activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_mul with hardswish activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_mul with sqrt activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_mul with abs activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_mul with clip activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_mul with gelu activation\u001b[0m\n",
      "\u001b[37m---    fused 0 elementwise_mul with relu6 activation\u001b[0m\n",
      "\u001b[37m---   \u001b[32m[2022-10-25 05:49:10,581] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load '../uie-base-en/taskflow/information_extraction/uie-base-en'.\u001b[0m\n",
      " fused 0 elementwise_mul with sigmoid activation\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# prepare pretrained model, it will downlaod pretrained en-model from model repo, approximately 1-3 minutes\n",
    "from paddlenlp import Taskflow\n",
    "\n",
    "schema = ['asin',\n",
    "              'design for Device',\n",
    "              'Hub/Dock',\n",
    "              'Number of Ports',  # 接口数\n",
    "              'usb transfer speed',  # USB接口传输速度\n",
    "              'SD transfer speed',  # SD卡传输速度\n",
    "              'contain HDMI hub',  # 含有HDMI接口\n",
    "              'contain VGA hub',  # 含有VGA接口\n",
    "              ]  # Define the schema for entity extraction\n",
    "ie = Taskflow(\"information_extraction\", model='uie-base-en', schema=schema, home_path='../uie-base-en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uie_en_model path: s3://sagemaker-us-east-1-726335585155/model_uie_base_en\n"
     ]
    }
   ],
   "source": [
    "#upload uie-base-en pretrain\n",
    "\n",
    "uie_en_model_s3 = sagemaker.Session().upload_data(path = \"../uie-base-en/taskflow/information_extraction/uie-base-en\", key_prefix=\"model_uie_base_en\")\n",
    "#uie_en_model_s3 = 's3://sagemaker-us-west-2-064542430558/model_uie_base_en'\n",
    "print (\"uie_en_model path:\", uie_en_model_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-25 06:09:42 Starting - Starting the training job...ProfilerReport-1666678182: InProgress\n",
      "...\n",
      "2022-10-25 06:10:30 Starting - Preparing the instances for training.........\n",
      "2022-10-25 06:12:10 Downloading - Downloading input data......\n",
      "2022-10-25 06:13:11 Training - Downloading the training image............"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "hyperparameters = {'train_path': '/opt/ml/input/data/training/train.txt', \n",
    "                   'dev_path': '/opt/ml/input/data/training/dev.txt', \n",
    "                   'save_dir': '/opt/ml/model', \n",
    "                   'learning_rate': 1e-5, \n",
    "                   'batch_size': 16, \n",
    "                   'max_seq_len':512, \n",
    "                   'num_epochs': 50, \n",
    "                   'model': 'uie-base',\n",
    "                   'seed': 1000,\n",
    "                   'logging_steps': 10,\n",
    "                   'valid_steps': 50, # note this step should not larger than total\n",
    "                   'device': 'gpu',\n",
    "                   'freeze':True}\n",
    "\n",
    "instance_type = 'ml.p3.2xlarge'  # 'ml.p3.2xlarge' or 'ml.p3.8xlarge' or ...\n",
    "\n",
    "#git_config = {'repo': 'https://github.com/whn09/paddlenlp_sagemaker.git', 'branch': 'main'}\n",
    "\n",
    "estimator = PyTorch(entry_point='finetune.py',\n",
    "                    source_dir='./',\n",
    "                           # git_config=git_config,\n",
    "                    role=role,\n",
    "                    hyperparameters=hyperparameters,\n",
    "                    framework_version='1.9.1',\n",
    "                    py_version='py38',\n",
    "                    script_mode=True,\n",
    "                    instance_count=1,  # 1 or 2 or ...\n",
    "                    instance_type=instance_type,\n",
    "                    # Parameters required to enable checkpointing\n",
    "                    checkpoint_s3_uri=uie_en_model_s3, #使用你自己用来保存/加载模型的s3桶地址, 注意桶需要在us-east-1\n",
    "                    checkpoint_local_path=\"/opt/ml/checkpoints\")\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-training-2022-10-25-06-09-41-771\n"
     ]
    }
   ],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "# training_job_name = 'xxx'\n",
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-726335585155/pytorch-training-2022-10-25-06-09-41-771/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_data = estimator.model_data\n",
    "print (model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the trained model to prepare for predictions\n",
    "\n",
    "The deploy() method creates an endpoint (in this case locally) which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-726335585155/pytorch-training-2022-10-25-06-09-41-771/output/model.tar.gz to ../../../../../../../tmp/model.tar.gz\n",
      "inference.pdmodel\n",
      "model_best/\n",
      "model_best/model_config.json\n",
      "model_best/special_tokens_map.json\n",
      "model_best/tokenizer_config.json\n",
      "model_best/model_state.pdparams\n",
      "model_best/vocab.txt\n",
      "inference.pdiparams\n",
      "inference.pdiparams.info\n"
     ]
    }
   ],
   "source": [
    "#!mkdir /tmp\n",
    "!aws s3 cp $model_data /tmp/\n",
    "!tar -zxvf /tmp/model.tar.gz -C /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\n",
      "code/requirements.txt\n",
      "code/infer_gpu_shulex.py\n",
      "code/infer.py\n",
      "code/uie_predictor.py\n",
      "code/infer_cpu.py\n",
      "code/model.py\n",
      "code/requirements_cpu.txt\n",
      "code/requirements_gpu.txt\n",
      "code/infer_gpu.py\n",
      "inference.pdiparams\n",
      "inference.pdiparams.info\n",
      "inference.pdmodel\n",
      "model_config.json\n",
      "model_state.pdparams\n"
     ]
    }
   ],
   "source": [
    "!cp /tmp/inference.* model/\n",
    "!cp /tmp/model_best/* model/\n",
    "!cp model/code/requirements_gpu.txt model/code/requirements.txt\n",
    "!cd model && tar -czvf ../model-inference-gpu.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp model-inference-gpu.tar.gz s3://$bucket/output/model-inference-gpu.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "instance_type = 'ml.g4dn.xlarge'\n",
    "\n",
    "# predictor = estimator.deploy(initial_instance_count=1, instance_type=instance_type)\n",
    "\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data='s3://{}/output/model-inference-gpu.tar.gz'.format(bucket), role=role,\n",
    "                             entry_point='infer_gpu_shulex.py', framework_version='1.9.0', py_version='py38', model_server_workers=4)  # TODO [For GPU], model_server_workers=6\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type=instance_type, initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoking the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:  [{'Shoe Type': [{'text': 'Retro knee-high boot', 'start': 210, 'end': 230, 'probability': 0.9831036329269409}], 'Shoe Heel Height': [{'text': 'approximately 13\"', 'start': 182, 'end': 199, 'probability': 0.44407209753990173}], 'Shoe Heel Type': [{'text': 'block heel', 'start': 256, 'end': 266, 'probability': 0.45025530457496643}], 'Shoe Toe Style': [{'text': 'square toe', 'start': 241, 'end': 251, 'probability': 0.9709370732307434}]}]\n",
      "time: 0.22002243995666504\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Funtasma by Pleaser Women's Gogo-300 Boot\\n100% Synthetic  \\n Manmade sole  \\n Shaft measures approximately 16 1/2\\\" from arch  \\n Heel measures approximately 3\\\"  \\n Boot opening measures approximately 13\\\" around  \\n Retro knee-high boot featuring square toe and block heel\"]\n",
    "import time\n",
    "start = time.time()\n",
    "outputs = predictor.predict(texts)\n",
    "end = time.time()\n",
    "print('outputs: ', outputs)\n",
    "print('time:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [{\"id\": 40097, \"start_offset\": 28, \"end_offset\": 41, \"label\": \"Shoe Type\"}, {\"id\": 40098, \"start_offset\": 60, \"end_offset\": 74, \"label\": \"Shoe Pattern\"}, {\"id\": 40099, \"start_offset\": 126, \"end_offset\": 158, \"label\": \"Shoe Heel Height\"}, {\"id\": 40100, \"start_offset\": 210, \"end_offset\": 230, \"label\": \"Shoe Type\"}, {\"id\": 40101, \"start_offset\": 231, \"end_offset\": 251, \"label\": \"Shoe Toe Style\"}, {\"id\": 40102, \"start_offset\": 256, \"end_offset\": 266, \"label\": \"Shoe Heel Type\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = ['Shoe Type',\n",
    "     'Shoe Heel Height',\n",
    "     'Shoe Pattern',\n",
    "     'Shoe Heel Type',\n",
    "     'Shoe Toe Style']\n",
    "\n",
    "true = []\n",
    "for i in ls:\n",
    "    for j in label:\n",
    "        if j['label']==i:\n",
    "            true.append({'type':i,'text':texts[0][int(j['start_offset']):int(j['end_offset'])],'start':j['start_offset'],'end':j['end_offset']})\n",
    "            #true.append({'start':j['start_offset'],'end':j['end_offset']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'Shoe Type', 'text': 'Gogo-300 Boot', 'start': 28, 'end': 41},\n",
       " {'type': 'Shoe Type',\n",
       "  'text': 'Retro knee-high boot',\n",
       "  'start': 210,\n",
       "  'end': 230},\n",
       " {'type': 'Shoe Heel Height',\n",
       "  'text': 'Heel measures approximately 3\"  ',\n",
       "  'start': 126,\n",
       "  'end': 158},\n",
       " {'type': 'Shoe Pattern', 'text': 'Manmade sole  ', 'start': 60, 'end': 74},\n",
       " {'type': 'Shoe Heel Type', 'text': 'block heel', 'start': 256, 'end': 266},\n",
       " {'type': 'Shoe Toe Style',\n",
       "  'text': 'featuring square toe',\n",
       "  'start': 231,\n",
       "  'end': 251}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare \n",
    "\n",
    "predict = []\n",
    "for i in ls:\n",
    "    try:\n",
    "        predict.append(outputs[0][i]) \n",
    "    except:\n",
    "        predict.append(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'text': 'Retro knee-high boot',\n",
       "   'start': 210,\n",
       "   'end': 230,\n",
       "   'probability': 0.9831036329269409}],\n",
       " [{'text': 'approximately 13\"',\n",
       "   'start': 182,\n",
       "   'end': 199,\n",
       "   'probability': 0.44407209753990173}],\n",
       " '',\n",
       " [{'text': 'block heel',\n",
       "   'start': 256,\n",
       "   'end': 266,\n",
       "   'probability': 0.45025530457496643}],\n",
       " [{'text': 'square toe',\n",
       "   'start': 241,\n",
       "   'end': 251,\n",
       "   'probability': 0.9709370732307434}]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean-up\n",
    "\n",
    "Deleting the local endpoint when you're finished is important since you can only run one local endpoint at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.delete_endpoint()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"I wipe whatever tears had trickled down my face, removing my rings from my fingers and clutching them in my hands.\\nThe hallway seems longer than normal but I walk briskly to the office where I find Christian, the elders, the lawyer, Jordan, Derek and Vanessa waiting for me.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

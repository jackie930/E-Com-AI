{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59532974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b606ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: openpyxl in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from openpyxl) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd3f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  train_sample.zip\n",
      "replace train_sample/Women-Sweatshirts/046dc32dca450b69c3fc0777039b9c42.html.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!unzip train_sample.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data\n",
    "#!mkdir data_0731\n",
    "#!aws s3 cp s3://jackie-test/bumingjueli/data0731/ ./data_0731/ --recursive\n",
    "#!unzip ./data_0731/Sports.zip -d ./data_0731"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b1e0b",
   "metadata": {},
   "source": [
    "# data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e27da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter not 13 list\n",
    "def get_feature_len(x):\n",
    "    t = json.loads(x)\n",
    "    return len(t)\n",
    "\n",
    "def get_key_list(x):\n",
    "    # get key dictionary\n",
    "    t = json.loads(x)\n",
    "    res = [i for i in list(t.values())]\n",
    "    res = [list(i.keys())[0] for i in res]\n",
    "    return res\n",
    "\n",
    "def get_keys(df):\n",
    "    lst = list(df['feature_dict'])\n",
    "    myList = [x for j in lst for x in j]\n",
    "    res = list(set(myList))\n",
    "    #res_str = ','.join(res)\n",
    "    return res\n",
    "    \n",
    "def map_feature(x,leng):\n",
    "    t = json.loads(x)\n",
    "    for i in range(leng):\n",
    "        if str(i) in t.keys():\n",
    "            continue\n",
    "        else:\n",
    "            t[str(i)] = ''\n",
    "    return t\n",
    "\n",
    "def get_res(x):\n",
    "    try:\n",
    "        a = ast.literal_eval(str(x))\n",
    "        return a\n",
    "    except:\n",
    "        return {'res':'others'}\n",
    "        \n",
    "#map back labels\n",
    "def get_label_txt():\n",
    "    with open('./data/label.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    keys =  [i.split('\\t')[0] for i in lines]\n",
    "    keys_update = [str(int(i)-1) for i in keys]\n",
    "    res = [i.split('\\t')[1][:-1] for i in lines ]\n",
    "    dict_res = dict(zip(keys_update, res))\n",
    "    return dict_res\n",
    "\n",
    "def get_key_value(x,i):\n",
    "#x = df['data'][59335]\n",
    "\n",
    "    t = json.loads(x)\n",
    "\n",
    "    res = [i for i in list(t.values())]\n",
    "    keys = [list(i.keys())[0] for i in res]\n",
    "    values = [list(i.values())[0] for i in res]\n",
    "    dict_res = dict(zip(keys, values))\n",
    "    if i in dict_res.keys():\n",
    "        return dict_res[i]\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "\n",
    "def test_path(x,category):\n",
    "    root_path = os.path.join('/home/ec2-user/SageMaker/bumingjueli/img-cls/data/data_0731',category)\n",
    "    img_name = os.path.join(root_path,str(x)+'.png')\n",
    "    #print ('img_name',img_name)\n",
    "    if os.path.exists(img_name):  \n",
    "        # for local training\n",
    "        #return img_name\n",
    "        # for sagemaker only\n",
    "        img = Image.open(img_name)\n",
    "        if len(img.getbands())==3:\n",
    "            return os.path.join('/opt/ml/input/data/training',str(x)+'.png')\n",
    "        else:\n",
    "            return 'none'\n",
    "    else:\n",
    "        return 'none'\n",
    "\n",
    "def self_mkdir(folder):\n",
    "    isExists = os.path.exists(folder)\n",
    "    if not isExists:\n",
    "        os.makedirs(folder)\n",
    "        print('path of %s is build' % (folder))\n",
    "\n",
    "def copy_files(df,category,output_dir):\n",
    "    for i in df['md5_url']:\n",
    "        copyfile(os.path.join('./data_0731',category,i+'.png'),os.path.join(output_dir,i+'.png'))\n",
    "        \n",
    "        \n",
    "def get_data(path,category,output_dir):\n",
    "    df = pd.read_excel(path,engine=\"openpyxl\")\n",
    "    df = df[df['creg']==category]\n",
    "    #df['feature_len'] = df['data'].map(lambda x: get_feature_len(x))\n",
    "    #leng = max(df['feature_len'])\n",
    "    df['feature_dict'] = df['data'].map(lambda x: get_key_list(x))\n",
    "    res_keys = get_keys(df)\n",
    "    print (\"<<< predict for keys: \", ','.join(res_keys))\n",
    "    \n",
    "    for i in res_keys:\n",
    "        df[i] = df['data'].map(lambda x: get_key_value(x,i))\n",
    "    \n",
    "    #repath\n",
    "    df['image_path'] = df['md5_url'].map(lambda x: test_path(x,category))\n",
    "    df = df[df['image_path']!='none']\n",
    "    \n",
    "    #make dir if not exist\n",
    "    self_mkdir(output_dir)\n",
    "    #save data\n",
    "    df[res_keys].to_csv(os.path.join(output_dir, 'total.csv'),index=False)\n",
    "    \n",
    "    #sample\n",
    "    df = df.head(50)\n",
    "    #copy images\n",
    "    copy_files(df,category,output_dir)\n",
    "    \n",
    "    train, test = train_test_split(df,test_size=0.2,random_state=0)\n",
    "    train.to_csv(os.path.join(output_dir, 'train.csv'))\n",
    "    test.to_csv(os.path.join(output_dir, 'test.csv'))\n",
    "    print (\"train size {}, test size{}\".format(train.shape,test.shape))\n",
    "    \n",
    "    return df\n",
    "\n",
    "category = 'Women-Sweatshirts'\n",
    "output_dir = os.path.join(\"./train_sample\",category)\n",
    "#df = get_data('./data_0731/shein_info.xlsx',category=category,output_dir = output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c07aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./train_sample/Women-Sweatshirts'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a47de14",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81cd4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "sess = sage.Session()\n",
    "\n",
    "#WORK_DIRECTORY = output_dir\n",
    "\n",
    "# S3 prefix\n",
    "#prefix = \"bmjl-train-\"+category\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "#data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e69e5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"epoch\":1, # test 1\n",
    "    \"batch_size\":4,\n",
    "    \"num_workers\":8,  \n",
    "    'val_epoch':1,\n",
    "    'save_epoch':1,\n",
    "    'model_name':'resnet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c56eabb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point = 'train_general_sagemaker.py'\n",
    "source_dir = './code'\n",
    "git_config = None\n",
    "role = get_execution_role()\n",
    "framework_version = '1.7.1'\n",
    "py_version='py36'\n",
    "instance_type='ml.p3.2xlarge'\n",
    "#instance_type='local_gpu'\n",
    "instance_count=1\n",
    "volume_size=50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c87fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point = entry_point,\n",
    "    source_dir = source_dir,\n",
    "    git_config = git_config,\n",
    "    role = role,\n",
    "    debugger_hook_config=False,\n",
    "    hyperparameters = hyperparameters,\n",
    "    framework_version = framework_version, \n",
    "    py_version = py_version,\n",
    "    instance_type = instance_type,\n",
    "    instance_count = instance_count,\n",
    "    base_job_name = prefix+hyperparameters['model_name'],\n",
    "    volume_size=volume_size,\n",
    "    # Parameters required to enable checkpointing\n",
    "    checkpoint_s3_uri=\"s3://726335585155-sagemaker-us-east-1/bmjl_models\", #使用你自己用来保存/加载模型的s3桶地址, 注意桶需要在us-east-1\n",
    "    checkpoint_local_path=\"/opt/ml/checkpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69270c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-26 07:22:21 Starting - Starting the training job...\n",
      "2022-08-26 07:22:47 Starting - Preparing the instances for trainingProfilerReport-1661498541: InProgress\n",
      "............\n",
      "2022-08-26 07:24:45 Downloading - Downloading input data......\n",
      "2022-08-26 07:25:45 Training - Downloading the training image...............\n",
      "2022-08-26 07:28:21 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-08-26 07:28:24,515 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-08-26 07:28:24,539 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-08-26 07:28:24,548 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-08-26 07:28:24,940 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (3.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (8.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (4.51.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 4)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch->-r requirements.txt (line 5)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch->-r requirements.txt (line 5)) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (0.35.1)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (2.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.11.0-py2.py3-none-any.whl (167 kB)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (3.17.1)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 8)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (1.25.11)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.0.1\n",
      "    Uninstalling importlib-metadata-4.0.1:\n",
      "      Successfully uninstalled importlib-metadata-4.0.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed absl-py-1.2.0 cachetools-4.2.4 google-auth-2.11.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 importlib-metadata-4.8.3 markdown-3.3.7 oauthlib-3.2.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-08-26 07:28:31,804 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 4,\n",
      "        \"epoch\": 1,\n",
      "        \"model_name\": \"resnet\",\n",
      "        \"num_workers\": 8,\n",
      "        \"save_epoch\": 1,\n",
      "        \"val_epoch\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"bmjl-train-Women-Sweatshirtsresnet-2022-08-26-07-22-21-027\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-726335585155/bmjl-train-Women-Sweatshirtsresnet-2022-08-26-07-22-21-027/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_general_sagemaker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_general_sagemaker.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":4,\"epoch\":1,\"model_name\":\"resnet\",\"num_workers\":8,\"save_epoch\":1,\"val_epoch\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_general_sagemaker.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_general_sagemaker\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-726335585155/bmjl-train-Women-Sweatshirtsresnet-2022-08-26-07-22-21-027/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":4,\"epoch\":1,\"model_name\":\"resnet\",\"num_workers\":8,\"save_epoch\":1,\"val_epoch\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"bmjl-train-Women-Sweatshirtsresnet-2022-08-26-07-22-21-027\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-726335585155/bmjl-train-Women-Sweatshirtsresnet-2022-08-26-07-22-21-027/source/sourcedir.tar.gz\",\"module_name\":\"train_general_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_general_sagemaker.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"4\",\"--epoch\",\"1\",\"--model_name\",\"resnet\",\"--num_workers\",\"8\",\"--save_epoch\",\"1\",\"--val_epoch\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=4\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCH=1\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=resnet\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_WORKERS=8\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_EPOCH=1\u001b[0m\n",
      "\u001b[34mSM_HP_VAL_EPOCH=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_general_sagemaker.py --batch_size 4 --epoch 1 --model_name resnet --num_workers 8 --save_epoch 1 --val_epoch 1\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (3.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (8.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (4.51.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (2.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 4)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch->-r requirements.txt (line 5)) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch->-r requirements.txt (line 5)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.47.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (2.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (3.3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (0.35.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (0.4.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (3.17.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (2.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 8)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (4.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 8)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 8)) (4.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 8)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 8)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard in /opt/conda/lib/python3.6/site-packages (2.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.47.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.35.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (3.3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (3.17.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.4.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m<<< num workers:  8\u001b[0m\n",
      "\u001b[34m<<< train key list:  ['Size Fit', 'Fit Type', 'Details', 'Sleeve Length', 'Color', 'Quantity', 'Sheer', 'Lining', 'Fabric', 'Warm Lined', 'Composition', 'Body', 'Care Instructions', 'Pattern Type', 'Pockets', 'Length', 'Type', 'Hem Shaped', 'Material', 'Belt', 'Neckline', 'Sleeve Type', 'Arabian Clothing', 'Style']\u001b[0m\n",
      "\u001b[34m<<< self.key_ls:  ['Size Fit', 'Fit Type', 'Details', 'Sleeve Length', 'Color', 'Quantity', 'Sheer', 'Lining', 'Fabric', 'Warm Lined', 'Composition', 'Body', 'Care Instructions', 'Pattern Type', 'Pockets', 'Length', 'Type', 'Hem Shaped', 'Material', 'Belt', 'Neckline', 'Sleeve Type', 'Arabian Clothing', 'Style']\u001b[0m\n",
      "\u001b[34m<<< self.class_len_ls:  [2, 4, 47, 6, 55, 9, 4, 3, 4, 3, 96, 2, 5, 44, 3, 4, 5, 4, 21, 3, 21, 10, 2, 7]\u001b[0m\n",
      "\u001b[34mall checkpoints:  ['/opt/ml/checkpoints/checkpoint-000001.pth.sagemaker-uploaded', '/opt/ml/checkpoints/checkpoint-000001.pth']\u001b[0m\n",
      "\u001b[34m<<< training from last job!!!\u001b[0m\n",
      "\u001b[34mStarting training ...\u001b[0m\n",
      "\u001b[34mepoch    1, loss: 20.8615, n_train_samples:   10\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Size Fit is 1.0\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Fit Type is 0.7833333333333333\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Details is 0.3416666666666667\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Sleeve Length is 0.9\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Color is 0.1\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Quantity is 0.9\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Sheer is 0.95\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Lining is 0.95\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Fabric is 0.6166666666666666\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Warm Lined is 0.9\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Composition is 0.31666666666666665\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Body is 0.85\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Care Instructions is 0.5833333333333333\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Pattern Type is 0.3\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Pockets is 1.0\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Length is 0.4833333333333334\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Type is 0.5083333333333333\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Hem Shaped is 1.0\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Material is 0.65\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Belt is 0.95\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Neckline is 0.37499999999999994\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Sleeve Type is 0.5666666666666667\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Arabian Clothing is 1.0\u001b[0m\n",
      "\u001b[34mepoch    1, accuracy for Style is 0.95\u001b[0m\n",
      "\u001b[34m------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mValidation  loss: 601.9231 \u001b[0m\n",
      "\u001b[34maccuracy for Size Fit is 1.0 \u001b[0m\n",
      "\u001b[34maccuracy for Fit Type is 0.5 \u001b[0m\n",
      "\u001b[34maccuracy for Details is 0.16666666666666666 \u001b[0m\n",
      "\u001b[34maccuracy for Sleeve Length is 1.0 \u001b[0m\n",
      "\u001b[34maccuracy for Color is 0.08333333333333333 \u001b[0m\n",
      "\u001b[34maccuracy for Quantity is 0.8333333333333334 \u001b[0m\n",
      "\u001b[34maccuracy for Sheer is 1.0 \u001b[0m\n",
      "\u001b[34maccuracy for Lining is 1.0 \u001b[0m\n",
      "\u001b[34maccuracy for Fabric is 0.611111111111111 \u001b[0m\n",
      "\u001b[34maccuracy for Warm Lined is 0.6666666666666666 \u001b[0m\n",
      "\u001b[34maccuracy for Composition is 0.1111111111111111 \u001b[0m\n",
      "\u001b[34maccuracy for Body is 1.0 \u001b[0m\n",
      "\u001b[34maccuracy for Care Instructions is 0.8333333333333334 \u001b[0m\n",
      "\u001b[34maccuracy for Pattern Type is 0.19444444444444442 \u001b[0m\n",
      "\u001b[34maccuracy for Pockets is 1.0 \u001b[0m\n",
      "\u001b[34maccuracy for Length is 0.611111111111111 \u001b[0m\n",
      "\u001b[34maccuracy for Type is 0.0 \u001b[0m\n",
      "\u001b[34maccuracy for Hem Shaped is 1.0 \u001b[0m\n",
      "\u001b[34maccuracy for Material is 0.0 \u001b[0m\n",
      "\u001b[34maccuracy for Belt is 1.0 \u001b[0m\n",
      "\u001b[34maccuracy for Neckline is 0.4444444444444444 \u001b[0m\n",
      "\u001b[34maccuracy for Sleeve Type is 1.0 \u001b[0m\n",
      "\u001b[34maccuracy for Arabian Clothing is 1.0 \u001b[0m\n",
      "\u001b[34maccuracy for Style is 0.8333333333333334 \u001b[0m\n",
      "\u001b[34mSaved checkpoint: /opt/ml/checkpoints/checkpoint-000001.pth\u001b[0m\n",
      "\u001b[34mSaved checkpoint: /opt/ml/model/checkpoint-000001.pth\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/44.7M [00:00<?, ?B/s]#015 32%|███▏      | 14.5M/44.7M [00:00<00:00, 152MB/s]#015 69%|██████▊   | 30.6M/44.7M [00:00<00:00, 157MB/s]#015100%|██████████| 44.7M/44.7M [00:00<00:00, 164MB/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/10 [00:00<?, ?it/s]#015Epoch 1:   0%|          | 0/10 [00:01<?, ?it/s]#015Epoch 1:   0%|          | 0/10 [00:10<?, ?it/s, loss=17.3]#015Epoch 1:  10%|█         | 1/10 [00:10<01:36, 10.71s/it, loss=17.3]#015Epoch 1:  10%|█         | 1/10 [00:10<01:36, 10.71s/it, loss=17.3]#015Epoch 1:  10%|█         | 1/10 [00:11<01:36, 10.71s/it, loss=20.5]#015Epoch 1:  20%|██        | 2/10 [00:11<01:00,  7.62s/it, loss=20.5]#015Epoch 1:  20%|██        | 2/10 [00:11<01:00,  7.62s/it, loss=20.5]#015Epoch 1:  20%|██        | 2/10 [00:11<01:00,  7.62s/it, loss=18.5]#015Epoch 1:  30%|███       | 3/10 [00:11<00:38,  5.45s/it, loss=18.5]#015Epoch 1:  30%|███       | 3/10 [00:11<00:38,  5.45s/it, loss=18.5]#015Epoch 1:  30%|███       | 3/10 [00:11<00:38,  5.45s/it, loss=23.1]#015Epoch 1:  40%|████      | 4/10 [00:11<00:23,  3.92s/it, loss=23.1]#015Epoch 1:  40%|████      | 4/10 [00:11<00:23,  3.92s/it, loss=23.1]#015Epoch 1:  40%|████      | 4/10 [00:12<00:23,  3.92s/it, loss=23]  #015Epoch 1:  50%|█████     | 5/10 [00:12<00:14,  2.86s/it, loss=23]#015Epoch 1:  50%|█████     | 5/10 [00:12<00:14,  2.86s/it, loss=23]#015Epoch 1:  50%|█████     | 5/10 [00:12<00:14,  2.86s/it, loss=24.8]#015Epoch 1:  60%|██████    | 6/10 [00:12<00:08,  2.11s/it, loss=24.8]#015Epoch 1:  60%|██████    | 6/10 [00:12<00:08,  2.11s/it, loss=24.8]#015Epoch 1:  60%|██████    | 6/10 [00:12<00:08,  2.11s/it, loss=20.2]#015Epoch 1:  70%|███████   | 7/10 [00:12<00:04,  1.59s/it, loss=20.2]#015Epoch 1:  70%|███████   | 7/10 [00:12<00:04,  1.59s/it, loss=20.2]#015Epoch 1:  70%|███████   | 7/10 [00:13<00:04,  1.59s/it, loss=20.6]#015Epoch 1:  80%|████████  | 8/10 [00:13<00:02,  1.23s/it, loss=20.6]#015Epoch 1:  80%|████████  | 8/10 [00:13<00:02,  1.23s/it, loss=20.6]#015Epoch 1:  80%|████████  | 8/10 [00:13<00:02,  1.23s/it, loss=22]  #015Epoch 1:  90%|█████████ | 9/10 [00:13<00:00,  1.03it/s, loss=22]#015Epoch 1:  90%|█████████ | 9/10 [00:13<00:00,  1.03it/s, loss=22]#015Epoch 1:  90%|█████████ | 9/10 [00:14<00:00,  1.03it/s, loss=18.6]#015Epoch 1: 100%|██████████| 10/10 [00:14<00:00,  1.26it/s, loss=18.6]#015Epoch 1: 100%|██████████| 10/10 [00:14<00:00,  1.42s/it, loss=18.6]\u001b[0m\n",
      "\u001b[34m2022-08-26 07:29:00,494 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-08-26 07:29:26 Uploading - Uploading generated training model\n",
      "2022-08-26 07:29:26 Completed - Training job completed\n",
      "Training seconds: 297\n",
      "Billable seconds: 297\n"
     ]
    }
   ],
   "source": [
    "response = estimator.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bff912",
   "metadata": {},
   "source": [
    "# realtime endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbf14a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "#s3_model = estimator.model_data \n",
    "s3_model = \"s3://sagemaker-us-east-1-726335585155/bmjl-train-Women-Sweatshirtsresnet-2022-08-17-02-59-54-374/output/model.tar.gz\"\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data=s3_model, \n",
    "                             role=role,\n",
    "                             entry_point='inference.py', \n",
    "                             source_dir='./code', \n",
    "                             framework_version='1.7.1', \n",
    "                             py_version='py36'\n",
    "                ) # TODO set model_server_workers=1 to avoid torchhub bug\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type='ml.g4dn.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1edba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.5 ms, sys: 12.4 ms, total: 53 ms\n",
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from boto3.session import Session\n",
    "\n",
    "session = Session()\n",
    "runtime = session.client(\"runtime.sagemaker\")\n",
    "\n",
    "with open('train_sample/Women-Sweatshirts/000c08064f41455e5217ac37f1bea615.html.png', \"rb\") as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "    \n",
    "response = runtime.invoke_endpoint(\n",
    "    #EndpointName='pytorch-inference-2022-08-17-03-10-11-481', \n",
    "    EndpointName=predictor.endpoint_name, \n",
    "    ContentType=\"application/x-image\", \n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "result = response[\"Body\"].read()\n",
    "# result will be in json format and convert it to ndarray\n",
    "result = json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e521ff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': {'Size Fit': 'other',\n",
       "  'Fit Type': 'Regular Fit',\n",
       "  'Details': 'other',\n",
       "  'Sleeve Length': 'Long Sleeve',\n",
       "  'Color': 'Navy Blue',\n",
       "  'Quantity': '1 piece',\n",
       "  'Sheer': 'No',\n",
       "  'Lining': 'other',\n",
       "  'Fabric': 'Slight Stretch',\n",
       "  'Warm Lined': 'other',\n",
       "  'Composition': '100% Polyester',\n",
       "  'Body': 'other',\n",
       "  'Care Instructions': 'Machine wash or professional dry clean',\n",
       "  'Pattern Type': 'Letter',\n",
       "  'Pockets': 'other',\n",
       "  'Length': 'Regular',\n",
       "  'Type': 'Pullovers',\n",
       "  'Hem Shaped': 'other',\n",
       "  'Material': 'Polyester',\n",
       "  'Belt': 'other',\n",
       "  'Neckline': 'Hooded',\n",
       "  'Sleeve Type': 'Drop Shoulder',\n",
       "  'Arabian Clothing': 'other',\n",
       "  'Style': 'Casual'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e7d6b9",
   "metadata": {},
   "source": [
    "# servelss inference\n",
    "\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/main/serverless-inference/huggingface-serverless-inference/huggingface-text-classification-serverless-inference.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf4fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serverless.serverless_inference_config import ServerlessInferenceConfig\n",
    "\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=6144,\n",
    "    max_concurrency=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff4fdbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!CPU times: user 3.9 s, sys: 686 ms, total: 4.58 s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "#s3_model = estimator.model_data \n",
    "s3_model = \"s3://sagemaker-us-east-1-726335585155/bmjl-train-Women-Sweatshirtsresnet-2022-08-17-02-59-54-374/output/model.tar.gz\"\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data=s3_model, \n",
    "                             role=role,\n",
    "                             entry_point='inference.py', \n",
    "                             source_dir='./code', \n",
    "                             framework_version='1.7.1', \n",
    "                             py_version='py36'\n",
    "                ) # TODO set model_server_workers=1 to avoid torchhub bug\n",
    "\n",
    "predictor = pytorch_model.deploy(serverless_inference_config=serverless_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c82a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 136 ms, sys: 12.4 ms, total: 148 ms\n",
      "Wall time: 2.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from boto3.session import Session\n",
    "\n",
    "session = Session()\n",
    "runtime = session.client(\"runtime.sagemaker\")\n",
    "\n",
    "with open('train_sample/Women-Sweatshirts/000c08064f41455e5217ac37f1bea615.html.png', \"rb\") as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "    \n",
    "response = runtime.invoke_endpoint(\n",
    "    #EndpointName='pytorch-inference-2022-08-17-03-10-11-481', \n",
    "    EndpointName=predictor.endpoint_name, \n",
    "    ContentType=\"application/x-image\", \n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "result = response[\"Body\"].read()\n",
    "# result will be in json format and convert it to ndarray\n",
    "result = json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7903618c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': {'Size Fit': 'other',\n",
       "  'Fit Type': 'Regular Fit',\n",
       "  'Details': 'other',\n",
       "  'Sleeve Length': 'Long Sleeve',\n",
       "  'Color': 'Navy Blue',\n",
       "  'Quantity': '1 piece',\n",
       "  'Sheer': 'No',\n",
       "  'Lining': 'other',\n",
       "  'Fabric': 'Slight Stretch',\n",
       "  'Warm Lined': 'other',\n",
       "  'Composition': '100% Polyester',\n",
       "  'Body': 'other',\n",
       "  'Care Instructions': 'Machine wash or professional dry clean',\n",
       "  'Pattern Type': 'Letter',\n",
       "  'Pockets': 'other',\n",
       "  'Length': 'Regular',\n",
       "  'Type': 'Pullovers',\n",
       "  'Hem Shaped': 'other',\n",
       "  'Material': 'Polyester',\n",
       "  'Belt': 'other',\n",
       "  'Neckline': 'Hooded',\n",
       "  'Sleeve Type': 'Drop Shoulder',\n",
       "  'Arabian Clothing': 'other',\n",
       "  'Style': 'Casual'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd3326",
   "metadata": {},
   "source": [
    "# batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23d043f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input S3 path: s3://sagemaker-us-east-1-726335585155/batch_transform/test\n"
     ]
    }
   ],
   "source": [
    "image_dir = './test'\n",
    "inference_prefix = \"batch_transform/test\"\n",
    "inference_inputs = sess.upload_data(\n",
    "    path=image_dir, key_prefix=inference_prefix\n",
    ")\n",
    "print(\"Input S3 path: {}\".format(inference_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b576713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformer from PyTorchModel object\n",
    "transformer = pytorch_model.transformer(instance_count=1, instance_type=\"ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa60fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 1)) (3.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 2)) (1.19.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 1)) (3.3.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 2)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 3)) (8.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 4)) (0.21.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 5)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 6)) (0.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 7)) (4.62.3)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (0.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r /opt/ml/model/code/requirements.txt (line 4)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r /opt/ml/model/code/requirements.txt (line 4)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch->-r /opt/ml/model/code/requirements.txt (line 5)) (4.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch->-r /opt/ml/model/code/requirements.txt (line 5)) (0.8)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (2.22.0)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (0.37.0)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.10.0-py2.py3-none-any.whl (167 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (2021.5.30)\u001b[0m\n",
      "\u001b[34mCollecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (0.4.8)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 3)) (8.4.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 4)) (0.21.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 5)) (1.7.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 6)) (0.8.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 7)) (4.62.3)\u001b[0m\n",
      "\u001b[35mCollecting tensorboard\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (0.11.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.6)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (1.3.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (2.8.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r /opt/ml/model/code/requirements.txt (line 4)) (1.0.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r /opt/ml/model/code/requirements.txt (line 4)) (1.3.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch->-r /opt/ml/model/code/requirements.txt (line 5)) (4.0.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch->-r /opt/ml/model/code/requirements.txt (line 5)) (0.8)\u001b[0m\n",
      "\u001b[35mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (2.22.0)\u001b[0m\n",
      "\u001b[35mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001b[0m\n",
      "\u001b[35mCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35mCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (0.37.0)\u001b[0m\n",
      "\u001b[35mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[35mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.10.0-py2.py3-none-any.whl (167 kB)\u001b[0m\n",
      "\u001b[35mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (1.16.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (4.7.2)\u001b[0m\n",
      "\u001b[35mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35mCollecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (3.0.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (2.8)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (1.25.11)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (2021.5.30)\u001b[0m\n",
      "\u001b[35mCollecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r /opt/ml/model/code/requirements.txt (line 8)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: zipp, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35mInstalling collected packages: zipp, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34mSuccessfully installed absl-py-1.2.0 cachetools-4.2.4 google-auth-2.10.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 importlib-metadata-4.8.3 markdown-3.3.7 oauthlib-3.2.0 protobuf-3.19.4 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3 zipp-3.6.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:25,972 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.3.1\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 3014 M\u001b[0m\n",
      "\u001b[35mSuccessfully installed absl-py-1.2.0 cachetools-4.2.4 google-auth-2.10.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 importlib-metadata-4.8.3 markdown-3.3.7 oauthlib-3.2.0 protobuf-3.19.4 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3 zipp-3.6.0\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:25,972 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[35mTorchserve version: 0.3.1\u001b[0m\n",
      "\u001b[35mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[35mCurrent directory: /\u001b[0m\n",
      "\u001b[35mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[35mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[35mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[35mMax heap size: 3014 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:26,003 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[35mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[35mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[35mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[35mInitial Models: model.mar\u001b[0m\n",
      "\u001b[35mLog dir: /logs\u001b[0m\n",
      "\u001b[35mMetrics dir: /logs\u001b[0m\n",
      "\u001b[35mNetty threads: 0\u001b[0m\n",
      "\u001b[35mNetty client threads: 0\u001b[0m\n",
      "\u001b[35mDefault workers per model: 4\u001b[0m\n",
      "\u001b[35mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[35mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[35mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[35mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[35mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[35mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[35mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[35mEnable metrics API: true\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:26,003 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:26,791 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 8b3366f58d3a47739e77f2e1078056ed\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:26,802 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:26,833 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,010 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,011 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]55\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,012 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,014 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,014 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,016 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]56\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,016 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,017 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,029 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,031 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,031 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,032 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]58\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,033 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,033 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,033 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,061 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,062 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]57\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,062 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,062 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,063 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,086 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,086 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:26,791 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 8b3366f58d3a47739e77f2e1078056ed\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:26,802 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:26,833 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,010 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,011 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]55\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,012 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,014 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,014 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,016 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]56\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,016 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,017 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,029 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,031 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,031 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,032 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]58\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,033 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,033 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,033 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,061 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,062 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]57\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,062 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,062 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,063 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,086 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,086 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,095 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,095 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,098 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,098 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,101 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,104 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,326 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:55226 \"GET /ping HTTP/1.1\" 200 75\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,356 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,842 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,843 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.83776092529297|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,844 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.02737045288086|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,845 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.4|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,845 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14138.83203125|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,846 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1275.6015625|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,847 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:10.2|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,903 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:55236 \"GET /execution-parameters HTTP/1.1\" 404 12\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:27,904 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,098 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,098 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,101 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,104 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,326 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:55226 \"GET /ping HTTP/1.1\" 200 75\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,356 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[35mModel server started.\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,842 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,843 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.83776092529297|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,844 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.02737045288086|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,845 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.4|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,845 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14138.83203125|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,846 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1275.6015625|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,847 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:10.2|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707987\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,903 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:55236 \"GET /execution-parameters HTTP/1.1\" 404 12\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:27,904 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:28,950 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/checkpoint-000001.pth']\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:28,950 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:28,950 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/checkpoint-000001.pth']\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:28,950 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:28,951 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:28,977 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:28,978 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:28,978 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/checkpoint-000001.pth']\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,007 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/checkpoint-000001.pth']\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,007 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,008 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,068 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   0%|          | 0.00/44.7M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,078 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   0%|          | 0.00/44.7M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:28,951 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:28,977 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:28,978 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:28,978 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/checkpoint-000001.pth']\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,007 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/checkpoint-000001.pth']\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,007 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,008 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,068 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   0%|          | 0.00/44.7M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,078 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   0%|          | 0.00/44.7M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[32m2022-08-17T03:46:28.737:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,109 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   0%|          | 0.00/44.7M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,168 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  24%|██▎       | 10.5M/44.7M [00:00<00:00, 95.3MB/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,179 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  15%|█▍        | 6.65M/44.7M [00:00<00:00, 68.4MB/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,209 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   7%|▋         | 3.21M/44.7M [00:00<00:01, 33.6MB/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,238 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,238 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,238 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/checkpoint-000001.pth']\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,279 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  39%|███▉      | 17.6M/44.7M [00:00<00:00, 95.4MB/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,283 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  60%|█████▉    | 26.7M/44.7M [00:00<00:00, 136MB/s] \u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,109 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   0%|          | 0.00/44.7M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,168 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  24%|██▎       | 10.5M/44.7M [00:00<00:00, 95.3MB/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,179 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  15%|█▍        | 6.65M/44.7M [00:00<00:00, 68.4MB/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,209 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   7%|▋         | 3.21M/44.7M [00:00<00:01, 33.6MB/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,238 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,238 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,238 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/checkpoint-000001.pth']\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,279 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  39%|███▉      | 17.6M/44.7M [00:00<00:00, 95.4MB/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,283 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  60%|█████▉    | 26.7M/44.7M [00:00<00:00, 136MB/s] \u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,308 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  16%|█▌        | 6.96M/44.7M [00:00<00:01, 36.9MB/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,311 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  90%|████████▉ | 40.0M/44.7M [00:00<00:00, 129MB/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,337 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   0%|          | 0.00/44.7M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,379 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  70%|██████▉   | 31.2M/44.7M [00:00<00:00, 117MB/s] \u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,390 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  96%|█████████▌| 42.9M/44.7M [00:00<00:00, 119MB/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,409 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  54%|█████▎    | 23.9M/44.7M [00:00<00:00, 101MB/s] \u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,449 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   4%|▍         | 1.99M/44.7M [00:00<00:02, 20.9MB/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,470 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  79%|███████▉  | 35.4M/44.7M [00:00<00:00, 109MB/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,549 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   9%|▉         | 3.98M/44.7M [00:00<00:02, 19.6MB/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2361\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,561 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:2749|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707989\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,561 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:95|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,649 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  37%|███▋      | 16.5M/44.7M [00:00<00:00, 68.9MB/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,684 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2485\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,685 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:2873|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707989\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,685 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:93|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,732 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2552\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,732 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:2921|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707989\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,732 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:73|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,749 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  63%|██████▎   | 28.2M/44.7M [00:00<00:00, 89.5MB/s]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:29,768 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  93%|█████████▎| 41.4M/44.7M [00:00<00:00, 107MB/s] \u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:30,029 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2846\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:30,029 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:3220|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707990\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:30,029 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:76|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,308 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  16%|█▌        | 6.96M/44.7M [00:00<00:01, 36.9MB/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,311 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  90%|████████▉ | 40.0M/44.7M [00:00<00:00, 129MB/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,337 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   0%|          | 0.00/44.7M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,379 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  70%|██████▉   | 31.2M/44.7M [00:00<00:00, 117MB/s] \u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,390 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  96%|█████████▌| 42.9M/44.7M [00:00<00:00, 119MB/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,409 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  54%|█████▎    | 23.9M/44.7M [00:00<00:00, 101MB/s] \u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,449 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   4%|▍         | 1.99M/44.7M [00:00<00:02, 20.9MB/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,470 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  79%|███████▉  | 35.4M/44.7M [00:00<00:00, 109MB/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,549 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -   9%|▉         | 3.98M/44.7M [00:00<00:02, 19.6MB/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2361\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,561 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:2749|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707989\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,561 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:95|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,649 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  37%|███▋      | 16.5M/44.7M [00:00<00:00, 68.9MB/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,684 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2485\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,685 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:2873|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707989\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,685 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:93|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,732 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2552\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,732 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:2921|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707989\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,732 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:73|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,749 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  63%|██████▎   | 28.2M/44.7M [00:00<00:00, 89.5MB/s]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:29,768 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle -  93%|█████████▎| 41.4M/44.7M [00:00<00:00, 107MB/s] \u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:30,029 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2846\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:30,029 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:3220|#Level:Host|#hostname:ca32a1b17073,timestamp:1660707990\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:30,029 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:76|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:32,151 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - <<< self.key_ls:  ['Size Fit', 'Fit Type', 'Details', 'Sleeve Length', 'Color', 'Quantity', 'Sheer', 'Lining', 'Fabric', 'Warm Lined', 'Composition', 'Body', 'Care Instructions', 'Pattern Type', 'Pockets', 'Length', 'Type', 'Hem Shaped', 'Material', 'Belt', 'Neckline', 'Sleeve Type', 'Arabian Clothing', 'Style']\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:32,152 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - <<< self.class_len_ls:  [2, 4, 47, 6, 55, 9, 4, 3, 4, 3, 96, 2, 5, 44, 3, 4, 5, 4, 21, 3, 21, 10, 2, 7]\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:32,152 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2588\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:32,152 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2586.67|#ModelName:model,Level:Model|#hostname:ca32a1b17073,requestID:43de4fe1-517b-4311-be71-d19354a660d9,timestamp:1660707992\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:32,153 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:55252 \"POST /invocations HTTP/1.1\" 200 2960\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:32,153 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:32,153 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:357|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-08-17 03:46:32,153 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:32,151 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - <<< self.key_ls:  ['Size Fit', 'Fit Type', 'Details', 'Sleeve Length', 'Color', 'Quantity', 'Sheer', 'Lining', 'Fabric', 'Warm Lined', 'Composition', 'Body', 'Care Instructions', 'Pattern Type', 'Pockets', 'Length', 'Type', 'Hem Shaped', 'Material', 'Belt', 'Neckline', 'Sleeve Type', 'Arabian Clothing', 'Style']\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:32,152 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - <<< self.class_len_ls:  [2, 4, 47, 6, 55, 9, 4, 3, 4, 3, 96, 2, 5, 44, 3, 4, 5, 4, 21, 3, 21, 10, 2, 7]\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:32,152 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2588\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:32,152 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2586.67|#ModelName:model,Level:Model|#hostname:ca32a1b17073,requestID:43de4fe1-517b-4311-be71-d19354a660d9,timestamp:1660707992\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:32,153 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:55252 \"POST /invocations HTTP/1.1\" 200 2960\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:32,153 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:32,153 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:357|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-08-17 03:46:32,153 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:ca32a1b17073,timestamp:null\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    data=inference_inputs,\n",
    "    data_type=\"S3Prefix\",\n",
    "    content_type=\"application/x-image\",\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f99cd826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2022, 8, 17, 3, 41, 25, 653000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 8, 17, 3, 46, 35, 723000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 17, 3, 46, 35, 356000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/pytorch-inference-2022-08-17-03-41-25-641',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-17-03-41-25-641',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2022, 8, 17, 3, 35, 7, 506000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 8, 17, 3, 46, 10, 832000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 17, 3, 46, 10, 434000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/pytorch-inference-2022-08-17-03-35-07-494',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-17-03-35-07-494',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2022, 8, 17, 3, 27, 56, 44000, tzinfo=tzlocal()),\n",
      " 'FailureReason': 'AlgorithmError: See job logs for more information',\n",
      " 'LastModifiedTime': datetime.datetime(2022, 8, 17, 3, 33, 5, 475000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 17, 3, 33, 5, 113000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/pytorch-inference-2022-08-17-03-27-56-032',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-17-03-27-56-032',\n",
      " 'TransformJobStatus': 'Failed'}\n",
      "{'CreationTime': datetime.datetime(2022, 8, 12, 6, 54, 29, 763000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 8, 12, 7, 5, 38, 60000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 12, 7, 5, 37, 569000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/pytorch-inference-2022-08-12-06-54-29-751',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-12-06-54-29-751',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2022, 8, 12, 3, 49, 22, 714000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 8, 12, 4, 30, 11, 750000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 12, 4, 30, 11, 197000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/pytorch-inference-2022-08-12-03-49-22-702',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-12-03-49-22-702',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2022, 8, 12, 3, 29, 32, 586000, tzinfo=tzlocal()),\n",
      " 'FailureReason': 'AlgorithmError: See job logs for more information',\n",
      " 'LastModifiedTime': datetime.datetime(2022, 8, 12, 3, 42, 40, 99000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 12, 3, 42, 39, 693000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/pytorch-inference-2022-08-12-03-29-32-572',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-12-03-29-32-572',\n",
      " 'TransformJobStatus': 'Failed'}\n",
      "{'CreationTime': datetime.datetime(2022, 8, 10, 8, 54, 8, 975000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 8, 10, 8, 59, 9, 644000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 10, 8, 59, 9, 265000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/pytorch-inference-2022-08-10-08-54-08-963',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-10-08-54-08-963',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2020, 1, 7, 8, 6, 7, 55000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2020, 1, 7, 8, 11, 17, 354000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2020, 1, 7, 8, 11, 17, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/image-classification-model-2020-01-07-08-06-02',\n",
      " 'TransformJobName': 'image-classification-model-2020-01-07-08-06-02',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2020, 1, 7, 7, 41, 38, 806000, tzinfo=tzlocal()),\n",
      " 'FailureReason': 'ClientError: See job logs for more information',\n",
      " 'LastModifiedTime': datetime.datetime(2020, 1, 7, 7, 46, 43, 466000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2020, 1, 7, 7, 46, 43, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/image-classification-model-2020-01-07-07-41-18',\n",
      " 'TransformJobName': 'image-classification-model-2020-01-07-07-41-18',\n",
      " 'TransformJobStatus': 'Failed'}\n",
      "{'CreationTime': datetime.datetime(2020, 1, 6, 8, 16, 47, 650000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2020, 1, 6, 8, 22, 33, 342000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2020, 1, 6, 8, 22, 33, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/image-classification-model-2020-01-06-08-16-45',\n",
      " 'TransformJobName': 'image-classification-model-2020-01-06-08-16-45',\n",
      " 'TransformJobStatus': 'Completed'}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "sm_cli = sess.sagemaker_client\n",
    "\n",
    "transform_jobs = sm_cli.list_transform_jobs()[\"TransformJobSummaries\"]\n",
    "for job in transform_jobs:\n",
    "    pp.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebbeaa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2022, 8, 17, 3, 41, 25, 653000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'ModelName': 'pytorch-inference-2022-08-17-03-41-25-120',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '900',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Wed, 17 Aug 2022 03:47:54 GMT',\n",
      "                                      'x-amzn-requestid': '9a8d0d27-232a-40de-bc8c-202682f676fa'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '9a8d0d27-232a-40de-bc8c-202682f676fa',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 17, 3, 46, 35, 356000, tzinfo=tzlocal()),\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
      "                                                    'S3Uri': 's3://sagemaker-us-east-1-726335585155/batch_transform/test'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/pytorch-inference-2022-08-17-03-41-25-641',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-17-03-41-25-641',\n",
      " 'TransformJobStatus': 'Completed',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-east-1-726335585155/pytorch-inference-2022-08-17-03-41-25-641'},\n",
      " 'TransformResources': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge'},\n",
      " 'TransformStartTime': datetime.datetime(2022, 8, 17, 3, 44, 46, 651000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "job_info = sm_cli.describe_transform_job(\n",
    "    TransformJobName=transformer.latest_transform_job.name\n",
    ")\n",
    "\n",
    "pp.pprint(job_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26398f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-726335585155 pytorch-inference-2022-08-17-03-41-25-641\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_bucket_and_prefix(s3_output_path):\n",
    "    trim = re.sub(\"s3://\", \"\", s3_output_path)\n",
    "    bucket, prefix = trim.split(\"/\")\n",
    "    return bucket, prefix\n",
    "\n",
    "\n",
    "local_path = \"output\"  # Where to save the output locally\n",
    "\n",
    "bucket, output_prefix = get_bucket_and_prefix(job_info[\"TransformOutput\"][\"S3OutputPath\"])\n",
    "print(bucket, output_prefix)\n",
    "\n",
    "sess.download_data(path=local_path, bucket=bucket, key_prefix=output_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f591e37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': {'Size Fit': 'other', 'Fit Type': 'Regular Fit', 'Details': 'other', 'Sleeve Length': 'Long Sleeve', 'Color': 'Navy Blue', 'Quantity': '1 piece', 'Sheer': 'No', 'Lining': 'other', 'Fabric': 'Slight Stretch', 'Warm Lined': 'other', 'Composition': '100% Polyester', 'Body': 'other', 'Care Instructions': 'Machine wash or professional dry clean', 'Pattern Type': 'Letter', 'Pockets': 'other', 'Length': 'Regular', 'Type': 'Pullovers', 'Hem Shaped': 'other', 'Material': 'Polyester', 'Belt': 'other', 'Neckline': 'Hooded', 'Sleeve Type': 'Drop Shoulder', 'Arabian Clothing': 'other', 'Style': 'Casual'}}\n",
      "{'result': {'Size Fit': 'other', 'Fit Type': 'Regular Fit', 'Details': 'other', 'Sleeve Length': 'Long Sleeve', 'Color': 'Black', 'Quantity': '1 piece', 'Sheer': 'No', 'Lining': 'other', 'Fabric': 'Slight Stretch', 'Warm Lined': 'other', 'Composition': '100% Polyester', 'Body': 'other', 'Care Instructions': 'Machine wash or professional dry clean', 'Pattern Type': 'Letter', 'Pockets': 'other', 'Length': 'Regular', 'Type': 'Pullovers', 'Hem Shaped': 'other', 'Material': 'Polyester', 'Belt': 'other', 'Neckline': 'Hooded', 'Sleeve Type': 'Drop Shoulder', 'Arabian Clothing': 'other', 'Style': 'Casual'}}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the output\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "for f in os.listdir(local_path):\n",
    "    path = os.path.join(local_path, f)\n",
    "    with open(path, \"r\") as f:\n",
    "        pred = json.load(f)\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95736da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

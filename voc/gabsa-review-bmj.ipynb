{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f292507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "import pandas as pd\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8873454b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting mendelai-brat-parser\n",
      "  Downloading mendelai_brat_parser-0.0.11.tar.gz (4.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hBuilding wheels for collected packages: mendelai-brat-parser\n",
      "  Building wheel for mendelai-brat-parser (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for mendelai-brat-parser: filename=mendelai_brat_parser-0.0.11-py3-none-any.whl size=4945 sha256=d061dc3c5fb289b982388241b9abadd4b2c7fe53234b2b74bc98597d39c0b48d\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/90/a7/ff/138853d8196095fec56e0a97779a96d754b98f169c063beca3\n",
      "Successfully built mendelai-brat-parser\n",
      "Installing collected packages: mendelai-brat-parser\n",
      "Successfully installed mendelai-brat-parser-0.0.11\n",
      "\u001B[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install mendelai-brat-parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386c4d0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "585ef1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process for (aspect, category)\n",
      "a_list: ['feelings', 'expectancy', 'color', 'scene', 'purchase_behavior', 'size', 'design', 'price', 'fabric', 'style', 'audiences', 'quality', 'type', 'collocation', 'delivery']\n",
      "finished process, result save to:  ./label_data/good/aspect_category.csv\n"
     ]
    }
   ],
   "source": [
    "! python data_prepare_bmjl.py\\\n",
    "--label_dir './label_data/good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e4d2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process for (aspect, category)\n",
      "a_list: ['size', 'scene', 'design', 'feelings', 'fabric', 'purchase_behavior', 'audiences', 'color', 'quality', 'type', 'price', 'style', 'collocation', 'expectancy', 'delivery']\n",
      "finished process, result save to:  ./label_data/bad/aspect_category.csv\n"
     ]
    }
   ],
   "source": [
    "! python data_prepare_bmjl.py\\\n",
    "--label_dir './label_data/bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b5600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data\n",
    "good = './label_data/good/aspect_category.csv'\n",
    "bad = './label_data/bad/aspect_category.csv'\n",
    "df1 = pd.read_csv(good)\n",
    "df2 = pd.read_csv(bad)\n",
    "df_res = pd.concat([df1,df2])\n",
    "df_res.to_csv('./aspect_category.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d8d9c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1  sent_num  \\\n",
      "0           0             0         0   \n",
      "1           1             0         0   \n",
      "2           2             0         0   \n",
      "3           3             0         0   \n",
      "4           4             0         0   \n",
      "\n",
      "                                                text  sent_start  sent_end  \\\n",
      "0  I like the shorts. They're comfortable. But I ...           0       313   \n",
      "1  Absolutely love these shorts! The green color ...           0       215   \n",
      "2  I ordered the purple tie dye color and was sen...           0       322   \n",
      "3  I am 5â€™1 and around 110-112 lbs. I love these ...           0       453   \n",
      "4  I am obsessed with these shorts. Iâ€™ve ordered ...           0       351   \n",
      "\n",
      "   sent_len                                              label  \\\n",
      "0       313  [('comfortable', 'feelings'), ('being able to ...   \n",
      "1       215  [('green color was perfect', 'color'), ('runni...   \n",
      "2       322  [('Just wish I was given the correct color', '...   \n",
      "3       453  [('I love these shorts', 'feelings'), ('perfec...   \n",
      "4       351  [('Iâ€™ve ordered multiple colors', 'purchase_be...   \n",
      "\n",
      "                                           label_tag  \n",
      "0                                feelings,expectancy  \n",
      "1  color,scene,purchase_behavior,purchase_behavio...  \n",
      "2                                         expectancy  \n",
      "3                   feelings,size,design,design,size  \n",
      "4   purchase_behavior,price,design,purchase_behavior  \n",
      "<< path valid!\n",
      "training size:  (826, 9)\n",
      "test size:  (104, 9)\n",
      "validate size:  (103, 9)\n",
      "<<<finish data preparing!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd   \n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#preprocess data\n",
    "def write_txt(df,path):\n",
    "    '''\n",
    "    write back to txt\n",
    "    '''\n",
    "    #output txt file\n",
    "    df = df.reset_index()\n",
    "    with open(path,'a')as f:\n",
    "        for i in range(len(df)):\n",
    "            f.write(\"{} #### {}\".format(df.loc[i,'text'].strip(),df.loc[i,'label']))\n",
    "            f.write('\\n')\n",
    "            \n",
    "            \n",
    "def mkdir_rm(folder):\n",
    "    '''\n",
    "    make directory if not exists\n",
    "    '''\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder) \n",
    "    os.mkdir(folder)\n",
    "    print (\"<< path valid!\")\n",
    "    \n",
    "\n",
    "def preprocess_data(input_file,output_path,over_sample=True):\n",
    "    jsonObj = pd.read_csv(input_file)\n",
    "    jsonObj = jsonObj[jsonObj['label']!='[]']\n",
    "    print (jsonObj.head())\n",
    "    \n",
    "    #remove & remake the output folder \n",
    "    mkdir_rm(output_path)\n",
    "    \n",
    "    #generate tag.txt\n",
    "    #a_list = ['consumer','zone','target','consequence','product','product_spec']\n",
    "    #with open('tag.txt', 'w') as filehandle:\n",
    "     #   filehandle.writelines(\"%s\\n\" % tag for tag in a_list)\n",
    "    \n",
    "    #train/test/val split\n",
    "    train, validate, test = np.split(jsonObj.sample(frac=1), [int(.8*len(jsonObj)), int(.9*len(jsonObj))])\n",
    "   \n",
    "    print (\"training size: \",train.shape)\n",
    "    print (\"test size: \",test.shape)\n",
    "    print (\"validate size: \",validate.shape)\n",
    "    \n",
    "    # write train/test/dev\n",
    "    write_txt(train,os.path.join(output_path,'train.txt'))\n",
    "    write_txt(test,os.path.join(output_path,'test.txt'))\n",
    "    write_txt(validate,os.path.join(output_path,'dev.txt'))\n",
    "    print (\"<<<finish data preparing!\")\n",
    "    \n",
    "input_file = './aspect_category.csv'\n",
    "output_path = './data/tasd/bmjl'\n",
    "preprocess_data(input_file,output_path,over_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43ec1ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a5fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sage.Session()\n",
    "\n",
    "WORK_DIRECTORY = \"./data\"\n",
    "\n",
    "# S3 prefix\n",
    "prefix = \"bmjl\"\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"task\" : \"tasd\", \n",
    "    \"dataset\" : \"bmjl\", \n",
    "    \"model_name_or_path\" : \"t5-base\", \n",
    "    \"paradigm\": \"extraction\",\n",
    "    \"eval_batch_size\" :\"16\",\n",
    "    \"train_batch_size\" :\"2\",\n",
    "    \"learning_rate\" :\"3e-4\",\n",
    "    \"num_train_epochs\":\"1\",\n",
    "    \"n_gpu\": \"1\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a1a00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point = 'finetune.py'\n",
    "source_dir = './'\n",
    "git_config = None\n",
    "role = get_execution_role()\n",
    "framework_version = '1.7.1'\n",
    "py_version='py36'\n",
    "instance_type='ml.p3.2xlarge'\n",
    "#instance_type='local_gpu'\n",
    "instance_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a0da441",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point = 'finetune.py'\n",
    "source_dir = './'\n",
    "git_config = None\n",
    "role = get_execution_role()\n",
    "framework_version = '1.7.1'\n",
    "py_version='py36'\n",
    "instance_type='ml.p3.2xlarge'\n",
    "#instance_type='local_gpu'\n",
    "instance_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63fea514",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point = entry_point,\n",
    "    source_dir = source_dir,\n",
    "    git_config = git_config,\n",
    "    role = role,\n",
    "    debugger_hook_config=False,\n",
    "    hyperparameters = hyperparameters,\n",
    "    framework_version = framework_version, \n",
    "    py_version = py_version,\n",
    "    instance_type = instance_type,\n",
    "    instance_count = instance_count\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992c348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'tasd': data_location+'/tasd/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbf34d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-17 02:58:35 Starting - Starting the training job...\n",
      "2022-08-17 02:59:01 Starting - Preparing the instances for trainingProfilerReport-1660705115: InProgress\n",
      ".........\n",
      "2022-08-17 03:00:30 Downloading - Downloading input data...\n",
      "2022-08-17 03:00:50 Training - Downloading the training image.......................\u001B[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001B[0m\n",
      "\u001B[34mbash: no job control in this shell\u001B[0m\n",
      "\u001B[34m2022-08-17 03:04:46,061 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001B[0m\n",
      "\u001B[34m2022-08-17 03:04:46,085 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:04:46,095 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:04:47,443 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001B[0m\n",
      "\u001B[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001B[0m\n",
      "\u001B[34mCollecting transformers==4.6.0\n",
      "  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\u001B[0m\n",
      "\u001B[34mCollecting datasets==1.11.0\n",
      "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\u001B[0m\n",
      "\u001B[34mCollecting sentencepiece==0.1.91\n",
      "  Downloading sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\u001B[0m\n",
      "\u001B[34mCollecting pytorch_lightning==0.8.1\n",
      "  Downloading pytorch_lightning-0.8.1-py3-none-any.whl (293 kB)\u001B[0m\n",
      "\u001B[34mCollecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\u001B[0m\n",
      "\u001B[34mCollecting editdistance\n",
      "  Downloading editdistance-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (284 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (0.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (2.25.1)\u001B[0m\n",
      "\u001B[34mCollecting huggingface-hub==0.0.8\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (4.0.1)\u001B[0m\n",
      "\u001B[34mCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (4.51.0)\u001B[0m\n",
      "\u001B[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.25-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (1.19.1)\u001B[0m\n",
      "\u001B[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\u001B[0m\n",
      "\n",
      "2022-08-17 03:04:51 Training - Training image download completed. Training in progress.\u001B[34mCollecting filelock\n",
      "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (20.9)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (0.70.11.1)\u001B[0m\n",
      "\u001B[34mCollecting pyarrow!=4.0.0,>=1.0.0\n",
      "  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (1.1.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dill in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (0.3.3)\u001B[0m\n",
      "\u001B[34mCollecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (2021.5.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.7.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (5.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.18.2)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard>=1.14\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (2.10)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (3.0.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (2020.12.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (1.25.11)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (3.17.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.35.1)\u001B[0m\n",
      "\u001B[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (2.0.1)\u001B[0m\n",
      "\u001B[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.10.0-py2.py3-none-any.whl (167 kB)\u001B[0m\n",
      "\u001B[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001B[0m\n",
      "\u001B[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001B[0m\n",
      "\u001B[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (49.6.0.post20210108)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (4.7.2)\u001B[0m\n",
      "\u001B[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.16.0)\u001B[0m\n",
      "\u001B[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001B[0m\n",
      "\u001B[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001B[0m\n",
      "\u001B[34mCollecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.0->-r requirements.txt (line 1)) (3.10.0.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.0->-r requirements.txt (line 1)) (3.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.4.8)\u001B[0m\n",
      "\u001B[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r requirements.txt (line 1)) (2.4.7)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r requirements.txt (line 2)) (2.8.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r requirements.txt (line 2)) (2021.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r requirements.txt (line 1)) (7.1.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r requirements.txt (line 1)) (1.0.1)\u001B[0m\n",
      "\u001B[34mBuilding wheels for collected packages: jieba, sacremoses\n",
      "  Building wheel for jieba (setup.py): started\u001B[0m\n",
      "\u001B[34m  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=f01018e941d46d63eea042259f3db5a1bb75167f4bc9d69d8c97816c99c4d663\n",
      "  Stored in directory: /root/.cache/pip/wheels/17/a7/8b/a7e03881534e78558920ac68aaeca05180c0e2c3d11c4fce3b\n",
      "  Building wheel for sacremoses (setup.py): started\u001B[0m\n",
      "\u001B[34m  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895252 sha256=9e801007b4f861a76a98e90eaf4af594c0069c6209ed1dca0043726c99b825b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001B[0m\n",
      "\u001B[34mSuccessfully built jieba sacremoses\u001B[0m\n",
      "\u001B[34mInstalling collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, regex, markdown, grpcio, google-auth-oauthlib, filelock, absl-py, xxhash, tokenizers, tensorboard, sacremoses, pyarrow, huggingface-hub, transformers, sentencepiece, pytorch-lightning, jieba, editdistance, datasets\u001B[0m\n",
      "\u001B[34m  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.0.1\n",
      "    Uninstalling importlib-metadata-4.0.1:\n",
      "      Successfully uninstalled importlib-metadata-4.0.1\u001B[0m\n",
      "\u001B[34m  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 4.0.0\n",
      "    Uninstalling pyarrow-4.0.0:\n",
      "      Successfully uninstalled pyarrow-4.0.0\u001B[0m\n",
      "\u001B[34mSuccessfully installed absl-py-1.2.0 cachetools-4.2.4 datasets-1.11.0 editdistance-0.6.0 filelock-3.4.1 google-auth-2.10.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 huggingface-hub-0.0.8 importlib-metadata-4.8.3 jieba-0.42.1 markdown-3.3.7 oauthlib-3.2.0 pyarrow-6.0.1 pyasn1-modules-0.2.8 pytorch-lightning-0.8.1 regex-2022.7.25 requests-oauthlib-1.3.1 sacremoses-0.0.53 sentencepiece-0.1.91 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.10.3 transformers-4.6.0 xxhash-3.0.0\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[34m2022-08-17 03:05:10,013 sagemaker-training-toolkit INFO     Invoking user script\u001B[0m\n",
      "\u001B[34mTraining Env:\u001B[0m\n",
      "\u001B[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"tasd\": \"/opt/ml/input/data/tasd\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dataset\": \"bmjl\",\n",
      "        \"eval_batch_size\": \"16\",\n",
      "        \"learning_rate\": \"3e-4\",\n",
      "        \"model_name_or_path\": \"t5-base\",\n",
      "        \"n_gpu\": \"1\",\n",
      "        \"num_train_epochs\": \"1\",\n",
      "        \"paradigm\": \"extraction\",\n",
      "        \"task\": \"tasd\",\n",
      "        \"train_batch_size\": \"2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"tasd\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-08-17-02-58-32-852\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-726335585155/pytorch-training-2022-08-17-02-58-32-852/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"finetune\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"finetune.py\"\u001B[0m\n",
      "\u001B[34m}\u001B[0m\n",
      "\u001B[34mEnvironment variables:\u001B[0m\n",
      "\u001B[34mSM_HOSTS=[\"algo-1\"]\u001B[0m\n",
      "\u001B[34mSM_NETWORK_INTERFACE_NAME=eth0\u001B[0m\n",
      "\u001B[34mSM_HPS={\"dataset\":\"bmjl\",\"eval_batch_size\":\"16\",\"learning_rate\":\"3e-4\",\"model_name_or_path\":\"t5-base\",\"n_gpu\":\"1\",\"num_train_epochs\":\"1\",\"paradigm\":\"extraction\",\"task\":\"tasd\",\"train_batch_size\":\"2\"}\u001B[0m\n",
      "\u001B[34mSM_USER_ENTRY_POINT=finetune.py\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_PARAMS={}\u001B[0m\n",
      "\u001B[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001B[0m\n",
      "\u001B[34mSM_INPUT_DATA_CONFIG={\"tasd\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001B[0m\n",
      "\u001B[34mSM_CHANNELS=[\"tasd\"]\u001B[0m\n",
      "\u001B[34mSM_CURRENT_HOST=algo-1\u001B[0m\n",
      "\u001B[34mSM_MODULE_NAME=finetune\u001B[0m\n",
      "\u001B[34mSM_LOG_LEVEL=20\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001B[0m\n",
      "\u001B[34mSM_INPUT_DIR=/opt/ml/input\u001B[0m\n",
      "\u001B[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DIR=/opt/ml/output\u001B[0m\n",
      "\u001B[34mSM_NUM_CPUS=8\u001B[0m\n",
      "\u001B[34mSM_NUM_GPUS=1\u001B[0m\n",
      "\u001B[34mSM_MODEL_DIR=/opt/ml/model\u001B[0m\n",
      "\u001B[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-726335585155/pytorch-training-2022-08-17-02-58-32-852/source/sourcedir.tar.gz\u001B[0m\n",
      "\u001B[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"tasd\":\"/opt/ml/input/data/tasd\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dataset\":\"bmjl\",\"eval_batch_size\":\"16\",\"learning_rate\":\"3e-4\",\"model_name_or_path\":\"t5-base\",\"n_gpu\":\"1\",\"num_train_epochs\":\"1\",\"paradigm\":\"extraction\",\"task\":\"tasd\",\"train_batch_size\":\"2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"tasd\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-08-17-02-58-32-852\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-726335585155/pytorch-training-2022-08-17-02-58-32-852/source/sourcedir.tar.gz\",\"module_name\":\"finetune\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"finetune.py\"}\u001B[0m\n",
      "\u001B[34mSM_USER_ARGS=[\"--dataset\",\"bmjl\",\"--eval_batch_size\",\"16\",\"--learning_rate\",\"3e-4\",\"--model_name_or_path\",\"t5-base\",\"--n_gpu\",\"1\",\"--num_train_epochs\",\"1\",\"--paradigm\",\"extraction\",\"--task\",\"tasd\",\"--train_batch_size\",\"2\"]\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001B[0m\n",
      "\u001B[34mSM_CHANNEL_TASD=/opt/ml/input/data/tasd\u001B[0m\n",
      "\u001B[34mSM_HP_DATASET=bmjl\u001B[0m\n",
      "\u001B[34mSM_HP_EVAL_BATCH_SIZE=16\u001B[0m\n",
      "\u001B[34mSM_HP_LEARNING_RATE=3e-4\u001B[0m\n",
      "\u001B[34mSM_HP_MODEL_NAME_OR_PATH=t5-base\u001B[0m\n",
      "\u001B[34mSM_HP_N_GPU=1\u001B[0m\n",
      "\u001B[34mSM_HP_NUM_TRAIN_EPOCHS=1\u001B[0m\n",
      "\u001B[34mSM_HP_PARADIGM=extraction\u001B[0m\n",
      "\u001B[34mSM_HP_TASK=tasd\u001B[0m\n",
      "\u001B[34mSM_HP_TRAIN_BATCH_SIZE=2\u001B[0m\n",
      "\u001B[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001B[0m\n",
      "\u001B[34mInvoking script with the following command:\u001B[0m\n",
      "\u001B[34m/opt/conda/bin/python3.6 finetune.py --dataset bmjl --eval_batch_size 16 --learning_rate 3e-4 --model_name_or_path t5-base --n_gpu 1 --num_train_epochs 1 --paradigm extraction --task tasd --train_batch_size 2\u001B[0m\n",
      "\u001B[34m/opt/ml/code\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: transformers==4.6.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (4.6.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: datasets==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.11.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: sentencepiece==0.1.91 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (0.1.91)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pytorch_lightning==0.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.8.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: jieba in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (0.42.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: editdistance in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.6.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (1.19.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (3.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (20.9)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (2.25.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (0.0.53)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (4.51.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (4.8.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (2022.7.25)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: huggingface-hub==0.0.8 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (0.0.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (0.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (0.10.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (2021.5.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dill in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (0.3.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (3.0.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (6.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (1.1.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (0.70.11.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tensorboard>=1.14 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (2.10.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.7.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.18.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (5.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (1.25.11)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (3.0.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (2020.12.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (2.10)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (2.10.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.35.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.8.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (2.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.6.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (3.17.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (49.6.0.post20210108)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.2.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.47.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (3.3.7)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.4.6)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.2.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (4.7.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (4.2.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.16.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.3.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.0->-r requirements.txt (line 1)) (3.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.0->-r requirements.txt (line 1)) (3.10.0.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.4.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (3.2.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r requirements.txt (line 1)) (2.4.7)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r requirements.txt (line 2)) (2.8.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r requirements.txt (line 2)) (2021.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r requirements.txt (line 1)) (1.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r requirements.txt (line 1)) (7.1.2)\u001B[0m\n",
      "\u001B[34m<<<run train!!\u001B[0m\n",
      "\u001B[34margs task:  tasd\n",
      " ============================== NEW EXP: TASD on bmjl ============================== \u001B[0m\n",
      "\u001B[34mHere is an example (from dev set) under `extraction` paradigm:\u001B[0m\n",
      "\u001B[34mTotal examples = 103 for data/tasd/bmjl/dev.txt\u001B[0m\n",
      "\u001B[34mInput : I sized up and they were still super short. You could easily see the under shorts without moving. They also did not flatter my shape at all and made the material pull in the middle.\u001B[0m\n",
      "\u001B[34mOutput: (super short, size); (sized up, size); (material pull in the middle, design); (did not flatter my shape, type); (see the under shorts without moving, size); (see the under shorts without moving, design)\u001B[0m\n",
      "\u001B[34m****** Conduct Training ******\u001B[0m\n",
      "\u001B[34mNamespace(adam_epsilon=1e-08, ckpoint_path='/opt/ml/model/cktepoch=1.ckpt', customer_jj=False, dataset='bmjl', do_batch_predict=False, do_direct_eval=False, do_direct_predict=False, do_eval=False, do_train=True, eval_batch_size=16, gradient_accumulation_steps=1, learning_rate=0.0003, max_seq_length=128, model_name_or_path='t5-base', n_gpu=1, num_train_epochs=1, output_dir='/opt/ml/model', paradigm='extraction', seed=42, task='tasd', text='æ—©é¤ä¸€èˆ¬èˆ¬ï¼Œå‹‰å‹‰å¼ºå¼ºå¡«é¥±è‚šå­ï¼Œæ ·å¼å¯é€‰æ€§ä¸å¤šï¼Œå¯èƒ½æ˜¯ç–«æƒ…çš„å½±å“å§ã€‚ä¸è¿‡é…’åº—çš„æœåŠ¡ä¸é”™ï¼Œäº”ä¸ªå°å­©æ—©é¤éƒ½é€äº†ï¼Œç‚¹ðŸ‘ã€‚ç”±äºŽé…’åº—åŽ†å²æœ‰ç‚¹é•¿ï¼Œæ‰€ä»¥è®¾æ–½æ„Ÿè§‰ä¸€èˆ¬èˆ¬ï¼Œæ•´ä½“è¿˜å¯ä»¥ï¼Œä¸‰é’»å§', train_batch_size=2, warmup_steps=0.0, weight_decay=0.0)\u001B[0m\n",
      "\u001B[34m{'default_root_dir': '/opt/ml/model', 'accumulate_grad_batches': 1, 'gpus': 1, 'gradient_clip_val': 1.0, 'max_epochs': 1, 'checkpoint_callback': <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f6052534748>, 'callbacks': [<__main__.LoggingCallback object at 0x7f60525347b8>]}\u001B[0m\n",
      "\u001B[34mTotal examples = 103 for data/tasd/bmjl/dev.txt\u001B[0m\n",
      "\u001B[34m#015Validation sanity check: 0it [00:00, ?it/s]#015Validation sanity check:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.77s/it]#015                                                                      #015Total examples = 826 for data/tasd/bmjl/train.txt\u001B[0m\n",
      "\u001B[34mtrain Input : theses shorts were made of cheap material not advertised properly very upset Amazon would deal with this company on anything further from maker I relied on Amazon to carry good products not product from any China that is cheap\u001B[0m\n",
      "\u001B[34mtrain Output: (cheap material, fabric); (cheap, fabric)\u001B[0m\n",
      "\u001B[34mself.hparams.n_gpu:  1\u001B[0m\n",
      "\u001B[34mt_total:  826.0\u001B[0m\n",
      "\u001B[34mTotal examples = 103 for data/tasd/bmjl/dev.txt\u001B[0m\n",
      "\u001B[34m#015Training: 0it [00:00, ?it/s]#015Training:   0%|          | 0/420 [00:00<?, ?it/s]#015Epoch 1:   0%|          | 0/420 [00:00<?, ?it/s] #015Epoch 1:   0%|          | 1/420 [00:00<03:25,  2.04it/s]#015Epoch 1:   0%|          | 1/420 [00:00<03:25,  2.04it/s, loss=3.807, v_num=0]#015Epoch 1:   0%|          | 2/420 [00:00<02:39,  2.63it/s, loss=3.807, v_num=0]#015Epoch 1:   0%|          | 2/420 [00:00<02:39,  2.62it/s, loss=3.528, v_num=0]#015Epoch 1:   1%|          | 3/420 [00:01<02:22,  2.92it/s, loss=3.528, v_num=0]#015Epoch 1:   1%|          | 3/420 [00:01<02:22,  2.92it/s, loss=3.461, v_num=0]#015Epoch 1:   1%|          | 4/420 [00:01<02:14,  3.09it/s, loss=3.461, v_num=0]#015Epoch 1:   1%|          | 4/420 [00:01<02:14,  3.09it/s, loss=3.245, v_num=0]#015Epoch 1:   1%|          | 5/420 [00:01<02:11,  3.15it/s, loss=3.245, v_num=0]#015Epoch 1:   1%|          | 5/420 [00:01<02:11,  3.14it/s, loss=3.493, v_num=0]#015Epoch 1:   1%|â–         | 6/420 [00:01<02:09,  3.20it/s, loss=3.493, v_num=0]#015Epoch 1:   1%|â–         | 6/420 [00:01<02:09,  3.20it/s, loss=3.313, v_num=0]#015Epoch 1:   2%|â–         | 7/420 [00:02<02:05,  3.28it/s, loss=3.313, v_num=0]#015Epoch 1:   2%|â–         | 7/420 [00:02<02:05,  3.28it/s, loss=3.119, v_num=0]#015Epoch 1:   2%|â–         | 8/420 [00:02<02:03,  3.35it/s, loss=3.119, v_num=0]#015Epoch 1:   2%|â–         | 8/420 [00:02<02:03,  3.35it/s, loss=2.970, v_num=0]#015Epoch 1:   2%|â–         | 9/420 [00:02<02:00,  3.40it/s, loss=2.970, v_num=0]#015Epoch 1:   2%|â–         | 9/420 [00:02<02:00,  3.40it/s, loss=3.016, v_num=0]#015Epoch 1:   2%|â–         | 10/420 [00:02<01:59,  3.42it/s, loss=3.016, v_num=0]#015Epoch 1:   2%|â–         | 10/420 [00:02<01:59,  3.42it/s, loss=2.900, v_num=0]#015Epoch 1:   3%|â–Ž         | 11/420 [00:03<01:57,  3.47it/s, loss=2.900, v_num=0]#015Epoch 1:   3%|â–Ž         | 11/420 [00:03<01:57,  3.47it/s, loss=2.788, v_num=0]#015Epoch 1:   3%|â–Ž         | 12/420 [00:03<01:56,  3.50it/s, loss=2.788, v_num=0]#015Epoch 1:   3%|â–Ž         | 12/420 [00:03<01:56,  3.50it/s, loss=2.688, v_num=0]#015Epoch 1:   3%|â–Ž         | 13/420 [00:03<01:55,  3.53it/s, loss=2.688, v_num=0]#015Epoch 1:   3%|â–Ž         | 13/420 [00:03<01:55,  3.53it/s, loss=2.580, v_num=0]#015Epoch 1:   3%|â–Ž         | 14/420 [00:03<01:53,  3.56it/s, loss=2.580, v_num=0]#015Epoch 1:   3%|â–Ž         | 14/420 [00:03<01:53,  3.56it/s, loss=2.511, v_num=0]#015Epoch 1:   4%|â–Ž         | 15/420 [00:04<01:53,  3.57it/s, loss=2.511, v_num=0]#015Epoch 1:   4%|â–Ž         | 15/420 [00:04<01:53,  3.57it/s, loss=2.445, v_num=0]#015Epoch 1:   4%|â–         | 16/420 [00:04<01:52,  3.59it/s, loss=2.445, v_num=0]#015Epoch 1:   4%|â–         | 16/420 [00:04<01:52,  3.59it/s, loss=2.393, v_num=0]#015Epoch 1:   4%|â–         | 17/420 [00:04<01:51,  3.60it/s, loss=2.393, v_num=0]#015Epoch 1:   4%|â–         | 17/420 [00:04<01:51,  3.60it/s, loss=2.366, v_num=0]#015Epoch 1:   4%|â–         | 18/420 [00:04<01:51,  3.62it/s, loss=2.366, v_num=0]#015Epoch 1:   4%|â–         | 18/420 [00:04<01:51,  3.62it/s, loss=2.324, v_num=0]#015Epoch 1:   5%|â–         | 19/420 [00:05<01:50,  3.62it/s, loss=2.324, v_num=0]#015Epoch 1:   5%|â–         | 19/420 [00:05<01:50,  3.62it/s, loss=2.289, v_num=0]#015Epoch 1:   5%|â–         | 20/420 [00:05<01:50,  3.64it/s, loss=2.289, v_num=0]#015Epoch 1:   5%|â–         | 20/420 [00:05<01:50,  3.64it/s, loss=2.239, v_num=0]#015Epoch 1:   5%|â–Œ         | 21/420 [00:05<01:49,  3.65it/s, loss=2.239, v_num=0]#015Epoch 1:   5%|â–Œ         | 21/420 [00:05<01:49,  3.65it/s, loss=2.129, v_num=0]#015Epoch 1:   5%|â–Œ         | 22/420 [00:06<01:48,  3.65it/s, loss=2.129, v_num=0]#015Epoch 1:   5%|â–Œ         | 22/420 [00:06<01:49,  3.65it/s, loss=2.036, v_num=0]#015Epoch 1:   5%|â–Œ         | 23/420 [00:06<01:48,  3.66it/s, loss=2.036, v_num=0]#015Epoch 1:   5%|â–Œ         | 23/420 [00:06<01:48,  3.66it/s, loss=1.944, v_num=0]#015Epoch 1:   6%|â–Œ         | 24/420 [00:06<01:48,  3.66it/s, loss=1.944, v_num=0]#015Epoch 1:   6%|â–Œ         | 24/420 [00:06<01:48,  3.66it/s, loss=1.883, v_num=0]#015Epoch 1:   6%|â–Œ         | 25/420 [00:06<01:47,  3.67it/s, loss=1.883, v_num=0]#015Epoch 1:   6%|â–Œ         | 25/420 [00:06<01:47,  3.67it/s, loss=1.710, v_num=0]#015Epoch 1:   6%|â–Œ         | 26/420 [00:07<01:47,  3.67it/s, loss=1.710, v_num=0]#015Epoch 1:   6%|â–Œ         | 26/420 [00:07<01:47,  3.67it/s, loss=1.660, v_num=0]#015Epoch 1:   6%|â–‹         | 27/420 [00:07<01:46,  3.68it/s, loss=1.660, v_num=0]#015Epoch 1:   6%|â–‹         | 27/420 [00:07<01:46,  3.68it/s, loss=1.635, v_num=0]#015Epoch 1:   7%|â–‹         | 28/420 [00:07<01:46,  3.69it/s, loss=1.635, v_num=0]#015Epoch 1:   7%|â–‹         | 28/420 [00:07<01:46,  3.69it/s, loss=1.615, v_num=0]#015Epoch 1:   7%|â–‹         | 29/420 [00:07<01:45,  3.70it/s, loss=1.615, v_num=0]#015Epoch 1:   7%|â–‹         | 29/420 [00:07<01:45,  3.70it/s, loss=1.511, v_num=0]#015Epoch 1:   7%|â–‹         | 30/420 [00:08<01:45,  3.71it/s, loss=1.511, v_num=0]#015Epoch 1:   7%|â–‹         | 30/420 [00:08<01:45,  3.71it/s, loss=1.461, v_num=0]#015Epoch 1:   7%|â–‹         | 31/420 [00:08<01:44,  3.71it/s, loss=1.461, v_num=0]#015Epoch 1:   7%|â–‹         | 31/420 [00:08<01:44,  3.71it/s, loss=1.454, v_num=0]#015Epoch 1:   8%|â–Š         | 32/420 [00:08<01:44,  3.71it/s, loss=1.454, v_num=0]#015Epoch 1:   8%|â–Š         | 32/420 [00:08<01:44,  3.71it/s, loss=1.420, v_num=0]#015Epoch 1:   8%|â–Š         | 33/420 [00:08<01:44,  3.71it/s, loss=1.420, v_num=0]#015Epoch 1:   8%|â–Š         | 33/420 [00:08<01:44,  3.71it/s, loss=1.419, v_num=0]#015Epoch 1:   8%|â–Š         | 34/420 [00:09<01:43,  3.71it/s, loss=1.419, v_num=0]#015Epoch 1:   8%|â–Š         | 34/420 [00:09<01:43,  3.71it/s, loss=1.381, v_num=0]#015Epoch 1:   8%|â–Š         | 35/420 [00:09<01:43,  3.71it/s, loss=1.381, v_num=0]#015Epoch 1:   8%|â–Š         | 35/420 [00:09<01:43,  3.71it/s, loss=1.368, v_num=0]#015Epoch 1:   9%|â–Š         | 36/420 [00:09<01:43,  3.72it/s, loss=1.368, v_num=0]#015Epoch 1:   9%|â–Š         | 36/420 [00:09<01:43,  3.72it/s, loss=1.328, v_num=0]#015Epoch 1:   9%|â–‰         | 37/420 [00:09<01:43,  3.72it/s, loss=1.328, v_num=0]#015Epoch 1:   9%|â–‰         | 37/420 [00:09<01:43,  3.72it/s, loss=1.290, v_num=0]#015Epoch 1:   9%|â–‰         | 38/420 [00:10<01:42,  3.72it/s, loss=1.290, v_num=0]#015Epoch 1:   9%|â–‰         | 38/420 [00:10<01:42,  3.72it/s, loss=1.272, v_num=0]#015Epoch 1:   9%|â–‰         | 39/420 [00:10<01:42,  3.72it/s, loss=1.272, v_num=0]#015Epoch 1:   9%|â–‰         | 39/420 [00:10<01:42,  3.72it/s, loss=1.229, v_num=0]#015Epoch 1:  10%|â–‰         | 40/420 [00:10<01:42,  3.72it/s, loss=1.229, v_num=0]#015Epoch 1:  10%|â–‰         | 40/420 [00:10<01:42,  3.72it/s, loss=1.229, v_num=0]#015Epoch 1:  10%|â–‰         | 41/420 [00:11<01:41,  3.72it/s, loss=1.229, v_num=0]#015Epoch 1:  10%|â–‰         | 41/420 [00:11<01:41,  3.72it/s, loss=1.203, v_num=0]#015Epoch 1:  10%|â–ˆ         | 42/420 [00:11<01:41,  3.72it/s, loss=1.203, v_num=0]#015Epoch 1:  10%|â–ˆ         | 42/420 [00:11<01:41,  3.72it/s, loss=1.186, v_num=0]#015Epoch 1:  10%|â–ˆ         | 43/420 [00:11<01:41,  3.73it/s, loss=1.186, v_num=0]#015Epoch 1:  10%|â–ˆ         | 43/420 [00:11<01:41,  3.72it/s, loss=1.167, v_num=0]#015Epoch 1:  10%|â–ˆ         | 44/420 [00:11<01:40,  3.73it/s, loss=1.167, v_num=0]#015Epoch 1:  10%|â–ˆ         | 44/420 [00:11<01:40,  3.73it/s, loss=1.160, v_num=0]#015Epoch 1:  11%|â–ˆ         | 45/420 [00:12<01:40,  3.73it/s, loss=1.160, v_num=0]#015Epoch 1:  11%|â–ˆ         | 45/420 [00:12<01:40,  3.73it/s, loss=1.175, v_num=0]#015Epoch 1:  11%|â–ˆ         | 46/420 [00:12<01:40,  3.74it/s, loss=1.175, v_num=0]#015Epoch 1:  11%|â–ˆ         | 46/420 [00:12<01:40,  3.74it/s, loss=1.159, v_num=0]#015Epoch 1:  11%|â–ˆ         | 47/420 [00:12<01:39,  3.74it/s, loss=1.159, v_num=0]#015Epoch 1:  11%|â–ˆ         | 47/420 [00:12<01:39,  3.74it/s, loss=1.144, v_num=0]#015Epoch 1:  11%|â–ˆâ–        | 48/420 [00:12<01:39,  3.74it/s, loss=1.144, v_num=0]#015Epoch 1:  11%|â–ˆâ–        | 48/420 [00:12<01:39,  3.74it/s, loss=1.133, v_num=0]#015Epoch 1:  12%|â–ˆâ–        | 49/420 [00:13<01:38,  3.75it/s, loss=1.133, v_num=0]#015Epoch 1:  12%|â–ˆâ–        | 49/420 [00:13<01:38,  3.75it/s, loss=1.152, v_num=0]#015Epoch 1:  12%|â–ˆâ–        | 50/420 [00:13<01:38,  3.74it/s, loss=1.152, v_num=0]#015Epoch 1:  12%|â–ˆâ–        | 50/420 [00:13<01:38,  3.74it/s, loss=1.171, v_num=0]#015Epoch 1:  12%|â–ˆâ–        | 51/420 [00:13<01:39,  3.72it/s, loss=1.171, v_num=0]#015Epoch 1:  12%|â–ˆâ–        | 51/420 [00:13<01:39,  3.72it/s, loss=1.143, v_num=0]#015Epoch 1:  12%|â–ˆâ–        | 52/420 [00:13<01:38,  3.72it/s, loss=1.143, v_num=0]#015Epoch 1:  12%|â–ˆâ–        | 52/420 [00:13<01:38,  3.72it/s, loss=1.200, v_num=0]#015Epoch 1:  13%|â–ˆâ–Ž        | 53/420 [00:14<01:38,  3.71it/s, loss=1.200, v_num=0]#015Epoch 1:  13%|â–ˆâ–Ž        | 53/420 [00:14<01:38,  3.71it/s, loss=1.202, v_num=0]#015Epoch 1:  13%|â–ˆâ–Ž        | 54/420 [00:14<01:38,  3.71it/s, loss=1.202, v_num=0]#015Epoch 1:  13%|â–ˆâ–Ž        | 54/420 [00:14<01:38,  3.71it/s, loss=1.258, v_num=0]#015Epoch 1:  13%|â–ˆâ–Ž        | 55/420 [00:14<01:38,  3.71it/s, loss=1.258, v_num=0]#015Epoch 1:  13%|â–ˆâ–Ž        | 55/420 [00:14<01:38,  3.71it/s, loss=1.260, v_num=0]#015Epoch 1:  13%|â–ˆâ–Ž        | 56/420 [00:15<01:38,  3.71it/s, loss=1.260, v_num=0]#015Epoch 1:  13%|â–ˆâ–Ž        | 56/420 [00:15<01:38,  3.71it/s, loss=1.281, v_num=0]#015Epoch 1:  14%|â–ˆâ–Ž        | 57/420 [00:15<01:37,  3.71it/s, loss=1.281, v_num=0]#015Epoch 1:  14%|â–ˆâ–Ž        | 57/420 [00:15<01:37,  3.70it/s, loss=1.269, v_num=0]#015Epoch 1:  14%|â–ˆâ–        | 58/420 [00:15<01:37,  3.70it/s, loss=1.269, v_num=0]#015Epoch 1:  14%|â–ˆâ–        | 58/420 [00:15<01:37,  3.70it/s, loss=1.288, v_num=0]#015Epoch 1:  14%|â–ˆâ–        | 59/420 [00:15<01:37,  3.69it/s, loss=1.288, v_num=0]#015Epoch 1:  14%|â–ˆâ–        | 59/420 [00:15<01:37,  3.69it/s, loss=1.292, v_num=0]#015Epoch 1:  14%|â–ˆâ–        | 60/420 [00:16<01:37,  3.68it/s, loss=1.292, v_num=0]#015Epoch 1:  14%|â–ˆâ–        | 60/420 [00:16<01:37,  3.68it/s, loss=1.282, v_num=0]#015Epoch 1:  15%|â–ˆâ–        | 61/420 [00:16<01:37,  3.68it/s, loss=1.282, v_num=0]#015Epoch 1:  15%|â–ˆâ–        | 61/420 [00:16<01:37,  3.68it/s, loss=1.265, v_num=0]#015Epoch 1:  15%|â–ˆâ–        | 62/420 [00:16<01:37,  3.68it/s, loss=1.265, v_num=0]#015Epoch 1:  15%|â–ˆâ–        | 62/420 [00:16<01:37,  3.68it/s, loss=1.244, v_num=0]#015Epoch 1:  15%|â–ˆâ–Œ        | 63/420 [00:17<01:36,  3.68it/s, loss=1.244, v_num=0]#015Epoch 1:  15%|â–ˆâ–Œ        | 63/420 [00:17<01:36,  3.68it/s, loss=1.227, v_num=0]#015Epoch 1:  15%|â–ˆâ–Œ        | 64/420 [00:17<01:36,  3.68it/s, loss=1.227, v_num=0]#015Epoch 1:  15%|â–ˆâ–Œ        | 64/420 [00:17<01:36,  3.68it/s, loss=1.213, v_num=0]#015Epoch 1:  15%|â–ˆâ–Œ        | 65/420 [00:17<01:36,  3.69it/s, loss=1.213, v_num=0]#015Epoch 1:  15%|â–ˆâ–Œ        | 65/420 [00:17<01:36,  3.69it/s, loss=1.230, v_num=0]#015Epoch 1:  16%|â–ˆâ–Œ        | 66/420 [00:17<01:35,  3.69it/s, loss=1.230, v_num=0]#015Epoch 1:  16%|â–ˆâ–Œ        | 66/420 [00:17<01:35,  3.69it/s, loss=1.222, v_num=0]#015Epoch 1:  16%|â–ˆâ–Œ        | 67/420 [00:18<01:35,  3.69it/s, loss=1.222, v_num=0]#015Epoch 1:  16%|â–ˆâ–Œ        | 67/420 [00:18<01:35,  3.69it/s, loss=1.231, v_num=0]#015Epoch 1:  16%|â–ˆâ–Œ        | 68/420 [00:18<01:35,  3.70it/s, loss=1.231, v_num=0]#015Epoch 1:  16%|â–ˆâ–Œ        | 68/420 [00:18<01:35,  3.70it/s, loss=1.212, v_num=0]#015Epoch 1:  16%|â–ˆâ–‹        | 69/420 [00:18<01:34,  3.70it/s, loss=1.212, v_num=0]#015Epoch 1:  16%|â–ˆâ–‹        | 69/420 [00:18<01:34,  3.70it/s, loss=1.180, v_num=0]#015Epoch 1:  17%|â–ˆâ–‹        | 70/420 [00:18<01:34,  3.71it/s, loss=1.180, v_num=0]#015Epoch 1:  17%|â–ˆâ–‹        | 70/420 [00:18<01:34,  3.71it/s, loss=1.178, v_num=0]#015Epoch 1:  17%|â–ˆâ–‹        | 71/420 [00:19<01:34,  3.71it/s, loss=1.178, v_num=0]#015Epoch 1:  17%|â–ˆâ–‹        | 71/420 [00:19<01:34,  3.71it/s, loss=1.186, v_num=0]#015Epoch 1:  17%|â–ˆâ–‹        | 72/420 [00:19<01:33,  3.72it/s, loss=1.186, v_num=0]#015Epoch 1:  17%|â–ˆâ–‹        | 72/420 [00:19<01:33,  3.72it/s, loss=1.140, v_num=0]#015Epoch 1:  17%|â–ˆâ–‹        | 73/420 [00:19<01:33,  3.72it/s, loss=1.140, v_num=0]#015Epoch 1:  17%|â–ˆâ–‹        | 73/420 [00:19<01:33,  3.72it/s, loss=1.118, v_num=0]#015Epoch 1:  18%|â–ˆâ–Š        | 74/420 [00:19<01:32,  3.72it/s, loss=1.118, v_num=0]#015Epoch 1:  18%|â–ˆâ–Š        | 74/420 [00:19<01:32,  3.72it/s, loss=1.065, v_num=0]#015Epoch 1:  18%|â–ˆâ–Š        | 75/420 [00:20<01:32,  3.73it/s, loss=1.065, v_num=0]#015Epoch 1:  18%|â–ˆâ–Š        | 75/420 [00:20<01:32,  3.73it/s, loss=1.046, v_num=0]#015Epoch 1:  18%|â–ˆâ–Š        | 76/420 [00:20<01:32,  3.73it/s, loss=1.046, v_num=0]#015Epoch 1:  18%|â–ˆâ–Š        | 76/420 [00:20<01:32,  3.73it/s, loss=1.029, v_num=0]#015Epoch 1:  18%|â–ˆâ–Š        | 77/420 [00:20<01:32,  3.73it/s, loss=1.029, v_num=0]#015Epoch 1:  18%|â–ˆâ–Š        | 77/420 [00:20<01:32,  3.73it/s, loss=1.015, v_num=0]#015Epoch 1:  19%|â–ˆâ–Š        | 78/420 [00:20<01:31,  3.73it/s, loss=1.015, v_num=0]#015Epoch 1:  19%|â–ˆâ–Š        | 78/420 [00:20<01:31,  3.73it/s, loss=0.977, v_num=0]#015Epoch 1:  19%|â–ˆâ–‰        | 79/420 [00:21<01:31,  3.73it/s, loss=0.977, v_num=0]#015Epoch 1:  19%|â–ˆâ–‰        | 79/420 [00:21<01:31,  3.73it/s, loss=0.975, v_num=0]#015Epoch 1:  19%|â–ˆâ–‰        | 80/420 [00:21<01:31,  3.73it/s, loss=0.975, v_num=0]#015Epoch 1:  19%|â–ˆâ–‰        | 80/420 [00:21<01:31,  3.73it/s, loss=0.964, v_num=0]#015Epoch 1:  19%|â–ˆâ–‰        | 81/420 [00:21<01:30,  3.73it/s, loss=0.964, v_num=0]#015Epoch 1:  19%|â–ˆâ–‰        | 81/420 [00:21<01:30,  3.73it/s, loss=0.985, v_num=0]#015Epoch 1:  20%|â–ˆâ–‰        | 82/420 [00:21<01:30,  3.74it/s, loss=0.985, v_num=0]#015Epoch 1:  20%|â–ˆâ–‰        | 82/420 [00:21<01:30,  3.74it/s, loss=0.996, v_num=0]#015Epoch 1:  20%|â–ˆâ–‰        | 83/420 [00:22<01:30,  3.74it/s, loss=0.996, v_num=0]#015Epoch 1:  20%|â–ˆâ–‰        | 83/420 [00:22<01:30,  3.74it/s, loss=0.994, v_num=0]#015Epoch 1:  20%|â–ˆâ–ˆ        | 84/420 [00:22<01:29,  3.74it/s, loss=0.994, v_num=0]#015Epoch 1:  20%|â–ˆâ–ˆ        | 84/420 [00:22<01:29,  3.74it/s, loss=0.983, v_num=0]#015Epoch 1:  20%|â–ˆâ–ˆ        | 85/420 [00:22<01:29,  3.74it/s, loss=0.983, v_num=0]#015Epoch 1:  20%|â–ˆâ–ˆ        | 85/420 [00:22<01:29,  3.74it/s, loss=0.950, v_num=0]#015Epoch 1:  20%|â–ˆâ–ˆ        | 86/420 [00:22<01:29,  3.74it/s, loss=0.950, v_num=0]#015Epoch 1:  20%|â–ˆâ–ˆ        | 86/420 [00:22<01:29,  3.74it/s, loss=0.963, v_num=0]#015Epoch 1:  21%|â–ˆâ–ˆ        | 87/420 [00:23<01:28,  3.74it/s, loss=0.963, v_num=0]#015Epoch 1:  21%|â–ˆâ–ˆ        | 87/420 [00:23<01:28,  3.74it/s, loss=0.949, v_num=0]#015Epoch 1:  21%|â–ˆâ–ˆ        | 88/420 [00:23<01:28,  3.74it/s, loss=0.949, v_num=0]#015Epoch 1:  21%|â–ˆâ–ˆ        | 88/420 [00:23<01:28,  3.74it/s, loss=0.976, v_num=0]#015Epoch 1:  21%|â–ˆâ–ˆ        | 89/420 [00:23<01:28,  3.74it/s, loss=0.976, v_num=0]#015Epoch 1:  21%|â–ˆâ–ˆ        | 89/420 [00:23<01:28,  3.74it/s, loss=0.977, v_num=0]#015Epoch 1:  21%|â–ˆâ–ˆâ–       | 90/420 [00:24<01:28,  3.75it/s, loss=0.977, v_num=0]#015Epoch 1:  21%|â–ˆâ–ˆâ–       | 90/420 [00:24<01:28,  3.75it/s, loss=0.956, v_num=0]#015Epoch 1:  22%|â–ˆâ–ˆâ–       | 91/420 [00:24<01:27,  3.75it/s, loss=0.956, v_num=0]#015Epoch 1:  22%|â–ˆâ–ˆâ–       | 91/420 [00:24<01:27,  3.75it/s, loss=0.939, v_num=0]#015Epoch 1:  22%|â–ˆâ–ˆâ–       | 92/420 [00:24<01:27,  3.75it/s, loss=0.939, v_num=0]#015Epoch 1:  22%|â–ˆâ–ˆâ–       | 92/420 [00:24<01:27,  3.75it/s, loss=0.926, v_num=0]#015Epoch 1:  22%|â–ˆâ–ˆâ–       | 93/420 [00:24<01:27,  3.75it/s, loss=0.926, v_num=0]#015Epoch 1:  22%|â–ˆâ–ˆâ–       | 93/420 [00:24<01:27,  3.75it/s, loss=0.931, v_num=0]#015Epoch 1:  22%|â–ˆâ–ˆâ–       | 94/420 [00:25<01:26,  3.75it/s, loss=0.931, v_num=0]#015Epoch 1:  22%|â–ˆâ–ˆâ–       | 94/420 [00:25<01:26,  3.75it/s, loss=0.929, v_num=0]#015Epoch 1:  23%|â–ˆâ–ˆâ–Ž       | 95/420 [00:25<01:26,  3.75it/s, loss=0.929, v_num=0]#015Epoch 1:  23%|â–ˆâ–ˆâ–Ž       | 95/420 [00:25<01:26,  3.75it/s, loss=0.930, v_num=0]#015Epoch 1:  23%|â–ˆâ–ˆâ–Ž       | 96/420 [00:25<01:26,  3.75it/s, loss=0.930, v_num=0]#015Epoch 1:  23%|â–ˆâ–ˆâ–Ž       | 96/420 [00:25<01:26,  3.75it/s, loss=0.930, v_num=0]#015Epoch 1:  23%|â–ˆâ–ˆâ–Ž       | 97/420 [00:25<01:25,  3.76it/s, loss=0.930, v_num=0]#015Epoch 1:  23%|â–ˆâ–ˆâ–Ž       | 97/420 [00:25<01:25,  3.76it/s, loss=0.947, v_num=0]#015Epoch 1:  23%|â–ˆâ–ˆâ–Ž       | 98/420 [00:26<01:25,  3.76it/s, loss=0.947, v_num=0]#015Epoch 1:  23%|â–ˆâ–ˆâ–Ž       | 98/420 [00:26<01:25,  3.76it/s, loss=0.952, v_num=0]#015Epoch 1:  24%|â–ˆâ–ˆâ–Ž       | 99/420 [00:26<01:25,  3.76it/s, loss=0.952, v_num=0]#015Epoch 1:  24%|â–ˆâ–ˆâ–Ž       | 99/420 [00:26<01:25,  3.76it/s, loss=0.945, v_num=0]#015Epoch 1:  24%|â–ˆâ–ˆâ–    \u001B[0m\n",
      "\u001B[34m   | 100/420 [00:26<01:25,  3.76it/s, loss=0.945, v_num=0]#015Epoch 1:  24%|â–ˆâ–ˆâ–       | 100/420 [00:26<01:25,  3.76it/s, loss=0.947, v_num=0]#015Epoch 1:  24%|â–ˆâ–ˆâ–       | 101/420 [00:26<01:24,  3.76it/s, loss=0.947, v_num=0]#015Epoch 1:  24%|â–ˆâ–ˆâ–       | 101/420 [00:26<01:24,  3.76it/s, loss=0.951, v_num=0]#015Epoch 1:  24%|â–ˆâ–ˆâ–       | 102/420 [00:27<01:24,  3.76it/s, loss=0.951, v_num=0]#015Epoch 1:  24%|â–ˆâ–ˆâ–       | 102/420 [00:27<01:24,  3.76it/s, loss=0.962, v_num=0]#015Epoch 1:  25%|â–ˆâ–ˆâ–       | 103/420 [00:27<01:24,  3.76it/s, loss=0.962, v_num=0]#015Epoch 1:  25%|â–ˆâ–ˆâ–       | 103/420 [00:27<01:24,  3.76it/s, loss=0.981, v_num=0]#015Epoch 1:  25%|â–ˆâ–ˆâ–       | 104/420 [00:27<01:24,  3.76it/s, loss=0.981, v_num=0]#015Epoch 1:  25%|â–ˆâ–ˆâ–       | 104/420 [00:27<01:24,  3.76it/s, loss=1.006, v_num=0]#015Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 105/420 [00:27<01:23,  3.76it/s, loss=1.006, v_num=0]#015Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 105/420 [00:27<01:23,  3.76it/s, loss=1.011, v_num=0]#015Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 106/420 [00:28<01:23,  3.76it/s, loss=1.011, v_num=0]#015Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 106/420 [00:28<01:23,  3.76it/s, loss=1.004, v_num=0]#015Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 107/420 [00:28<01:23,  3.76it/s, loss=1.004, v_num=0]#015Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 107/420 [00:28<01:23,  3.76it/s, loss=0.978, v_num=0]#015Epoch 1:  26%|â–ˆâ–ˆâ–Œ       | 108/420 [00:28<01:22,  3.76it/s, loss=0.978, v_num=0]#015Epoch 1:  26%|â–ˆâ–ˆâ–Œ       | 108/420 [00:28<01:22,  3.76it/s, loss=0.950, v_num=0]#015Epoch 1:  26%|â–ˆâ–ˆâ–Œ       | 109/420 [00:28<01:22,  3.77it/s, loss=0.950, v_num=0]#015Epoch 1:  26%|â–ˆâ–ˆâ–Œ       | 109/420 [00:28<01:22,  3.77it/s, loss=0.953, v_num=0]#015Epoch 1:  26%|â–ˆâ–ˆâ–Œ       | 110/420 [00:29<01:22,  3.77it/s, loss=0.953, v_num=0]#015Epoch 1:  26%|â–ˆâ–ˆâ–Œ       | 110/420 [00:29<01:22,  3.77it/s, loss=0.953, v_num=0]#015Epoch 1:  26%|â–ˆâ–ˆâ–‹       | 111/420 [00:29<01:21,  3.77it/s, loss=0.953, v_num=0]#015Epoch 1:  26%|â–ˆâ–ˆâ–‹       | 111/420 [00:29<01:21,  3.77it/s, loss=0.955, v_num=0]#015Epoch 1:  27%|â–ˆâ–ˆâ–‹       | 112/420 [00:29<01:21,  3.77it/s, loss=0.955, v_num=0]#015Epoch 1:  27%|â–ˆâ–ˆâ–‹       | 112/420 [00:29<01:21,  3.77it/s, loss=0.957, v_num=0]#015Epoch 1:  27%|â–ˆâ–ˆâ–‹       | 113/420 [00:29<01:21,  3.77it/s, loss=0.957, v_num=0]#015Epoch 1:  27%|â–ˆâ–ˆâ–‹       | 113/420 [00:29<01:21,  3.77it/s, loss=0.951, v_num=0]#015Epoch 1:  27%|â–ˆâ–ˆâ–‹       | 114/420 [00:30<01:21,  3.78it/s, loss=0.951, v_num=0]#015Epoch 1:  27%|â–ˆâ–ˆâ–‹       | 114/420 [00:30<01:21,  3.78it/s, loss=0.949, v_num=0]#015Epoch 1:  27%|â–ˆâ–ˆâ–‹       | 115/420 [00:30<01:20,  3.78it/s, loss=0.949, v_num=0]#015Epoch 1:  27%|â–ˆâ–ˆâ–‹       | 115/420 [00:30<01:20,  3.78it/s, loss=0.946, v_num=0]#015Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 116/420 [00:30<01:20,  3.78it/s, loss=0.946, v_num=0]#015Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 116/420 [00:30<01:20,  3.78it/s, loss=0.947, v_num=0]#015Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 117/420 [00:30<01:20,  3.78it/s, loss=0.947, v_num=0]#015Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 117/420 [00:30<01:20,  3.78it/s, loss=0.949, v_num=0]#015Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 118/420 [00:31<01:19,  3.78it/s, loss=0.949, v_num=0]#015Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 118/420 [00:31<01:19,  3.78it/s, loss=0.945, v_num=0]#015Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 119/420 [00:31<01:19,  3.78it/s, loss=0.945, v_num=0]#015Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 119/420 [00:31<01:19,  3.78it/s, loss=0.951, v_num=0]#015Epoch 1:  29%|â–ˆâ–ˆâ–Š       | 120/420 [00:31<01:19,  3.78it/s, loss=0.951, v_num=0]#015Epoch 1:  29%|â–ˆâ–ˆâ–Š       | 120/420 [00:31<01:19,  3.78it/s, loss=0.941, v_num=0]#015Epoch 1:  29%|â–ˆâ–ˆâ–‰       | 121/420 [00:32<01:19,  3.78it/s, loss=0.941, v_num=0]#015Epoch 1:  29%|â–ˆâ–ˆâ–‰       | 121/420 [00:32<01:19,  3.78it/s, loss=0.927, v_num=0]#015Epoch 1:  29%|â–ˆâ–ˆâ–‰       | 122/420 [00:32<01:18,  3.78it/s, loss=0.927, v_num=0]#015Epoch 1:  29%|â–ˆâ–ˆâ–‰       | 122/420 [00:32<01:18,  3.78it/s, loss=0.913, v_num=0]#015Epoch 1:  29%|â–ˆâ–ˆâ–‰       | 123/420 [00:32<01:18,  3.78it/s, loss=0.913, v_num=0]#015Epoch 1:  29%|â–ˆâ–ˆâ–‰       | 123/420 [00:32<01:18,  3.78it/s, loss=0.893, v_num=0]#015Epoch 1:  30%|â–ˆâ–ˆâ–‰       | 124/420 [00:32<01:18,  3.77it/s, loss=0.893, v_num=0]#015Epoch 1:  30%|â–ˆâ–ˆâ–‰       | 124/420 [00:32<01:18,  3.77it/s, loss=0.892, v_num=0]#015Epoch 1:  30%|â–ˆâ–ˆâ–‰       | 125/420 [00:33<01:18,  3.77it/s, loss=0.892, v_num=0]#015Epoch 1:  30%|â–ˆâ–ˆâ–‰       | 125/420 [00:33<01:18,  3.77it/s, loss=0.864, v_num=0]#015Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 126/420 [00:33<01:17,  3.77it/s, loss=0.864, v_num=0]#015Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 126/420 [00:33<01:17,  3.77it/s, loss=0.842, v_num=0]#015Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 127/420 [00:33<01:17,  3.77it/s, loss=0.842, v_num=0]#015Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 127/420 [00:33<01:17,  3.77it/s, loss=0.840, v_num=0]#015Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 128/420 [00:33<01:17,  3.77it/s, loss=0.840, v_num=0]#015Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 128/420 [00:33<01:17,  3.77it/s, loss=0.854, v_num=0]#015Epoch 1:  31%|â–ˆâ–ˆâ–ˆ       | 129/420 [00:34<01:17,  3.77it/s, loss=0.854, v_num=0]#015Epoch 1:  31%|â–ˆâ–ˆâ–ˆ       | 129/420 [00:34<01:17,  3.77it/s, loss=0.839, v_num=0]#015Epoch 1:  31%|â–ˆâ–ˆâ–ˆ       | 130/420 [00:34<01:16,  3.77it/s, loss=0.839, v_num=0]#015Epoch 1:  31%|â–ˆâ–ˆâ–ˆ       | 130/420 [00:34<01:16,  3.77it/s, loss=0.825, v_num=0]#015Epoch 1:  31%|â–ˆâ–ˆâ–ˆ       | 131/420 [00:34<01:16,  3.77it/s, loss=0.825, v_num=0]#015Epoch 1:  31%|â–ˆâ–ˆâ–ˆ       | 131/420 [00:34<01:16,  3.77it/s, loss=0.832, v_num=0]#015Epoch 1:  31%|â–ˆâ–ˆâ–ˆâ–      | 132/420 [00:34<01:16,  3.77it/s, loss=0.832, v_num=0]#015Epoch 1:  31%|â–ˆâ–ˆâ–ˆâ–      | 132/420 [00:34<01:16,  3.77it/s, loss=0.837, v_num=0]#015Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 133/420 [00:35<01:16,  3.77it/s, loss=0.837, v_num=0]#015Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 133/420 [00:35<01:16,  3.77it/s, loss=0.836, v_num=0]#015Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 134/420 [00:35<01:15,  3.77it/s, loss=0.836, v_num=0]#015Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 134/420 [00:35<01:15,  3.77it/s, loss=0.852, v_num=0]#015Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 135/420 [00:35<01:15,  3.77it/s, loss=0.852, v_num=0]#015Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 135/420 [00:35<01:15,  3.77it/s, loss=0.835, v_num=0]#015Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 136/420 [00:36<01:15,  3.77it/s, loss=0.835, v_num=0]#015Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 136/420 [00:36<01:15,  3.77it/s, loss=0.827, v_num=0]#015Epoch 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 137/420 [00:36<01:15,  3.77it/s, loss=0.827, v_num=0]#015Epoch 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 137/420 [00:36<01:15,  3.77it/s, loss=0.822, v_num=0]#015Epoch 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 138/420 [00:36<01:14,  3.77it/s, loss=0.822, v_num=0]#015Epoch 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 138/420 [00:36<01:14,  3.77it/s, loss=0.832, v_num=0]#015Epoch 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 139/420 [00:36<01:14,  3.77it/s, loss=0.832, v_num=0]#015Epoch 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 139/420 [00:36<01:14,  3.77it/s, loss=0.816, v_num=0]#015Epoch 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 140/420 [00:37<01:14,  3.77it/s, loss=0.816, v_num=0]#015Epoch 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 140/420 [00:37<01:14,  3.77it/s, loss=0.814, v_num=0]#015Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 141/420 [00:37<01:14,  3.77it/s, loss=0.814, v_num=0]#015Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 141/420 [00:37<01:14,  3.77it/s, loss=0.803, v_num=0]#015Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 142/420 [00:37<01:13,  3.77it/s, loss=0.803, v_num=0]#015Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 142/420 [00:37<01:13,  3.77it/s, loss=0.825, v_num=0]#015Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 143/420 [00:37<01:13,  3.77it/s, loss=0.825, v_num=0]#015Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 143/420 [00:37<01:13,  3.77it/s, loss=0.839, v_num=0]#015Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 144/420 [00:38<01:13,  3.77it/s, loss=0.839, v_num=0]#015Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 144/420 [00:38<01:13,  3.77it/s, loss=0.801, v_num=0]#015Epoch 1:  35%|â–ˆâ–ˆâ–ˆâ–      | 145/420 [00:38<01:13,  3.77it/s, loss=0.801, v_num=0]#015Epoch 1:  35%|â–ˆâ–ˆâ–ˆâ–      | 145/420 [00:38<01:13,  3.77it/s, loss=0.830, v_num=0]#015Epoch 1:  35%|â–ˆâ–ˆâ–ˆâ–      | 146/420 [00:38<01:12,  3.77it/s, loss=0.830, v_num=0]#015Epoch 1:  35%|â–ˆâ–ˆâ–ˆâ–      | 146/420 [00:38<01:12,  3.77it/s, loss=0.863, v_num=0]#015Epoch 1:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 147/420 [00:39<01:12,  3.77it/s, loss=0.863, v_num=0]#015Epoch 1:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 147/420 [00:39<01:12,  3.77it/s, loss=0.903, v_num=0]#015Epoch 1:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 148/420 [00:39<01:12,  3.76it/s, loss=0.903, v_num=0]#015Epoch 1:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 148/420 [00:39<01:12,  3.76it/s, loss=0.889, v_num=0]#015Epoch 1:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 149/420 [00:39<01:11,  3.76it/s, loss=0.889, v_num=0]#015Epoch 1:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 149/420 [00:39<01:11,  3.76it/s, loss=0.902, v_num=0]#015Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 150/420 [00:39<01:11,  3.76it/s, loss=0.902, v_num=0]#015Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 150/420 [00:39<01:11,  3.76it/s, loss=0.918, v_num=0]#015Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 151/420 [00:40<01:11,  3.76it/s, loss=0.918, v_num=0]#015Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 151/420 [00:40<01:11,  3.76it/s, loss=0.914, v_num=0]#015Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 152/420 [00:40<01:11,  3.76it/s, loss=0.914, v_num=0]#015Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 152/420 [00:40<01:11,  3.76it/s, loss=0.896, v_num=0]#015Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 153/420 [00:40<01:10,  3.76it/s, loss=0.896, v_num=0]#015Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 153/420 [00:40<01:10,  3.76it/s, loss=0.903, v_num=0]#015Epoch 1:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 154/420 [00:40<01:10,  3.76it/s, loss=0.903, v_num=0]#015Epoch 1:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 154/420 [00:40<01:10,  3.76it/s, loss=0.930, v_num=0]#015Epoch 1:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 155/420 [00:41<01:10,  3.76it/s, loss=0.930, v_num=0]#015Epoch 1:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 155/420 [00:41<01:10,  3.76it/s, loss=0.952, v_num=0]#015Epoch 1:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 156/420 [00:41<01:10,  3.76it/s, loss=0.952, v_num=0]#015Epoch 1:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 156/420 [00:41<01:10,  3.76it/s, loss=0.954, v_num=0]#015Epoch 1:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 157/420 [00:41<01:09,  3.76it/s, loss=0.954, v_num=0]#015Epoch 1:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 157/420 [00:41<01:09,  3.76it/s, loss=0.950, v_num=0]#015Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 158/420 [00:41<01:09,  3.77it/s, loss=0.950, v_num=0]#015Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 158/420 [00:41<01:09,  3.77it/s, loss=0.933, v_num=0]#015Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 159/420 [00:42<01:09,  3.77it/s, loss=0.933, v_num=0]#015Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 159/420 [00:42<01:09,  3.77it/s, loss=0.946, v_num=0]#015Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 160/420 [00:42<01:08,  3.77it/s, loss=0.946, v_num=0]#015Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 160/420 [00:42<01:08,  3.77it/s, loss=0.958, v_num=0]#015Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 161/420 [00:42<01:08,  3.77it/s, loss=0.958, v_num=0]#015Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 161/420 [00:42<01:08,  3.77it/s, loss=0.960, v_num=0]#015Epoch 1:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 162/420 [00:42<01:08,  3.77it/s, loss=0.960, v_num=0]#015Epoch 1:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 162/420 [00:42<01:08,  3.77it/s, loss=0.943, v_num=0]#015Epoch 1:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 163/420 [00:43<01:08,  3.77it/s, loss=0.943, v_num=0]#015Epoch 1:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 163/420 [00:43<01:08,  3.77it/s, loss=0.926, v_num=0]#015Epoch 1:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 164/420 [00:43<01:07,  3.77it/s, loss=0.926, v_num=0]#015Epoch 1:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 164/420 [00:43<01:07,  3.77it/s, loss=0.953, v_num=0]#015Epoch 1:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 165/420 [00:43<01:07,  3.77it/s, loss=0.953, v_num=0]#015Epoch 1:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 165/420 [00:43<01:07,  3.77it/s, loss=0.938, v_num=0]#015Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 166/420 [00:43<01:07,  3.77it/s, loss=0.938, v_num=0]#015Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 166/420 [00:43<01:07,  3.77it/s, loss=0.916, v_num=0]#015Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 167/420 [00:44<01:06,  3.78it/s, loss=0.916, v_num=0]#015Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 167/420 [00:44<01:06,  3.78it/s, loss=0.890, v_num=0]#015Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 168/420 [00:44<01:06,  3.78it/s, loss=0.890, v_num=0]#015Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 168/420 [00:44<01:06,  3.78it/s, loss=0.891, v_num=0]#015Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 169/420 [00:44<01:06,  3.78it/s, loss=0.891, v_num=0]#015Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 169/420 [00:44<01:06,  3.78it/s, loss=0.882, v_num=0]#015Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 170/420 [00:44<01:06,  3.78it/s, loss=0.882, v_num=0]#015Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 170/420 [00:44<01:06,  3.78it/s, loss=0.872, v_num=0]#015Epoch 1:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 171/420 [00:45<01:05,  3.78it/s, loss=0.872, v_num=0]#015Epoch 1:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 171/420 [00:45<01:05,  3.78it/s, loss=0.872, v_num=0]#015Epoch 1:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 172/420 [00:45<01:05,  3.79it/s, loss=0.872, v_num=0]#015Epoch 1:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 172/420 [00:45<01:05,  3.79it/s, loss=0.884, v_num=0]#015Epoch 1:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 173/420 [00:45<01:05,  3.79it/s, loss=0.884, v_num=0]#015Epoch 1:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 173/420 [00:45<01:05,  3.79it/s, loss=0.928, v_num=0]#015Epoch 1:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 174/420 [00:45<01:04,  3.79it/s, loss=0.928, v_num=0]#015Epoch 1:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 174/420 [00:45<01:04,  3.79it/s, loss=0.894, v_num=0]#015Epoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 175/420 [00:46<01:04,  3.79it/s, loss=0.894, v_num=0]#015Epoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 175/420 [00:46<01:04,  3.79it/s, loss=0.922, v_num=0]#015Epoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 176/420 [00:46<01:04,  3.79it/s, loss=0.922, v_num=0]#015Epoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 176/420 [00:46<01:04,  3.79it/s, loss=0.933, v_num=0]#015Epoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 177/420 [00:46<01:04,  3.79it/s, loss=0.933, v_num=0]#015Epoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 177/420 [00:46<01:04,  3.79it/s, loss=0.929, v_num=0]#015Epoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 178/420 [00:46<01:03,  3.79it/s, loss=0.929, v_num=0]#015Epoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 178/420 [00:46<01:03,  3.79it/s, loss=0.947, v_num=0]#015Epoch 1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 179/420 [00:47<01:03,  3.80it/s, loss=0.947, v_num=0]#015Epoch 1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 179/420 [00:47<01:03,  3.80it/s, loss=0.939, v_num=0]#015Epoch 1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 180/420 [00:47<01:03,  3.80it/s, loss=0.939, v_num=0]#015Epoch 1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 180/420 [00:47<01:03,  3.80it/s, loss=0.946, v_num=0]#015Epoch 1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 181/420 [00:47<01:02,  3.80it/s, loss=0.946, v_num=0]#015Epoch 1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 181/420 [00:47<01:02,  3.80it/s, loss=0.940, v_num=0]#015Epoch 1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 182/420 [00:47<01:02,  3.80it/s, loss=0.940, v_num=0]#015Epoch 1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 182/420 [00:47<01:02,  3.80it/s, loss=0.923, v_num=0]#015Epoch 1:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 183/420 [00:48<01:02,  3.80it/s, loss=0.923, v_num=0]#015Epoch 1:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 183/420 [00:48<01:02,  3.80it/s, loss=0.927, v_num=0]#015Epoch 1:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 184/420 [00:48<01:02,  3.80it/s, loss=0.927, v_num=0]#015Epoch 1:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 184/420 [00:48<01:02,  3.80it/s, loss=0.917, v_num=0]#015Epoch 1:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 185/420 [00:48<01:01,  3.81it/s, loss=0.917, v_num=0]#015Epoch 1:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 185/420 [00:48<01:01,  3.81it/s, loss=0.923, v_num=0]#015Epoch 1:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 186/420 [00:48<01:01,  3.81it/s, loss=0.923, v_num=0]#015Epoch 1:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 186/420 [00:48<01:01,  3.81it/s, loss=0.923, v_num=0]#015Epoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 187/420 [00:49<01:01,  3.81it/s, loss=0.923, v_num=0]#015Epoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 187/420 [00:49<01:01,  3.81it/s, loss=0.918, v_num=0]#015Epoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 188/420 [00:49<01:00,  3.81it/s, loss=0.918, v_num=0]#015Epoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 188/420 [00:49<01:00,  3.81it/s, loss=0.897, v_num=0]#015Epoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 189/420 [00:49<01:00,  3.81it/s, loss=0.897, v_num=0]#015Epoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 189/420 [00:49<01:00,  3.81it/s, loss=0.903, v_num=0]#015Epoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 190/420 [00:49<01:00,  3.81it/s, loss=0.903, v_num=0]#015Epoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 190/420 [00:49<01:00,  3.81it/s, loss=0.900, v_num=0]#015Epoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 191/420 [00:50<01:00,  3.81it/s, loss=0.900, v_num=0]#015Epoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 191/420 [00:50<01:00,  3.81it/s, loss=0.911, v_num=0]#015Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 192/420 [00:50<00:59,  3.81it/s, loss=0.911, v_num=0]#015Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 192/420 [00:50<00:59,  3.81it/s, loss=0.914, v_num=0]#015Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 193/420 [00:50<00:59,  3.81it/s, loss=0.914, v_num=0]#015Epoch\u001B[0m\n",
      "\u001B[34m 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 193/420 [00:50<00:59,  3.81it/s, loss=0.838, v_num=0]#015Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 194/420 [00:50<00:59,  3.81it/s, loss=0.838, v_num=0]#015Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 194/420 [00:50<00:59,  3.81it/s, loss=0.818, v_num=0]#015Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 195/420 [00:51<00:59,  3.81it/s, loss=0.818, v_num=0]#015Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 195/420 [00:51<00:59,  3.81it/s, loss=0.785, v_num=0]#015Epoch 1:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 196/420 [00:51<00:58,  3.80it/s, loss=0.785, v_num=0]#015Epoch 1:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 196/420 [00:51<00:58,  3.80it/s, loss=0.765, v_num=0]#015Epoch 1:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 197/420 [00:51<00:58,  3.80it/s, loss=0.765, v_num=0]#015Epoch 1:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 197/420 [00:51<00:58,  3.80it/s, loss=0.766, v_num=0]#015Epoch 1:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 198/420 [00:52<00:58,  3.81it/s, loss=0.766, v_num=0]#015Epoch 1:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 198/420 [00:52<00:58,  3.81it/s, loss=0.753, v_num=0]#015Epoch 1:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 199/420 [00:52<00:58,  3.81it/s, loss=0.753, v_num=0]#015Epoch 1:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 199/420 [00:52<00:58,  3.81it/s, loss=0.754, v_num=0]#015Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 200/420 [00:52<00:57,  3.81it/s, loss=0.754, v_num=0]#015Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 200/420 [00:52<00:57,  3.81it/s, loss=0.744, v_num=0]#015Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 201/420 [00:52<00:57,  3.81it/s, loss=0.744, v_num=0]#015Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 201/420 [00:52<00:57,  3.81it/s, loss=0.747, v_num=0]#015Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 202/420 [00:53<00:57,  3.81it/s, loss=0.747, v_num=0]#015Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 202/420 [00:53<00:57,  3.81it/s, loss=0.757, v_num=0]#015Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 203/420 [00:53<00:57,  3.81it/s, loss=0.757, v_num=0]#015Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 203/420 [00:53<00:57,  3.81it/s, loss=0.756, v_num=0]#015Epoch 1:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 204/420 [00:53<00:56,  3.81it/s, loss=0.756, v_num=0]#015Epoch 1:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 204/420 [00:53<00:56,  3.81it/s, loss=0.792, v_num=0]#015Epoch 1:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 205/420 [00:53<00:56,  3.81it/s, loss=0.792, v_num=0]#015Epoch 1:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 205/420 [00:53<00:56,  3.81it/s, loss=0.790, v_num=0]#015Epoch 1:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 206/420 [00:54<00:56,  3.81it/s, loss=0.790, v_num=0]#015Epoch 1:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 206/420 [00:54<00:56,  3.81it/s, loss=0.792, v_num=0]#015Epoch 1:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 207/420 [00:54<00:55,  3.81it/s, loss=0.792, v_num=0]#015Epoch 1:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 207/420 [00:54<00:55,  3.81it/s, loss=0.795, v_num=0]#015Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 208/420 [00:54<00:55,  3.81it/s, loss=0.795, v_num=0]#015Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 208/420 [00:54<00:55,  3.81it/s, loss=0.812, v_num=0]#015Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 209/420 [00:54<00:55,  3.81it/s, loss=0.812, v_num=0]#015Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 209/420 [00:54<00:55,  3.81it/s, loss=0.795, v_num=0]#015Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 210/420 [00:55<00:55,  3.81it/s, loss=0.795, v_num=0]#015Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 210/420 [00:55<00:55,  3.81it/s, loss=0.807, v_num=0]#015Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 211/420 [00:55<00:54,  3.81it/s, loss=0.807, v_num=0]#015Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 211/420 [00:55<00:54,  3.81it/s, loss=0.809, v_num=0]#015Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 212/420 [00:55<00:54,  3.81it/s, loss=0.809, v_num=0]#015Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 212/420 [00:55<00:54,  3.81it/s, loss=0.798, v_num=0]#015Epoch 1:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 213/420 [00:55<00:54,  3.81it/s, loss=0.798, v_num=0]#015Epoch 1:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 213/420 [00:55<00:54,  3.81it/s, loss=0.848, v_num=0]#015Epoch 1:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 214/420 [00:56<00:54,  3.81it/s, loss=0.848, v_num=0]#015Epoch 1:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 214/420 [00:56<00:54,  3.81it/s, loss=0.858, v_num=0]#015Epoch 1:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 215/420 [00:56<00:53,  3.81it/s, loss=0.858, v_num=0]#015Epoch 1:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 215/420 [00:56<00:53,  3.81it/s, loss=0.850, v_num=0]#015Epoch 1:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 216/420 [00:56<00:53,  3.81it/s, loss=0.850, v_num=0]#015Epoch 1:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 216/420 [00:56<00:53,  3.81it/s, loss=0.861, v_num=0]#015Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 217/420 [00:56<00:53,  3.81it/s, loss=0.861, v_num=0]#015Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 217/420 [00:56<00:53,  3.81it/s, loss=0.873, v_num=0]#015Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 218/420 [00:57<00:53,  3.81it/s, loss=0.873, v_num=0]#015Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 218/420 [00:57<00:53,  3.81it/s, loss=0.863, v_num=0]#015Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 219/420 [00:57<00:52,  3.81it/s, loss=0.863, v_num=0]#015Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 219/420 [00:57<00:52,  3.81it/s, loss=0.885, v_num=0]#015Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 220/420 [00:57<00:52,  3.81it/s, loss=0.885, v_num=0]#015Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 220/420 [00:57<00:52,  3.81it/s, loss=0.883, v_num=0]#015Epoch 1:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 221/420 [00:58<00:52,  3.81it/s, loss=0.883, v_num=0]#015Epoch 1:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 221/420 [00:58<00:52,  3.81it/s, loss=0.876, v_num=0]#015Epoch 1:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 222/420 [00:58<00:52,  3.80it/s, loss=0.876, v_num=0]#015Epoch 1:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 222/420 [00:58<00:52,  3.80it/s, loss=0.881, v_num=0]#015Epoch 1:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 223/420 [00:58<00:51,  3.80it/s, loss=0.881, v_num=0]#015Epoch 1:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 223/420 [00:58<00:51,  3.80it/s, loss=0.885, v_num=0]#015Epoch 1:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 224/420 [00:58<00:51,  3.80it/s, loss=0.885, v_num=0]#015Epoch 1:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 224/420 [00:58<00:51,  3.80it/s, loss=0.887, v_num=0]#015Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 225/420 [00:59<00:51,  3.80it/s, loss=0.887, v_num=0]#015Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 225/420 [00:59<00:51,  3.80it/s, loss=0.871, v_num=0]#015Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 226/420 [00:59<00:51,  3.80it/s, loss=0.871, v_num=0]#015Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 226/420 [00:59<00:51,  3.80it/s, loss=0.873, v_num=0]#015Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 227/420 [00:59<00:50,  3.80it/s, loss=0.873, v_num=0]#015Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 227/420 [00:59<00:50,  3.80it/s, loss=0.880, v_num=0]#015Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 228/420 [00:59<00:50,  3.80it/s, loss=0.880, v_num=0]#015Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 228/420 [00:59<00:50,  3.80it/s, loss=0.887, v_num=0]#015Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 229/420 [01:00<00:50,  3.80it/s, loss=0.887, v_num=0]#015Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 229/420 [01:00<00:50,  3.80it/s, loss=0.928, v_num=0]#015Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 230/420 [01:00<00:49,  3.80it/s, loss=0.928, v_num=0]#015Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 230/420 [01:00<00:49,  3.80it/s, loss=0.940, v_num=0]#015Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 231/420 [01:00<00:49,  3.80it/s, loss=0.940, v_num=0]#015Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 231/420 [01:00<00:49,  3.80it/s, loss=0.920, v_num=0]#015Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 232/420 [01:00<00:49,  3.80it/s, loss=0.920, v_num=0]#015Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 232/420 [01:00<00:49,  3.80it/s, loss=0.926, v_num=0]#015Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 233/420 [01:01<00:49,  3.80it/s, loss=0.926, v_num=0]#015Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 233/420 [01:01<00:49,  3.80it/s, loss=0.900, v_num=0]#015Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 234/420 [01:01<00:48,  3.80it/s, loss=0.900, v_num=0]#015Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 234/420 [01:01<00:48,  3.80it/s, loss=0.942, v_num=0]#015Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 235/420 [01:01<00:48,  3.80it/s, loss=0.942, v_num=0]#015Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 235/420 [01:01<00:48,  3.80it/s, loss=0.959, v_num=0]#015Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 236/420 [01:02<00:48,  3.80it/s, loss=0.959, v_num=0]#015Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 236/420 [01:02<00:48,  3.80it/s, loss=0.959, v_num=0]#015Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 237/420 [01:02<00:48,  3.80it/s, loss=0.959, v_num=0]#015Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 237/420 [01:02<00:48,  3.80it/s, loss=0.950, v_num=0]#015Epoch 1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 238/420 [01:02<00:47,  3.80it/s, loss=0.950, v_num=0]#015Epoch 1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 238/420 [01:02<00:47,  3.80it/s, loss=0.962, v_num=0]#015Epoch 1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 239/420 [01:02<00:47,  3.80it/s, loss=0.962, v_num=0]#015Epoch 1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 239/420 [01:02<00:47,  3.80it/s, loss=0.935, v_num=0]#015Epoch 1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 240/420 [01:03<00:47,  3.80it/s, loss=0.935, v_num=0]#015Epoch 1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 240/420 [01:03<00:47,  3.80it/s, loss=0.946, v_num=0]#015Epoch 1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 241/420 [01:03<00:47,  3.80it/s, loss=0.946, v_num=0]#015Epoch 1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 241/420 [01:03<00:47,  3.80it/s, loss=0.955, v_num=0]#015Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 242/420 [01:03<00:46,  3.80it/s, loss=0.955, v_num=0]#015Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 242/420 [01:03<00:46,  3.80it/s, loss=1.005, v_num=0]#015Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 243/420 [01:03<00:46,  3.80it/s, loss=1.005, v_num=0]#015Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 243/420 [01:03<00:46,  3.80it/s, loss=1.014, v_num=0]#015Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 244/420 [01:04<00:46,  3.80it/s, loss=1.014, v_num=0]#015Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 244/420 [01:04<00:46,  3.80it/s, loss=0.975, v_num=0]#015Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 245/420 [01:04<00:45,  3.80it/s, loss=0.975, v_num=0]#015Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 245/420 [01:04<00:45,  3.80it/s, loss=0.982, v_num=0]#015Epoch 1:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 246/420 [01:04<00:45,  3.81it/s, loss=0.982, v_num=0]#015Epoch 1:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 246/420 [01:04<00:45,  3.81it/s, loss=0.965, v_num=0]#015Epoch 1:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 247/420 [01:04<00:45,  3.81it/s, loss=0.965, v_num=0]#015Epoch 1:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 247/420 [01:04<00:45,  3.81it/s, loss=0.970, v_num=0]#015Epoch 1:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 248/420 [01:05<00:45,  3.81it/s, loss=0.970, v_num=0]#015Epoch 1:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 248/420 [01:05<00:45,  3.81it/s, loss=0.960, v_num=0]#015Epoch 1:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 249/420 [01:05<00:44,  3.81it/s, loss=0.960, v_num=0]#015Epoch 1:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 249/420 [01:05<00:44,  3.81it/s, loss=0.943, v_num=0]#015Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 250/420 [01:05<00:44,  3.81it/s, loss=0.943, v_num=0]#015Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 250/420 [01:05<00:44,  3.81it/s, loss=0.934, v_num=0]#015Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 251/420 [01:05<00:44,  3.81it/s, loss=0.934, v_num=0]#015Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 251/420 [01:05<00:44,  3.81it/s, loss=0.951, v_num=0]#015Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 252/420 [01:06<00:44,  3.81it/s, loss=0.951, v_num=0]#015Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 252/420 [01:06<00:44,  3.81it/s, loss=0.944, v_num=0]#015Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 253/420 [01:06<00:43,  3.81it/s, loss=0.944, v_num=0]#015Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 253/420 [01:06<00:43,  3.81it/s, loss=0.929, v_num=0]#015Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 254/420 [01:06<00:43,  3.81it/s, loss=0.929, v_num=0]#015Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 254/420 [01:06<00:43,  3.81it/s, loss=0.897, v_num=0]#015Epoch 1:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 255/420 [01:07<00:43,  3.81it/s, loss=0.897, v_num=0]#015Epoch 1:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 255/420 [01:07<00:43,  3.81it/s, loss=0.879, v_num=0]#015Epoch 1:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 256/420 [01:07<00:43,  3.81it/s, loss=0.879, v_num=0]#015Epoch 1:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 256/420 [01:07<00:43,  3.81it/s, loss=0.865, v_num=0]#015Epoch 1:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 257/420 [01:07<00:42,  3.81it/s, loss=0.865, v_num=0]#015Epoch 1:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 257/420 [01:07<00:42,  3.81it/s, loss=0.850, v_num=0]#015Epoch 1:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 258/420 [01:07<00:42,  3.81it/s, loss=0.850, v_num=0]#015Epoch 1:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 258/420 [01:07<00:42,  3.81it/s, loss=0.851, v_num=0]#015Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 259/420 [01:08<00:42,  3.81it/s, loss=0.851, v_num=0]#015Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 259/420 [01:08<00:42,  3.81it/s, loss=0.872, v_num=0]#015Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 260/420 [01:08<00:42,  3.81it/s, loss=0.872, v_num=0]#015Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 260/420 [01:08<00:42,  3.81it/s, loss=0.863, v_num=0]#015Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 261/420 [01:08<00:41,  3.81it/s, loss=0.863, v_num=0]#015Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 261/420 [01:08<00:41,  3.81it/s, loss=0.856, v_num=0]#015Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 262/420 [01:08<00:41,  3.81it/s, loss=0.856, v_num=0]#015Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 262/420 [01:08<00:41,  3.81it/s, loss=0.787, v_num=0]#015Epoch 1:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 263/420 [01:09<00:41,  3.80it/s, loss=0.787, v_num=0]#015Epoch 1:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 263/420 [01:09<00:41,  3.80it/s, loss=0.790, v_num=0]#015Epoch 1:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 264/420 [01:09<00:40,  3.81it/s, loss=0.790, v_num=0]#015Epoch 1:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 264/420 [01:09<00:40,  3.81it/s, loss=0.778, v_num=0]#015Epoch 1:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 265/420 [01:09<00:40,  3.81it/s, loss=0.778, v_num=0]#015Epoch 1:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 265/420 [01:09<00:40,  3.81it/s, loss=0.783, v_num=0]#015Epoch 1:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 266/420 [01:09<00:40,  3.81it/s, loss=0.783, v_num=0]#015Epoch 1:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 266/420 [01:09<00:40,  3.81it/s, loss=0.799, v_num=0]#015Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 267/420 [01:10<00:40,  3.81it/s, loss=0.799, v_num=0]#015Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 267/420 [01:10<00:40,  3.81it/s, loss=0.780, v_num=0]#015Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 268/420 [01:10<00:39,  3.81it/s, loss=0.780, v_num=0]#015Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 268/420 [01:10<00:39,  3.81it/s, loss=0.845, v_num=0]#015Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 269/420 [01:10<00:39,  3.81it/s, loss=0.845, v_num=0]#015Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 269/420 [01:10<00:39,  3.81it/s, loss=0.815, v_num=0]#015Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 270/420 [01:10<00:39,  3.81it/s, loss=0.815, v_num=0]#015Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 270/420 [01:10<00:39,  3.81it/s, loss=0.824, v_num=0]#015Epoch 1:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 271/420 [01:11<00:39,  3.81it/s, loss=0.824, v_num=0]#015Epoch 1:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 271/420 [01:11<00:39,  3.81it/s, loss=0.816, v_num=0]#015Epoch 1:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 272/420 [01:11<00:38,  3.81it/s, loss=0.816, v_num=0]#015Epoch 1:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 272/420 [01:11<00:38,  3.81it/s, loss=0.832, v_num=0]#015Epoch 1:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 273/420 [01:11<00:38,  3.81it/s, loss=0.832, v_num=0]#015Epoch 1:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 273/420 [01:11<00:38,  3.81it/s, loss=0.844, v_num=0]#015Epoch 1:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 274/420 [01:11<00:38,  3.81it/s, loss=0.844, v_num=0]#015Epoch 1:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 274/420 [01:11<00:38,  3.81it/s, loss=0.825, v_num=0]#015Epoch 1:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 275/420 [01:12<00:38,  3.81it/s, loss=0.825, v_num=0]#015Epoch 1:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 275/420 [01:12<00:38,  3.81it/s, loss=0.818, v_num=0]#015Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 276/420 [01:12<00:37,  3.81it/s, loss=0.818, v_num=0]#015Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 276/420 [01:12<00:37,  3.81it/s, loss=0.838, v_num=0]#015Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 277/420 [01:12<00:37,  3.80it/s, loss=0.838, v_num=0]#015Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 277/420 [01:12<00:37,  3.80it/s, loss=0.866, v_num=0]#015Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 278/420 [01:13<00:37,  3.81it/s, loss=0.866, v_num=0]#015Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 278/420 [01:13<00:37,  3.80it/s, loss=0.853, v_num=0]#015Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 279/420 [01:13<00:37,  3.80it/s, loss=0.853, v_num=0]#015Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 279/420 [01:13<00:37,  3.80it/s, loss=0.833, v_num=0]#015Epoch 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 280/420 [01:13<00:36,  3.80it/s, loss=0.833, v_num=0]#015Epoch 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 280/420 [01:13<00:36,  3.80it/s, loss=0.830, v_num=0]#015Epoch 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 281/420 [01:13<00:36,  3.80it/s, loss=0.830, v_num=0]#015Epoch 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 281/420 [01:13<00:36,  3.80it/s, loss=0.844, v_num=0]#015Epoch 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 282/420 [01:14<00:36,  3.80it/s, loss=0.844, v_num=0]#015Epoch\u001B[0m\n",
      "\u001B[34m 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 282/420 [01:14<00:36,  3.80it/s, loss=0.859, v_num=0]#015Epoch 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 283/420 [01:14<00:36,  3.80it/s, loss=0.859, v_num=0]#015Epoch 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 283/420 [01:14<00:36,  3.80it/s, loss=0.835, v_num=0]#015Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 284/420 [01:14<00:35,  3.80it/s, loss=0.835, v_num=0]#015Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 284/420 [01:14<00:35,  3.80it/s, loss=0.843, v_num=0]#015Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 285/420 [01:14<00:35,  3.80it/s, loss=0.843, v_num=0]#015Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 285/420 [01:14<00:35,  3.80it/s, loss=0.843, v_num=0]#015Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 286/420 [01:15<00:35,  3.80it/s, loss=0.843, v_num=0]#015Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 286/420 [01:15<00:35,  3.80it/s, loss=0.825, v_num=0]#015Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 287/420 [01:15<00:35,  3.80it/s, loss=0.825, v_num=0]#015Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 287/420 [01:15<00:35,  3.80it/s, loss=0.839, v_num=0]#015Epoch 1:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 288/420 [01:15<00:34,  3.80it/s, loss=0.839, v_num=0]#015Epoch 1:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 288/420 [01:15<00:34,  3.80it/s, loss=0.767, v_num=0]#015Epoch 1:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 289/420 [01:16<00:34,  3.80it/s, loss=0.767, v_num=0]#015Epoch 1:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 289/420 [01:16<00:34,  3.80it/s, loss=0.775, v_num=0]#015Epoch 1:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 290/420 [01:16<00:34,  3.80it/s, loss=0.775, v_num=0]#015Epoch 1:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 290/420 [01:16<00:34,  3.80it/s, loss=0.751, v_num=0]#015Epoch 1:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 291/420 [01:16<00:33,  3.79it/s, loss=0.751, v_num=0]#015Epoch 1:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 291/420 [01:16<00:33,  3.79it/s, loss=0.739, v_num=0]#015Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 292/420 [01:16<00:33,  3.80it/s, loss=0.739, v_num=0]#015Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 292/420 [01:16<00:33,  3.80it/s, loss=0.720, v_num=0]#015Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 293/420 [01:17<00:33,  3.79it/s, loss=0.720, v_num=0]#015Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 293/420 [01:17<00:33,  3.79it/s, loss=0.716, v_num=0]#015Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 294/420 [01:17<00:33,  3.79it/s, loss=0.716, v_num=0]#015Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 294/420 [01:17<00:33,  3.79it/s, loss=0.725, v_num=0]#015Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 295/420 [01:17<00:32,  3.79it/s, loss=0.725, v_num=0]#015Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 295/420 [01:17<00:32,  3.79it/s, loss=0.728, v_num=0]#015Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 296/420 [01:18<00:32,  3.79it/s, loss=0.728, v_num=0]#015Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 296/420 [01:18<00:32,  3.79it/s, loss=0.721, v_num=0]#015Epoch 1:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 297/420 [01:18<00:32,  3.79it/s, loss=0.721, v_num=0]#015Epoch 1:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 297/420 [01:18<00:32,  3.79it/s, loss=0.716, v_num=0]#015Epoch 1:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 298/420 [01:18<00:32,  3.79it/s, loss=0.716, v_num=0]#015Epoch 1:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 298/420 [01:18<00:32,  3.79it/s, loss=0.726, v_num=0]#015Epoch 1:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 299/420 [01:18<00:31,  3.79it/s, loss=0.726, v_num=0]#015Epoch 1:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 299/420 [01:18<00:31,  3.79it/s, loss=0.727, v_num=0]#015Epoch 1:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 300/420 [01:19<00:31,  3.79it/s, loss=0.727, v_num=0]#015Epoch 1:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 300/420 [01:19<00:31,  3.79it/s, loss=0.734, v_num=0]#015Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 301/420 [01:19<00:31,  3.79it/s, loss=0.734, v_num=0]#015Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 301/420 [01:19<00:31,  3.79it/s, loss=0.728, v_num=0]#015Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 302/420 [01:19<00:31,  3.79it/s, loss=0.728, v_num=0]#015Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 302/420 [01:19<00:31,  3.79it/s, loss=0.730, v_num=0]#015Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 303/420 [01:19<00:30,  3.79it/s, loss=0.730, v_num=0]#015Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 303/420 [01:19<00:30,  3.79it/s, loss=0.765, v_num=0]#015Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 304/420 [01:20<00:30,  3.79it/s, loss=0.765, v_num=0]#015Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 304/420 [01:20<00:30,  3.79it/s, loss=0.796, v_num=0]#015Epoch 1:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 305/420 [01:20<00:30,  3.79it/s, loss=0.796, v_num=0]#015Epoch 1:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 305/420 [01:20<00:30,  3.79it/s, loss=0.797, v_num=0]#015Epoch 1:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 306/420 [01:20<00:30,  3.79it/s, loss=0.797, v_num=0]#015Epoch 1:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 306/420 [01:20<00:30,  3.79it/s, loss=0.810, v_num=0]#015Epoch 1:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 307/420 [01:20<00:29,  3.79it/s, loss=0.810, v_num=0]#015Epoch 1:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 307/420 [01:20<00:29,  3.79it/s, loss=0.817, v_num=0]#015Epoch 1:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 308/420 [01:21<00:29,  3.79it/s, loss=0.817, v_num=0]#015Epoch 1:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 308/420 [01:21<00:29,  3.79it/s, loss=0.821, v_num=0]#015Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 309/420 [01:21<00:29,  3.79it/s, loss=0.821, v_num=0]#015Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 309/420 [01:21<00:29,  3.79it/s, loss=0.819, v_num=0]#015Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 310/420 [01:21<00:29,  3.79it/s, loss=0.819, v_num=0]#015Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 310/420 [01:21<00:29,  3.79it/s, loss=0.838, v_num=0]#015Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 311/420 [01:22<00:28,  3.79it/s, loss=0.838, v_num=0]#015Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 311/420 [01:22<00:28,  3.79it/s, loss=0.840, v_num=0]#015Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 312/420 [01:22<00:28,  3.79it/s, loss=0.840, v_num=0]#015Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 312/420 [01:22<00:28,  3.79it/s, loss=0.843, v_num=0]#015Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 313/420 [01:22<00:28,  3.79it/s, loss=0.843, v_num=0]#015Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 313/420 [01:22<00:28,  3.79it/s, loss=0.851, v_num=0]#015Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 314/420 [01:22<00:27,  3.79it/s, loss=0.851, v_num=0]#015Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 314/420 [01:22<00:27,  3.79it/s, loss=0.838, v_num=0]#015Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 315/420 [01:23<00:27,  3.79it/s, loss=0.838, v_num=0]#015Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 315/420 [01:23<00:27,  3.79it/s, loss=0.855, v_num=0]#015Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 316/420 [01:23<00:27,  3.79it/s, loss=0.855, v_num=0]#015Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 316/420 [01:23<00:27,  3.79it/s, loss=0.877, v_num=0]#015Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 317/420 [01:23<00:27,  3.79it/s, loss=0.877, v_num=0]#015Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 317/420 [01:23<00:27,  3.79it/s, loss=0.870, v_num=0]#015Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 318/420 [01:23<00:26,  3.79it/s, loss=0.870, v_num=0]#015Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 318/420 [01:23<00:26,  3.79it/s, loss=0.856, v_num=0]#015Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 319/420 [01:24<00:26,  3.79it/s, loss=0.856, v_num=0]#015Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 319/420 [01:24<00:26,  3.79it/s, loss=0.870, v_num=0]#015Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 320/420 [01:24<00:26,  3.79it/s, loss=0.870, v_num=0]#015Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 320/420 [01:24<00:26,  3.79it/s, loss=0.893, v_num=0]#015Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 321/420 [01:24<00:26,  3.79it/s, loss=0.893, v_num=0]#015Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 321/420 [01:24<00:26,  3.79it/s, loss=0.890, v_num=0]#015Epoch 1:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 322/420 [01:25<00:25,  3.79it/s, loss=0.890, v_num=0]#015Epoch 1:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 322/420 [01:25<00:25,  3.79it/s, loss=0.905, v_num=0]#015Epoch 1:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 323/420 [01:25<00:25,  3.79it/s, loss=0.905, v_num=0]#015Epoch 1:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 323/420 [01:25<00:25,  3.79it/s, loss=0.881, v_num=0]#015Epoch 1:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 324/420 [01:25<00:25,  3.79it/s, loss=0.881, v_num=0]#015Epoch 1:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 324/420 [01:25<00:25,  3.79it/s, loss=0.855, v_num=0]#015Epoch 1:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 325/420 [01:25<00:25,  3.79it/s, loss=0.855, v_num=0]#015Epoch 1:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 325/420 [01:25<00:25,  3.79it/s, loss=0.852, v_num=0]#015Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 326/420 [01:26<00:24,  3.79it/s, loss=0.852, v_num=0]#015Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 326/420 [01:26<00:24,  3.79it/s, loss=0.843, v_num=0]#015Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 327/420 [01:26<00:24,  3.79it/s, loss=0.843, v_num=0]#015Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 327/420 [01:26<00:24,  3.79it/s, loss=0.834, v_num=0]#015Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 328/420 [01:26<00:24,  3.79it/s, loss=0.834, v_num=0]#015Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 328/420 [01:26<00:24,  3.79it/s, loss=0.827, v_num=0]#015Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 329/420 [01:26<00:24,  3.79it/s, loss=0.827, v_num=0]#015Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 329/420 [01:26<00:24,  3.79it/s, loss=0.835, v_num=0]#015Epoch 1:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 330/420 [01:27<00:23,  3.79it/s, loss=0.835, v_num=0]#015Epoch 1:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 330/420 [01:27<00:23,  3.79it/s, loss=0.837, v_num=0]#015Epoch 1:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 331/420 [01:27<00:23,  3.79it/s, loss=0.837, v_num=0]#015Epoch 1:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 331/420 [01:27<00:23,  3.79it/s, loss=0.840, v_num=0]#015Epoch 1:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 332/420 [01:27<00:23,  3.79it/s, loss=0.840, v_num=0]#015Epoch 1:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 332/420 [01:27<00:23,  3.79it/s, loss=0.831, v_num=0]#015Epoch 1:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 333/420 [01:27<00:22,  3.79it/s, loss=0.831, v_num=0]#015Epoch 1:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 333/420 [01:27<00:22,  3.79it/s, loss=0.819, v_num=0]#015Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 334/420 [01:28<00:22,  3.79it/s, loss=0.819, v_num=0]#015Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 334/420 [01:28<00:22,  3.79it/s, loss=0.839, v_num=0]#015Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 335/420 [01:28<00:22,  3.79it/s, loss=0.839, v_num=0]#015Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 335/420 [01:28<00:22,  3.79it/s, loss=0.824, v_num=0]#015Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 336/420 [01:28<00:22,  3.79it/s, loss=0.824, v_num=0]#015Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 336/420 [01:28<00:22,  3.79it/s, loss=0.787, v_num=0]#015Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 337/420 [01:28<00:21,  3.79it/s, loss=0.787, v_num=0]#015Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 337/420 [01:28<00:21,  3.79it/s, loss=0.781, v_num=0]#015Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 338/420 [01:29<00:21,  3.79it/s, loss=0.781, v_num=0]#015Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 338/420 [01:29<00:21,  3.79it/s, loss=0.776, v_num=0]#015Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 339/420 [01:29<00:21,  3.79it/s, loss=0.776, v_num=0]#015Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 339/420 [01:29<00:21,  3.79it/s, loss=0.786, v_num=0]#015Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 340/420 [01:29<00:21,  3.79it/s, loss=0.786, v_num=0]#015Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 340/420 [01:29<00:21,  3.79it/s, loss=0.765, v_num=0]#015Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 341/420 [01:30<00:20,  3.79it/s, loss=0.765, v_num=0]#015Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 341/420 [01:30<00:20,  3.79it/s, loss=0.778, v_num=0]#015Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 342/420 [01:30<00:20,  3.79it/s, loss=0.778, v_num=0]#015Epoch 1:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 342/420 [01:30<00:20,  3.79it/s, loss=0.751, v_num=0]#015Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 343/420 [01:30<00:20,  3.79it/s, loss=0.751, v_num=0]#015Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 343/420 [01:30<00:20,  3.79it/s, loss=0.751, v_num=0]#015Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 344/420 [01:30<00:20,  3.79it/s, loss=0.751, v_num=0]#015Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 344/420 [01:30<00:20,  3.79it/s, loss=0.744, v_num=0]#015Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 345/420 [01:31<00:19,  3.79it/s, loss=0.744, v_num=0]#015Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 345/420 [01:31<00:19,  3.79it/s, loss=0.743, v_num=0]#015Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 346/420 [01:31<00:19,  3.79it/s, loss=0.743, v_num=0]#015Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 346/420 [01:31<00:19,  3.79it/s, loss=0.748, v_num=0]#015Epoch 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 347/420 [01:31<00:19,  3.79it/s, loss=0.748, v_num=0]#015Epoch 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 347/420 [01:31<00:19,  3.79it/s, loss=0.741, v_num=0]#015Epoch 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 348/420 [01:31<00:19,  3.79it/s, loss=0.741, v_num=0]#015Epoch 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 348/420 [01:31<00:19,  3.79it/s, loss=0.746, v_num=0]#015Epoch 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 349/420 [01:32<00:18,  3.79it/s, loss=0.746, v_num=0]#015Epoch 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 349/420 [01:32<00:18,  3.79it/s, loss=0.725, v_num=0]#015Epoch 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 350/420 [01:32<00:18,  3.79it/s, loss=0.725, v_num=0]#015Epoch 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 350/420 [01:32<00:18,  3.79it/s, loss=0.707, v_num=0]#015Epoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 351/420 [01:32<00:18,  3.79it/s, loss=0.707, v_num=0]#015Epoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 351/420 [01:32<00:18,  3.79it/s, loss=0.700, v_num=0]#015Epoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 352/420 [01:32<00:17,  3.79it/s, loss=0.700, v_num=0]#015Epoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 352/420 [01:32<00:17,  3.79it/s, loss=0.702, v_num=0]#015Epoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 353/420 [01:33<00:17,  3.79it/s, loss=0.702, v_num=0]#015Epoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 353/420 [01:33<00:17,  3.79it/s, loss=0.707, v_num=0]#015Epoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 354/420 [01:33<00:17,  3.79it/s, loss=0.707, v_num=0]#015Epoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 354/420 [01:33<00:17,  3.79it/s, loss=0.699, v_num=0]#015Epoch 1:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 355/420 [01:33<00:17,  3.79it/s, loss=0.699, v_num=0]#015Epoch 1:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 355/420 [01:33<00:17,  3.79it/s, loss=0.727, v_num=0]#015Epoch 1:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 356/420 [01:34<00:16,  3.79it/s, loss=0.727, v_num=0]#015Epoch 1:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 356/420 [01:34<00:16,  3.79it/s, loss=0.739, v_num=0]#015Epoch 1:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 357/420 [01:34<00:16,  3.79it/s, loss=0.739, v_num=0]#015Epoch 1:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 357/420 [01:34<00:16,  3.79it/s, loss=0.733, v_num=0]#015Epoch 1:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 358/420 [01:34<00:16,  3.79it/s, loss=0.733, v_num=0]#015Epoch 1:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 358/420 [01:34<00:16,  3.79it/s, loss=0.754, v_num=0]#015Epoch 1:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 359/420 [01:34<00:16,  3.79it/s, loss=0.754, v_num=0]#015Epoch 1:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 359/420 [01:34<00:16,  3.79it/s, loss=0.778, v_num=0]#015Epoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 360/420 [01:35<00:15,  3.79it/s, loss=0.778, v_num=0]#015Epoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 360/420 [01:35<00:15,  3.79it/s, loss=0.755, v_num=0]#015Epoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 361/420 [01:35<00:15,  3.79it/s, loss=0.755, v_num=0]#015Epoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 361/420 [01:35<00:15,  3.79it/s, loss=0.724, v_num=0]#015Epoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 362/420 [01:35<00:15,  3.79it/s, loss=0.724, v_num=0]#015Epoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 362/420 [01:35<00:15,  3.79it/s, loss=0.723, v_num=0]#015Epoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 363/420 [01:35<00:15,  3.79it/s, loss=0.723, v_num=0]#015Epoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 363/420 [01:35<00:15,  3.79it/s, loss=0.722, v_num=0]#015Epoch 1:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 364/420 [01:36<00:14,  3.79it/s, loss=0.722, v_num=0]#015Epoch 1:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 364/420 [01:36<00:14,  3.79it/s, loss=0.746, v_num=0]#015Epoch 1:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 365/420 [01:36<00:14,  3.79it/s, loss=0.746, v_num=0]#015Epoch 1:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 365/420 [01:36<00:14,  3.79it/s, loss=0.736, v_num=0]#015Epoch 1:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 366/420 [01:36<00:14,  3.79it/s, loss=0.736, v_num=0]#015Epoch 1:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 366/420 [01:36<00:14,  3.79it/s, loss=0.728, v_num=0]#015Epoch 1:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 367/420 [01:36<00:13,  3.79it/s, loss=0.728, v_num=0]#015Epoch 1:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆï¿½\u001B[0m\n",
      "\u001B[34mï¿½â–‹ | 367/420 [01:36<00:13,  3.79it/s, loss=0.734, v_num=0]#015Epoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 368/420 [01:37<00:13,  3.79it/s, loss=0.734, v_num=0]#015Epoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 368/420 [01:37<00:13,  3.79it/s, loss=0.740, v_num=0]#015Epoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 369/420 [01:37<00:13,  3.79it/s, loss=0.740, v_num=0]#015Epoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 369/420 [01:37<00:13,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 370/420 [01:37<00:13,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 370/420 [01:37<00:13,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 371/420 [01:37<00:12,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 371/420 [01:37<00:12,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 372/420 [01:38<00:12,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 372/420 [01:38<00:12,  3.79it/s, loss=0.766, v_num=0]#015Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 373/420 [01:38<00:12,  3.79it/s, loss=0.766, v_num=0]#015Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 373/420 [01:38<00:12,  3.79it/s, loss=0.772, v_num=0]#015Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 374/420 [01:38<00:12,  3.79it/s, loss=0.772, v_num=0]#015Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 374/420 [01:38<00:12,  3.79it/s, loss=0.762, v_num=0]#015Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 375/420 [01:38<00:11,  3.79it/s, loss=0.762, v_num=0]#015Epoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 375/420 [01:38<00:11,  3.79it/s, loss=0.730, v_num=0]#015Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 376/420 [01:39<00:11,  3.79it/s, loss=0.730, v_num=0]#015Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 376/420 [01:39<00:11,  3.79it/s, loss=0.716, v_num=0]#015Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 377/420 [01:39<00:11,  3.79it/s, loss=0.716, v_num=0]#015Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 377/420 [01:39<00:11,  3.79it/s, loss=0.726, v_num=0]#015Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 378/420 [01:39<00:11,  3.79it/s, loss=0.726, v_num=0]#015Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 378/420 [01:39<00:11,  3.79it/s, loss=0.720, v_num=0]#015Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 379/420 [01:39<00:10,  3.79it/s, loss=0.720, v_num=0]#015Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 379/420 [01:39<00:10,  3.79it/s, loss=0.678, v_num=0]#015Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 380/420 [01:40<00:10,  3.79it/s, loss=0.678, v_num=0]#015Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 380/420 [01:40<00:10,  3.79it/s, loss=0.698, v_num=0]#015Epoch 1:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 381/420 [01:40<00:10,  3.79it/s, loss=0.698, v_num=0]#015Epoch 1:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 381/420 [01:40<00:10,  3.79it/s, loss=0.719, v_num=0]#015Epoch 1:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 382/420 [01:40<00:10,  3.79it/s, loss=0.719, v_num=0]#015Epoch 1:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 382/420 [01:40<00:10,  3.79it/s, loss=0.730, v_num=0]#015Epoch 1:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 383/420 [01:40<00:09,  3.79it/s, loss=0.730, v_num=0]#015Epoch 1:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 383/420 [01:40<00:09,  3.79it/s, loss=0.745, v_num=0]#015Epoch 1:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 384/420 [01:41<00:09,  3.79it/s, loss=0.745, v_num=0]#015Epoch 1:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 384/420 [01:41<00:09,  3.79it/s, loss=0.726, v_num=0]#015Epoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 385/420 [01:41<00:09,  3.79it/s, loss=0.726, v_num=0]#015Epoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 385/420 [01:41<00:09,  3.79it/s, loss=0.736, v_num=0]#015Epoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 386/420 [01:41<00:08,  3.79it/s, loss=0.736, v_num=0]#015Epoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 386/420 [01:41<00:08,  3.79it/s, loss=0.752, v_num=0]#015Epoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 387/420 [01:42<00:08,  3.79it/s, loss=0.752, v_num=0]#015Epoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 387/420 [01:42<00:08,  3.79it/s, loss=0.736, v_num=0]#015Epoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 388/420 [01:42<00:08,  3.79it/s, loss=0.736, v_num=0]#015Epoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 388/420 [01:42<00:08,  3.79it/s, loss=0.769, v_num=0]#015Epoch 1:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 389/420 [01:42<00:08,  3.79it/s, loss=0.769, v_num=0]#015Epoch 1:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 389/420 [01:42<00:08,  3.79it/s, loss=0.756, v_num=0]#015Epoch 1:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 390/420 [01:42<00:07,  3.79it/s, loss=0.756, v_num=0]#015Epoch 1:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 390/420 [01:42<00:07,  3.79it/s, loss=0.758, v_num=0]#015Epoch 1:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 391/420 [01:43<00:07,  3.79it/s, loss=0.758, v_num=0]#015Epoch 1:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 391/420 [01:43<00:07,  3.79it/s, loss=0.778, v_num=0]#015Epoch 1:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 392/420 [01:43<00:07,  3.79it/s, loss=0.778, v_num=0]#015Epoch 1:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 392/420 [01:43<00:07,  3.79it/s, loss=0.775, v_num=0]#015Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 393/420 [01:43<00:07,  3.79it/s, loss=0.775, v_num=0]#015Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 393/420 [01:43<00:07,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 394/420 [01:43<00:06,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 394/420 [01:43<00:06,  3.79it/s, loss=0.764, v_num=0]#015Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 395/420 [01:44<00:06,  3.79it/s, loss=0.764, v_num=0]#015Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 395/420 [01:44<00:06,  3.79it/s, loss=0.763, v_num=0]#015Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 396/420 [01:44<00:06,  3.79it/s, loss=0.763, v_num=0]#015Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 396/420 [01:44<00:06,  3.79it/s, loss=0.773, v_num=0]#015Epoch 1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 397/420 [01:44<00:06,  3.79it/s, loss=0.773, v_num=0]#015Epoch 1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 397/420 [01:44<00:06,  3.79it/s, loss=0.761, v_num=0]#015Epoch 1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 398/420 [01:44<00:05,  3.79it/s, loss=0.761, v_num=0]#015Epoch 1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 398/420 [01:44<00:05,  3.79it/s, loss=0.765, v_num=0]#015Epoch 1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 399/420 [01:45<00:05,  3.79it/s, loss=0.765, v_num=0]#015Epoch 1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 399/420 [01:45<00:05,  3.79it/s, loss=0.763, v_num=0]#015Epoch 1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 400/420 [01:45<00:05,  3.79it/s, loss=0.763, v_num=0]#015Epoch 1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 400/420 [01:45<00:05,  3.79it/s, loss=0.770, v_num=0]#015Epoch 1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 401/420 [01:45<00:05,  3.79it/s, loss=0.770, v_num=0]#015Epoch 1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 401/420 [01:45<00:05,  3.79it/s, loss=0.752, v_num=0]#015Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 402/420 [01:46<00:04,  3.79it/s, loss=0.752, v_num=0]#015Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 402/420 [01:46<00:04,  3.79it/s, loss=0.738, v_num=0]#015Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 403/420 [01:46<00:04,  3.79it/s, loss=0.738, v_num=0]#015Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 403/420 [01:46<00:04,  3.79it/s, loss=0.724, v_num=0]#015Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 404/420 [01:46<00:04,  3.79it/s, loss=0.724, v_num=0]#015Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 404/420 [01:46<00:04,  3.79it/s, loss=0.710, v_num=0]#015Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 405/420 [01:46<00:03,  3.79it/s, loss=0.710, v_num=0]#015Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 405/420 [01:46<00:03,  3.79it/s, loss=0.729, v_num=0]#015Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 406/420 [01:47<00:03,  3.79it/s, loss=0.729, v_num=0]#015Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 406/420 [01:47<00:03,  3.79it/s, loss=0.725, v_num=0]#015Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 407/420 [01:47<00:03,  3.79it/s, loss=0.725, v_num=0]#015Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 407/420 [01:47<00:03,  3.79it/s, loss=0.722, v_num=0]#015Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 408/420 [01:47<00:03,  3.79it/s, loss=0.722, v_num=0]#015Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 408/420 [01:47<00:03,  3.79it/s, loss=0.685, v_num=0]#015Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 409/420 [01:47<00:02,  3.79it/s, loss=0.685, v_num=0]#015Epoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 409/420 [01:47<00:02,  3.79it/s, loss=0.682, v_num=0]#015Epoch 1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 410/420 [01:48<00:02,  3.79it/s, loss=0.682, v_num=0]#015Epoch 1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 410/420 [01:48<00:02,  3.79it/s, loss=0.678, v_num=0]#015Epoch 1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 411/420 [01:48<00:02,  3.79it/s, loss=0.678, v_num=0]#015Epoch 1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 411/420 [01:48<00:02,  3.79it/s, loss=0.662, v_num=0]#015Epoch 1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 412/420 [01:48<00:02,  3.79it/s, loss=0.662, v_num=0]#015Epoch 1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 412/420 [01:48<00:02,  3.79it/s, loss=0.697, v_num=0]#015Epoch 1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 413/420 [01:48<00:01,  3.79it/s, loss=0.697, v_num=0]#015Epoch 1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 413/420 [01:48<00:01,  3.79it/s, loss=0.713, v_num=0]\u001B[0m\n",
      "\u001B[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001B[0m\n",
      "\u001B[34m#015Validating:  14%|â–ˆâ–        | 1/7 [00:00<00:01,  5.44it/s]#033[A#015Epoch 1:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 414/420 [01:49<00:01,  3.80it/s, loss=0.713, v_num=0]\u001B[0m\n",
      "\u001B[34m#015Validating:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:00<00:00,  6.43it/s]#033[A#015Epoch 1:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 416/420 [01:49<00:01,  3.81it/s, loss=0.713, v_num=0]\u001B[0m\n",
      "\u001B[34m#015Validating:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:00<00:00,  7.33it/s]#033[A#015Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 418/420 [01:49<00:00,  3.82it/s, loss=0.713, v_num=0]\u001B[0m\n",
      "\u001B[34m#015Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.26it/s]#033[A#015Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 420/420 [01:49<00:00,  3.83it/s, loss=0.713, v_num=0]#015Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 420/420 [01:49<00:00,  3.83it/s, loss=0.713, v_num=0, val_loss=0.702]\u001B[0m\n",
      "\u001B[34m#015                                                         #033[A#015Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 420/420 [01:54<00:00,  3.66it/s, loss=0.713, v_num=0, val_loss=0.702]\u001B[0m\n",
      "\u001B[34msave output model path:  /opt/ml/model\u001B[0m\n",
      "\u001B[34m/opt/ml/model/cktepoch=1.ckpt\u001B[0m\n",
      "\u001B[34m/opt/ml/model/lightning_logs\u001B[0m\n",
      "\u001B[34mall checkpoints:  ['/opt/ml/model/cktepoch=1.ckpt']\u001B[0m\n",
      "\u001B[34mFinish training and saving the model!\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[34m#015Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]#015Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 792k/792k [00:00<00:00, 36.1MB/s]\u001B[0m\n",
      "\u001B[34m#015Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]#015Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.39M/1.39M [00:00<00:00, 39.3MB/s]\u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m#015Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]#015Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.20k/1.20k [00:00<00:00, 1.65MB/s]\u001B[0m\n",
      "\u001B[34m#015Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]#015Downloading:   0%|          | 3.49M/892M [00:00<00:25, 34.9MB/s]#015Downloading:   1%|          | 8.11M/892M [00:00<00:23, 37.7MB/s]#015Downloading:   1%|â–         | 12.6M/892M [00:00<00:22, 39.5MB/s]#015Downloading:   2%|â–         | 17.3M/892M [00:00<00:20, 41.7MB/s]#015Downloading:   2%|â–         | 22.1M/892M [00:00<00:20, 43.2MB/s]#015Downloading:   3%|â–Ž         | 26.8M/892M [00:00<00:19, 44.4MB/s]#015Downloading:   4%|â–Ž         | 31.6M/892M [00:00<00:18, 45.5MB/s]#015Downloading:   4%|â–         | 36.6M/892M [00:00<00:18, 46.5MB/s]#015Downloading:   5%|â–         | 41.5M/892M [00:00<00:17, 47.3MB/s]#015Downloading:   5%|â–Œ         | 46.4M/892M [00:01<00:17, 47.8MB/s]#015Downloading:   6%|â–Œ         | 51.1M/892M [00:01<00:17, 47.3MB/s]#015Downloading:   6%|â–‹         | 55.8M/892M [00:01<00:18, 44.5MB/s]#015Downloading:   7%|â–‹         | 60.2M/892M [00:01<00:19, 42.7MB/s]#015Downloading:   7%|â–‹         | 64.9M/892M [00:01<00:18, 43.9MB/s]#015Downloading:   8%|â–Š         | 69.8M/892M [00:01<00:18, 45.4MB/s]#015Downloading:   8%|â–Š         | 74.8M/892M [00:01<00:17, 46.6MB/s]#015Downloading:   9%|â–‰         | 79.8M/892M [00:01<00:17, 47.4MB/s]#015Downloading:  10%|â–‰         | 84.7M/892M [00:01<00:16, 48.1MB/s]#015Downloading:  10%|â–ˆ         | 89.7M/892M [00:01<00:16, 48.6MB/s]#015Downloading:  11%|â–ˆ         | 94.6M/892M [00:02<00:16, 47.8MB/s]#015Downloading:  11%|â–ˆ         | 99.4M/892M [00:02<00:16, 48.0MB/s]#015Downloading:  12%|â–ˆâ–        | 104M/892M [00:02<00:16, 48.1MB/s] #015Downloading:  12%|â–ˆâ–        | 109M/892M [00:02<00:16, 48.1MB/s]#015Downloading:  13%|â–ˆâ–Ž        | 114M/892M [00:02<00:16, 48.4MB/s]#015Downloading:  13%|â–ˆâ–Ž        | 119M/892M [00:02<00:15, 48.6MB/s]#015Downloading:  14%|â–ˆâ–        | 124M/892M [00:02<00:16, 47.8MB/s]#015Downloading:  14%|â–ˆâ–        | 129M/892M [00:02<00:15, 47.9MB/s]#015Downloading:  15%|â–ˆâ–        | 133M/892M [00:02<00:15, 47.9MB/s]#015Downloading:  16%|â–ˆâ–Œ        | 138M/892M [00:02<00:15, 48.3MB/s]#015Downloading:  16%|â–ˆâ–Œ        | 143M/892M [00:03<00:16, 45.9MB/s]#015Downloading:  17%|â–ˆâ–‹        | 148M/892M [00:03<00:16, 46.1MB/s]#015Downloading:  17%|â–ˆâ–‹        | 153M/892M [00:03<00:15, 47.0MB/s]#015Downloading:  18%|â–ˆâ–Š        | 158M/892M [00:03<00:15, 47.7MB/s]#015Downloading:  18%|â–ˆâ–Š        | 163M/892M [00:03<00:15, 48.2MB/s]#015Downloading:  19%|â–ˆâ–‰        | 168M/892M [00:03<00:14, 48.5MB/s]#015Downloading:  19%|â–ˆâ–‰        | 172M/892M [00:03<00:14, 48.8MB/s]#015Downloading:  20%|â–ˆâ–‰        | 177M/892M [00:03<00:14, 49.0MB/s]#015Downloading:  20%|â–ˆâ–ˆ        | 182M/892M [00:03<00:14, 49.2MB/s]#015Downloading:  21%|â–ˆâ–ˆ        | 187M/892M [00:03<00:14, 49.2MB/s]#015Downloading:  22%|â–ˆâ–ˆâ–       | 192M/892M [00:04<00:15, 45.2MB/s]#015Downloading:  22%|â–ˆâ–ˆâ–       | 197M/892M [00:04<00:16, 43.1MB/s]#015Downloading:  23%|â–ˆâ–ˆâ–Ž       | 201M/892M [00:04<00:16, 41.7MB/s]#015Downloading:  23%|â–ˆâ–ˆâ–Ž       | 205M/892M [00:04<00:16, 40.8MB/s]#015Downloading:  24%|â–ˆâ–ˆâ–Ž       | 210M/892M [00:04<00:16, 42.2MB/s]#015Downloading:  24%|â–ˆâ–ˆâ–       | 215M/892M [00:04<00:15, 44.0MB/s]#015Downloading:  25%|â–ˆâ–ˆâ–       | 220M/892M [00:04<00:14, 45.5MB/s]#015Downloading:  25%|â–ˆâ–ˆâ–Œ       | 225M/892M [00:04<00:14, 47.0MB/s]#015Downloading:  26%|â–ˆâ–ˆâ–Œ       | 231M/892M [00:04<00:13, 49.9MB/s]#015Downloading:  26%|â–ˆâ–ˆâ–‹       | 236M/892M [00:05<00:13, 49.1MB/s]#015Downloading:  27%|â–ˆâ–ˆâ–‹       | 241M/892M [00:05<00:13, 49.3MB/s]#015Downloading:  28%|â–ˆâ–ˆâ–Š       | 246M/892M [00:05<00:13, 49.4MB/s]#015Downloading:  28%|â–ˆâ–ˆâ–Š       | 251M/892M [00:05<00:12, 49.5MB/s]#015Downloading:  29%|â–ˆâ–ˆâ–Š       | 256M/892M [00:05<00:12, 49.4MB/s]#015Downloading:  29%|â–ˆâ–ˆâ–‰       | 261M/892M [00:05<00:13, 48.2MB/s]#015Downloading:  30%|â–ˆâ–ˆâ–‰       | 266M/892M [00:05<00:12, 48.7MB/s]#015Downloading:  30%|â–ˆâ–ˆâ–ˆ       | 271M/892M [00:05<00:12, 48.1MB/s]#015Downloading:  31%|â–ˆâ–ˆâ–ˆ       | 276M/892M [00:05<00:12, 48.6MB/s]#015Downloading:  31%|â–ˆâ–ˆâ–ˆâ–      | 280M/892M [00:05<00:12, 48.9MB/s]#015Downloading:  32%|â–ˆâ–ˆâ–ˆâ–      | 285M/892M [00:06<00:12, 48.9MB/s]#015Downloading:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 290M/892M [00:06<00:12, 48.8MB/s]#015Downloading:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 295M/892M [00:06<00:12, 49.0MB/s]#015Downloading:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 300M/892M [00:06<00:12, 49.1MB/s]#015Downloading:  34%|â–ˆâ–ˆâ–ˆâ–      | 305M/892M [00:06<00:11, 49.4MB/s]#015Downloading:  35%|â–ˆâ–ˆâ–ˆâ–      | 310M/892M [00:06<00:12, 47.2MB/s]#015Downloading:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 315M/892M [00:06<00:12, 47.5MB/s]#015Downloading:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 320M/892M [00:06<00:11, 48.2MB/s]#015Downloading:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 325M/892M [00:06<00:12, 46.2MB/s]#015Downloading:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 330M/892M [00:06<00:12, 46.7MB/s]#015Downloading:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 334M/892M [00:07<00:11, 47.5MB/s]#015Downloading:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 339M/892M [00:07<00:11, 48.2MB/s]#015Downloading:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 345M/892M [00:07<00:11, 48.8MB/s]#015Downloading:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 350M/892M [00:07<00:10, 49.3MB/s]#015Downloading:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 355M/892M [00:07<00:10, 49.8MB/s]#015Downloading:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 360M/892M [00:07<00:10, 49.9MB/s]#015Downloading:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 365M/892M [00:07<00:10, 49.0MB/s]#015Downloading:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 370M/892M [00:07<00:10, 49.4MB/s]#015Downloading:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 375M/892M [00:07<00:10, 49.6MB/s]#015Downloading:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 380M/892M [00:07<00:10, 49.6MB/s]#015Downloading:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 385M/892M [00:08<00:10, 49.7MB/s]#015Downloading:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 390M/892M [00:08<00:10, 50.0MB/s]#015Downloading:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 395M/892M [00:08<00:09, 50.2MB/s]#015Downloading:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 400M/892M [00:08<00:09, 50.7MB/s]#015Downloading:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 405M/892M [00:08<00:09, 50.8MB/s]#015Downloading:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 410M/892M [00:08<00:09, 51.0MB/s]#015Downloading:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 415M/892M [00:08<00:09, 51.3MB/s]#015Downloading:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 421M/892M [00:08<00:09, 51.3MB/s]#015Downloading:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 426M/892M [00:08<00:09, 51.3MB/s]#015Downloading:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 431M/892M [00:08<00:08, 51.3MB/s]#015Downloading:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 436M/892M [00:09<00:09, 49.9MB/s]#015Downloading:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 441M/892M [00:09<00:08, 50.4MB/s]#015Downloading:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 446M/892M [00:09<00:08, 50.7MB/s]#015Downloading:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 451M/892M [00:09<00:08, 51.0MB/s]#015Downloading:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 457M/892M [00:09<00:08, 51.0MB/s]#015Downloading:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 462M/892M [00:09<00:08, 51.3MB/s]#015Downloading:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 467M/892M [00:09<00:08, 51.4MB/s]#015Downloading:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 472M/892M [00:09<00:08, 51.6MB/s]#015Downloading:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 477M/892M [00:09<00:08, 51.7MB/s]#015Downloading:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 483M/892M [00:10<00:07, 51.8MB/s]#015Downloading:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 488M/892M [00:10<00:07, 51.7MB/s]#015Downloading:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 493M/892M [00:10<00:07, 51.8MB/s]#015Downloading:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 498M/892M [00:10<00:07, 52.0MB/s]#015Downloading:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 503M/892M [00:10<00:07, 52.0MB/s]#015Downloading:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 509M/892M [00:10<00:07, 51.9MB/s]#015Downloading:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 514M/892M [00:10<00:07, 51.9MB/s]#015Downloading:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 519M/892M [00:10<00:07, 51.9MB/s]#015Downloading:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 524M/892M [00:10<00:07, 51.9MB/s]#015Downloading:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 529M/892M [00:10<00:07, 51.8MB/s]#015Downloading:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 535M/892M [00:11<00:06, 51.6MB/s]#015Downloading:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 540M/892M [00:11<00:06, 50.4MB/s]#015Downloading:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 545M/892M [00:11<00:07, 49.1MB/s]#015Downloading:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 550M/892M [00:11<00:06, 49.9MB/s]#015Downloading:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 555M/892M [00:11<00:06, 50.4MB/s]#015Downloading:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 560M/892M [00:11<00:06, 50.7MB/s]#015Downloading:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 565M/892M [00:11<00:06, 51.0MB/s]#015Downloading:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 571M/892M [00:11<00:06, 51.1MB/s]#015Downloading:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 576M/892M [00:11<00:06, 51.3MB/s]#015Downloading:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 581M/892M [00:11<00:06, 51.4MB/s]#015Downloading:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 586M/892M [00:12<00:05, 51.5MB/s]#015Downloading:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 591M/892M [00:12<00:05, 51.6MB/s]#015Downloading:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 596M/892M [00:12<00:05, 51.3MB/s]#015Downloading:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 602M/892M [00:12<00:05, 51.2MB/s]#015Downloading:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 607M/892M [00:12<00:05, 51.2MB/s]#015Downloading:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 612M/892M [00:12<00:05, 51.2MB/s]#015Downloading:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 617M/892M [00:12<00:05, 51.5MB/s]#015Downloading:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 622M/892M [00:12<00:05, 50.1MB/s]#015Downloading:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 627M/892M [00:12<00:05, 50.3MB/s]#015Downloading:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 632M/892M [00:12<00:05, 50.8MB/s]#015Downloading:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 638M/892M [00:13<00:04, 51.0MB/s]#015Downloading:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 643M/892M [00:13<00:04, 50.8MB/s]#015Downloading:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 648M/892M [00:13<00:04, 51.1MB/s]#015Downloading:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 653M/892M [00:13<00:04, 51.2MB/s]#015Downloading:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 658M/892M [00:13<00:04, 51.4MB/s]#015Downloading:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 663M/892M [00:13<00:04, 51.4MB/s]#015Downloading:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 669M/892M [00:13<00:04, 51.5MB/s]#015Downloading:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 674M/892M [00:13<00:04, 51.4MB/s]#015Downloading:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 679M/892M [00:13<00:04, 51.2MB/s]#015Downloading:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 684M/892M [00:13<00:04, 51.2MB/s]#015Downloading:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 689M/892M [00:14<00:03, 51.3MB/s]#015Downloading:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 694M/892M [00:14<00:03, 51.2MB/s]#015Downloading:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 699M/892M [00:14<00:03, 51.3MB/s]#015Downloading:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 705M/892M [00:14<00:03, 51.3MB/s]#015Downloading:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 710M/892M [00:14<00:03, 51.5MB/s]#015Downloading:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 715M/892M [00:14<00:03, 51.6MB/s]#015Downloading:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 720M/892M [00:14<00:03, 51.7MB/s]#015Downloading:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 725M/892M [00:14<00:03, 51.8MB/s]#015Downloading:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 730M/892M [00:14<00:03, 51.8MB/s]#015Downloading:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 736M/892M [00:14<00:03, 51.8MB/s]#015Downloading:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 741M/892M [00:15<00:02, 51.8MB/s]#015Downloading:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 746M/892M [00:15<00:02, 51.7MB/s]#015Downloading:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 751M/892M [00:15<00:02, 51.6MB/s]#015Downloading:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 756M/892M [00:15<00:02, 51.6MB/s]#015Downloading:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 762M/892M [00:15<00:02, 51.6MB/s]#015Downloading:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 767M/892M [00:15<00:02, 51.6MB/s]#015Downloading:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 772M/892M [00:15<00:02, 51.5MB/s]#015Downloading:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 777M/892M [00:15<00:02, 51.5MB/s]#015Downloading:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 782M/892M [00:15<00:02, 51.6MB/s]#015Downloading:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 787M/892M [00:15<00:02, 51.6MB/s]#015Downloading:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 793M/892M [00:16<00:01, 51.6MB/s]#015Downloading:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 798M/892M [00:16<00:01, 51.5MB/s]#015Downloading:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 803M/892M [00:16<00:01, 51.4MB/s]#015Downloading:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 808M/892M [00:16<00:01, 51.3MB/s]#015Downloading:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 813M/892M [00:16<00:01, 50.8MB/s]#015Downloading:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 818M/892M [00:16<00:01, 50.9MB/s]#015Downloading:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 823M/892M [00:16<00:01, 51.1MB/s]#015Downloading:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 829M/892M [00:16<00:01, 51.1MB/s]#015Downloading:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 834M/892M [00:16<00:01, 51.3MB/s]#015Downloading:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 839M/892M [00:16<00:01, 51.4MB/s]#015Downloading:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 844M/892M [00:17<00:00, 50.9MB/s]#015Downloading:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 849M/892M [00:17<00:00, 50.9MB/s]#015Downloading:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 854M/892M [00:17<00:00, 51.0MB/s]#015Downloading:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 859M/892M [00:17<00:00, 51.1MB/s]#015Downloading:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 865M/892M [00:17<00:00, 51.2MB/s]#015Downloading:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 870M/892M [00:17<00:00, 51.3MB/s]#015Downloading:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 875M/892M [00:17<00:00, 51.3MB/s]#015Downloading:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 880M/892M [00:17<00:00, 51.3MB/s]#015Downloading:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 885M/892M [00:17<00:00, 51.3MB/s]#015Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 890M/892M [00:17<00:00, 51.4MB/s]#015Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 892M/892M [00:17<00:00, 49.6MB/s]\u001B[0m\n",
      "\u001B[34mGPU available: True, used: True\u001B[0m\n",
      "\u001B[34mTPU available: False, using: 0 TPU cores\u001B[0m\n",
      "\u001B[34mCUDA_VISIBLE_DEVICES: [0]\n",
      "  | Name  | Type                       | Params\u001B[0m\n",
      "\u001B[34m-----------------------------------------------------\u001B[0m\n",
      "\u001B[34m0 | model | T5ForConditionalGeneration | 222 M \u001B[0m\n",
      "\u001B[34mINFO:__main__:***** Validation results *****\u001B[0m\n",
      "\u001B[34mINFO:__main__:avg_val_loss = tensor(0.7019, device='cuda:0')\u001B[0m\n",
      "\u001B[34mINFO:__main__:loss = tensor(0.8472, device='cuda:0')\u001B[0m\n",
      "\u001B[34mINFO:__main__:train_loss = tensor(0.8472, device='cuda:0')\u001B[0m\n",
      "\u001B[34mINFO:__main__:val_loss = tensor(0.7019, device='cuda:0')\u001B[0m\n",
      "\u001B[34m2022-08-17 03:07:45,837 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001B[0m\n",
      "\n",
      "2022-08-17 03:08:12 Uploading - Uploading generated training model\n",
      "2022-08-17 03:16:54 Completed - Training job completed\n",
      "ProfilerReport-1660705115: NoIssuesFound\n",
      "Training seconds: 974\n",
      "Billable seconds: 974\n"
     ]
    }
   ],
   "source": [
    "response = estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9e951b",
   "metadata": {},
   "source": [
    "# deploy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e16f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "instance_type = 'ml.m5.4xlarge'\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75d0fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model = estimator.model_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f357cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data=s3_model, \n",
    "                             role=role,\n",
    "                             entry_point='inference.py', \n",
    "                             source_dir='./', \n",
    "                             framework_version='1.7.1', \n",
    "                             py_version='py36'\n",
    "                ) # TODO set model_server_workers=1 to avoid torchhub bug\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type=instance_type, initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da3506eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': '(pretty new to pickleball, scene); (finally decided to try out some different paddles, purchase_behavior)'}\n"
     ]
    }
   ],
   "source": [
    "from boto3.session import Session\n",
    "import json\n",
    "\n",
    "body = {\"inputs\": \"I am pretty new to pickleball and finally decided to try out some different paddles.\"}\n",
    "\n",
    "session = Session()\n",
    "runtime = session.client(\"runtime.sagemaker\")\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(body),\n",
    ")\n",
    "result = json.loads(response[\"Body\"].read())\n",
    "print (result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f02d1c49",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.98 ms, sys: 11.8 ms, total: 13.8 ms\n",
      "Wall time: 1.18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'result': '(pretty new to pickleball, scene); (finally decided to try out some different paddles, purchase_behavior)'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()\n",
    "\n",
    "body = {\"inputs\": \"I am pretty new to pickleball and finally decided to try out some different paddles.\"}\n",
    "\n",
    "predictor.predict(body,initial_args={\"ContentType\":\"application/json\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b90a291",
   "metadata": {},
   "source": [
    "# batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b36dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict.jsonl uploaded to s3://sagemaker-us-east-1-726335585155/batch_transform/input/predict.jsonl\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sagemaker.s3 import S3Uploader,s3_path_join\n",
    "\n",
    "# get the s3 bucket\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "#prepare data\n",
    "dataset_csv_file = 'predict_0811.csv'\n",
    "dataset_jsonl_file = \"predict.jsonl\"\n",
    "\n",
    "\n",
    "i = 0\n",
    "with open(dataset_csv_file, \"r+\") as infile, open(dataset_jsonl_file, \"w+\") as outfile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    for row in reader:\n",
    "        if i <5:\n",
    "            json.dump({\"inputs\":row[\"0\"]}, outfile)\n",
    "            outfile.write('\\n')\n",
    "        i = i+1\n",
    "                \n",
    "# uploads a given file to S3.\n",
    "input_s3_path = s3_path_join(\"s3://\",sagemaker_session_bucket,\"batch_transform/input\")\n",
    "output_s3_path = s3_path_join(\"s3://\",sagemaker_session_bucket,\"batch_transform/output\")\n",
    "s3_file_uri = S3Uploader.upload(dataset_jsonl_file,input_s3_path)\n",
    "\n",
    "print(f\"{dataset_jsonl_file} uploaded to {s3_file_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a4702e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transformer to run a batch job\n",
    "batch_job = pytorch_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g4dn.xlarge',\n",
    "    output_path=output_s3_path,\n",
    "    strategy='SingleRecord'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92580b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................................\u001B[34mCollecting transformers==4.6.0\n",
      "  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\u001B[0m\n",
      "\u001B[34mCollecting datasets==1.11.0\n",
      "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\u001B[0m\n",
      "\u001B[34mCollecting sentencepiece==0.1.91\n",
      "  Downloading sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\u001B[0m\n",
      "\u001B[34mCollecting pytorch_lightning==0.8.1\n",
      "  Downloading pytorch_lightning-0.8.1-py3-none-any.whl (293 kB)\u001B[0m\n",
      "\u001B[34mCollecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mCollecting editdistance\n",
      "  Downloading editdistance-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (284 kB)\u001B[0m\n",
      "\u001B[34mCollecting filelock\n",
      "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001B[0m\n",
      "\u001B[34mCollecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.19.1)\u001B[0m\n",
      "\u001B[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.25-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\u001B[0m\n",
      "\u001B[34mCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (20.4)\u001B[0m\n",
      "\u001B[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (4.62.3)\u001B[0m\n",
      "\u001B[34mCollecting huggingface-hub==0.0.8\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2.22.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (0.8)\u001B[0m\n",
      "\u001B[34mCollecting fsspec>=2021.05.0\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\u001B[0m\n",
      "\u001B[34mCollecting pyarrow!=4.0.0,>=1.0.0\n",
      "  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (0.25.0)\u001B[0m\n",
      "\u001B[34mCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py36-none-any.whl (106 kB)\u001B[0m\n",
      "\u001B[34mCollecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\u001B[0m\n",
      "\u001B[34mCollecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.18.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (1.7.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (5.4.1)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard>=1.14\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.25.11)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2021.5.30)\u001B[0m\n",
      "\u001B[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.10.0-py2.py3-none-any.whl (167 kB)\u001B[0m\n",
      "\u001B[34mCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001B[0m\n",
      "\u001B[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (49.6.0.post20210108)\u001B[0m\n",
      "\u001B[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001B[0m\n",
      "\u001B[34mCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001B[0m\n",
      "\u001B[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.37.0)\u001B[0m\n",
      "\u001B[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch>=1.3->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (4.0.0)\u001B[0m\n",
      "\u001B[34mCollecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.16.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.6)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (2.8.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (2021.3)\u001B[0m\n",
      "\u001B[34mCollecting click\n",
      "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (4.7.2)\u001B[0m\n",
      "\u001B[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001B[0m\n",
      "\u001B[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001B[0m\n",
      "\u001B[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.4.8)\u001B[0m\n",
      "\u001B[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001B[0m\n",
      "\u001B[34mBuilding wheels for collected packages: jieba, sacremoses\n",
      "  Building wheel for jieba (setup.py): started\u001B[0m\n",
      "\u001B[34m  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314476 sha256=a3a14471b331b7be42001fa26669b175c5ec2175fd50255c09610ca8487f69a6\n",
      "  Stored in directory: /root/.cache/pip/wheels/17/a7/8b/a7e03881534e78558920ac68aaeca05180c0e2c3d11c4fce3b\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895253 sha256=608c93633d2b3489c9711e524e9e25f58444430327c6b0b301192ee989532e50\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001B[0m\n",
      "\u001B[34mSuccessfully built jieba sacremoses\u001B[0m\n",
      "\u001B[34mInstalling collected packages: zipp, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, regex, protobuf, markdown, grpcio, google-auth-oauthlib, filelock, dill, click, absl-py, xxhash, tokenizers, tensorboard, sacremoses, pyarrow, multiprocess, huggingface-hub, fsspec, transformers, sentencepiece, pytorch-lightning, jieba, editdistance, datasets\u001B[0m\n",
      "\u001B[34mSuccessfully installed absl-py-1.2.0 cachetools-4.2.4 click-8.0.4 datasets-1.11.0 dill-0.3.4 editdistance-0.6.0 filelock-3.4.1 fsspec-2022.1.0 google-auth-2.10.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 huggingface-hub-0.0.8 importlib-metadata-4.8.3 jieba-0.42.1 markdown-3.3.7 multiprocess-0.70.12.2 oauthlib-3.2.0 protobuf-3.19.4 pyarrow-6.0.1 pyasn1-modules-0.2.8 pytorch-lightning-0.8.1 regex-2022.7.25 requests-oauthlib-1.3.1 sacremoses-0.0.53 sentencepiece-0.1.91 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.10.3 transformers-4.6.0 werkzeug-2.0.3 xxhash-3.0.0 zipp-3.6.0\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[34m2022-08-17 03:44:28,984 [INFO ] main org.pytorch.serve.ModelServer - \u001B[0m\n",
      "\u001B[34mTorchserve version: 0.3.1\u001B[0m\n",
      "\u001B[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001B[0m\n",
      "\u001B[34mCurrent directory: /\u001B[0m\n",
      "\u001B[34mTemp directory: /home/model-server/tmp\u001B[0m\n",
      "\u001B[34mNumber of GPUs: 1\u001B[0m\n",
      "\u001B[34mNumber of CPUs: 4\u001B[0m\n",
      "\u001B[34mMax heap size: 2996 M\u001B[0m\n",
      "\u001B[34mPython executable: /opt/conda/bin/python3.6\u001B[0m\n",
      "\u001B[34mConfig file: /etc/sagemaker-ts.properties\u001B[0m\n",
      "\u001B[34mInference address: http://0.0.0.0:8080\u001B[0m\n",
      "\u001B[34mManagement address: http://0.0.0.0:8080\u001B[0m\n",
      "\u001B[34mMetrics address: http://127.0.0.1:8082\u001B[0m\n",
      "\u001B[34mModel Store: /.sagemaker/ts/models\u001B[0m\n",
      "\u001B[34mInitial Models: model.mar\u001B[0m\n",
      "\u001B[34mLog dir: /logs\u001B[0m\n",
      "\u001B[34mMetrics dir: /logs\u001B[0m\n",
      "\u001B[34mNetty threads: 0\u001B[0m\n",
      "\u001B[34mNetty client threads: 0\u001B[0m\n",
      "\u001B[34mDefault workers per model: 1\u001B[0m\n",
      "\u001B[34mBlacklist Regex: N/A\u001B[0m\n",
      "\u001B[34mMaximum Response Size: 6553500\u001B[0m\n",
      "\u001B[34mMaximum Request Size: 6553500\u001B[0m\n",
      "\u001B[34mPrefer direct buffer: false\u001B[0m\n",
      "\u001B[34mAllowed Urls: [file://.*|http(s)?://.*]\u001B[0m\n",
      "\u001B[34mCustom python dependency for model allowed: false\u001B[0m\n",
      "\u001B[34mMetrics report format: prometheus\u001B[0m\n",
      "\u001B[34mEnable metrics API: true\u001B[0m\n",
      "\u001B[34m2022-08-17 03:44:29,018 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,631 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag eef13c56710a4bdbb5f6f62c208f9728\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,642 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,658 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,771 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,772 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,773 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,792 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,793 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]94\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,793 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,793 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,800 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,828 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,941 [INFO ] pool-1-thread-2 ACCESS_LOG - /169.254.255.130:60784 \"GET /ping HTTP/1.1\" 200 36\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,967 [INFO ] pool-1-thread-2 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,006 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:60798 \"GET /execution-parameters HTTP/1.1\" 404 2\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,007 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34mModel server started.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,282 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,282 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:79.51536178588867|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,282 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:29.051639556884766|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,283 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:26.8|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,283 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14285.8984375|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,283 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1127.70703125|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,283 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:9.3|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,035 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: transformers==4.6.0 in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 1)) (4.6.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,035 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: datasets==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 2)) (1.11.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,036 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: sentencepiece==0.1.91 in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 3)) (0.1.91)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,037 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pytorch_lightning==0.8.1 in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 4)) (0.8.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,037 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: jieba in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 5)) (0.42.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,038 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: editdistance in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 6)) (0.6.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,199 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (0.8)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,200 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: huggingface-hub==0.0.8 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (0.0.8)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,200 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (0.0.53)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,201 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (4.8.3)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,202 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (0.10.3)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,202 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.19.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,202 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2.22.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,203 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (3.4.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,204 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (4.62.3)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,204 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (20.4)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,204 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2022.7.25)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,311 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (0.25.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,311 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: xxhash in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (3.0.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,312 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dill in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (0.3.4)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,312 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: multiprocess in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (0.70.12.2)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,313 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (2022.1.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,314 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (6.0.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,321 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (5.4.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,321 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tensorboard>=1.14 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (2.10.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,322 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (1.7.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,323 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.18.2)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,380 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.4)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,381 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.25.11)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,382 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2.8)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,383 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2021.5.30)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,395 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.37.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,396 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (2.10.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,397 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (1.2.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,398 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (3.19.4)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,399 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.6.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,400 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (3.3.7)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,401 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.4.6)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,401 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (1.8.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,402 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (1.47.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,403 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (49.6.0.post20210108)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,404 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (2.0.3)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,430 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch>=1.3->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (4.0.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,472 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (3.6.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,479 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.6)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,480 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.16.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,488 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (2021.3)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,488 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (2.8.2)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,492 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.0.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,492 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (8.0.4)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,517 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.2.8)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,518 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (4.2.4)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,519 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (4.7.2)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,525 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (1.3.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,611 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.4.8)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,618 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (3.2.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,825 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[32m2022-08-17T03:45:25.054:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,551 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /home/model-server/tmp/models/eef13c56710a4bdbb5f6f62c208f9728\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,551 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - <<<run train!!\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,551 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/cktepoch=1.ckpt']\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,551 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /home/model-server/tmp/models/eef13c56710a4bdbb5f6f62c208f9728\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,551 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - <<<run train!!\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,551 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/cktepoch=1.ckpt']\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,551 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,553 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,601 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.20k/1.20k [00:00<00:00, 1.04MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,601 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,701 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,806 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 4.87M/892M [00:00<00:18, 48.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,950 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 10.3M/892M [00:00<00:17, 50.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,061 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   2%|â–         | 15.3M/892M [00:00<00:20, 42.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,173 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   2%|â–         | 19.7M/892M [00:00<00:21, 41.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,273 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   3%|â–Ž         | 23.8M/892M [00:00<00:21, 39.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,551 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,553 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,601 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.20k/1.20k [00:00<00:00, 1.04MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,601 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,701 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,806 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 4.87M/892M [00:00<00:18, 48.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,950 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 10.3M/892M [00:00<00:17, 50.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,061 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   2%|â–         | 15.3M/892M [00:00<00:20, 42.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,173 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   2%|â–         | 19.7M/892M [00:00<00:21, 41.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,273 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   3%|â–Ž         | 23.8M/892M [00:00<00:21, 39.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,373 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   3%|â–Ž         | 29.0M/892M [00:00<00:19, 43.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,485 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   4%|â–         | 34.3M/892M [00:00<00:18, 46.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,585 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   4%|â–         | 39.0M/892M [00:00<00:18, 44.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,713 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   5%|â–         | 43.6M/892M [00:00<00:18, 45.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,867 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   5%|â–Œ         | 48.1M/892M [00:01<00:20, 41.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,967 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   6%|â–Œ         | 52.4M/892M [00:01<00:23, 36.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,067 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   6%|â–‹         | 57.5M/892M [00:01<00:20, 40.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,168 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   7%|â–‹         | 62.7M/892M [00:01<00:19, 43.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,373 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   3%|â–Ž         | 29.0M/892M [00:00<00:19, 43.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,485 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   4%|â–         | 34.3M/892M [00:00<00:18, 46.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,585 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   4%|â–         | 39.0M/892M [00:00<00:18, 44.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,713 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   5%|â–         | 43.6M/892M [00:00<00:18, 45.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,867 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   5%|â–Œ         | 48.1M/892M [00:01<00:20, 41.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,967 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   6%|â–Œ         | 52.4M/892M [00:01<00:23, 36.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,067 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   6%|â–‹         | 57.5M/892M [00:01<00:20, 40.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,168 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   7%|â–‹         | 62.7M/892M [00:01<00:19, 43.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,435 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   8%|â–Š         | 68.3M/892M [00:01<00:17, 46.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,535 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   8%|â–Š         | 73.1M/892M [00:01<00:25, 31.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,635 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   9%|â–Š         | 77.2M/892M [00:01<00:24, 33.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,735 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   9%|â–‰         | 82.4M/892M [00:02<00:21, 38.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,836 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  10%|â–‰         | 87.4M/892M [00:02<00:19, 41.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,938 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  10%|â–ˆ         | 92.1M/892M [00:02<00:18, 42.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,088 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  11%|â–ˆ         | 96.7M/892M [00:02<00:18, 43.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,191 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  11%|â–ˆâ–        | 101M/892M [00:02<00:20, 38.6MB/s] \u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,292 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  12%|â–ˆâ–        | 106M/892M [00:02<00:19, 39.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,435 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   8%|â–Š         | 68.3M/892M [00:01<00:17, 46.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,535 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   8%|â–Š         | 73.1M/892M [00:01<00:25, 31.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,635 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   9%|â–Š         | 77.2M/892M [00:01<00:24, 33.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,735 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   9%|â–‰         | 82.4M/892M [00:02<00:21, 38.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,836 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  10%|â–‰         | 87.4M/892M [00:02<00:19, 41.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,938 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  10%|â–ˆ         | 92.1M/892M [00:02<00:18, 42.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,088 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  11%|â–ˆ         | 96.7M/892M [00:02<00:18, 43.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,191 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  11%|â–ˆâ–        | 101M/892M [00:02<00:20, 38.6MB/s] \u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,292 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  12%|â–ˆâ–        | 106M/892M [00:02<00:19, 39.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,392 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  12%|â–ˆâ–        | 110M/892M [00:02<00:19, 39.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,502 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  13%|â–ˆâ–Ž        | 115M/892M [00:02<00:17, 43.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,603 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  13%|â–ˆâ–Ž        | 119M/892M [00:02<00:18, 42.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,704 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  14%|â–ˆâ–        | 124M/892M [00:03<00:17, 42.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,804 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  14%|â–ˆâ–        | 128M/892M [00:03<00:17, 43.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,964 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  15%|â–ˆâ–        | 133M/892M [00:03<00:16, 45.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,085 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  15%|â–ˆâ–Œ        | 138M/892M [00:03<00:19, 38.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,210 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  16%|â–ˆâ–Œ        | 142M/892M [00:03<00:20, 37.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,392 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  12%|â–ˆâ–        | 110M/892M [00:02<00:19, 39.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,502 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  13%|â–ˆâ–Ž        | 115M/892M [00:02<00:17, 43.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,603 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  13%|â–ˆâ–Ž        | 119M/892M [00:02<00:18, 42.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,704 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  14%|â–ˆâ–        | 124M/892M [00:03<00:17, 42.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,804 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  14%|â–ˆâ–        | 128M/892M [00:03<00:17, 43.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,964 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  15%|â–ˆâ–        | 133M/892M [00:03<00:16, 45.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,085 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  15%|â–ˆâ–Œ        | 138M/892M [00:03<00:19, 38.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,210 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  16%|â–ˆâ–Œ        | 142M/892M [00:03<00:20, 37.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,311 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  16%|â–ˆâ–‹        | 146M/892M [00:03<00:21, 35.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,506 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  17%|â–ˆâ–‹        | 150M/892M [00:03<00:19, 37.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,607 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  17%|â–ˆâ–‹        | 154M/892M [00:03<00:24, 30.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,707 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  18%|â–ˆâ–Š        | 158M/892M [00:04<00:23, 31.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,807 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  18%|â–ˆâ–Š        | 162M/892M [00:04<00:21, 33.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,967 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|â–ˆâ–Š        | 166M/892M [00:04<00:20, 35.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:39,067 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|â–ˆâ–‰        | 169M/892M [00:04<00:23, 30.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:39,177 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|â–ˆâ–‰        | 173M/892M [00:04<00:22, 31.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:39,277 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  20%|â–ˆâ–‰        | 177M/892M [00:04<00:22, 32.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,311 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  16%|â–ˆâ–‹        | 146M/892M [00:03<00:21, 35.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,506 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  17%|â–ˆâ–‹        | 150M/892M [00:03<00:19, 37.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,607 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  17%|â–ˆâ–‹        | 154M/892M [00:03<00:24, 30.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,707 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  18%|â–ˆâ–Š        | 158M/892M [00:04<00:23, 31.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,807 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  18%|â–ˆâ–Š        | 162M/892M [00:04<00:21, 33.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,967 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|â–ˆâ–Š        | 166M/892M [00:04<00:20, 35.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:39,067 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|â–ˆâ–‰        | 169M/892M [00:04<00:23, 30.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:39,177 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|â–ˆâ–‰        | 173M/892M [00:04<00:22, 31.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:39,277 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  20%|â–ˆâ–‰        | 177M/892M [00:04<00:22, 32.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:40,409 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  24%|â–ˆâ–ˆâ–       | 214M/892M [00:05<00:19, 34.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:40,509 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  24%|â–ˆâ–ˆâ–       | 218M/892M [00:05<00:21, 31.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:40,618 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  25%|â–ˆâ–ˆâ–       | 222M/892M [00:05<00:19, 33.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:40,727 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  25%|â–ˆâ–ˆâ–Œ       | 225M/892M [00:06<00:20, 33.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:40,831 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|â–ˆâ–ˆâ–Œ       | 228M/892M [00:06<00:20, 32.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:40,981 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|â–ˆâ–ˆâ–Œ       | 232M/892M [00:06<00:19, 34.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,082 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|â–ˆâ–ˆâ–‹       | 236M/892M [00:06<00:21, 30.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,182 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  27%|â–ˆâ–ˆâ–‹       | 239M/892M [00:06<00:21, 30.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:40,409 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  24%|â–ˆâ–ˆâ–       | 214M/892M [00:05<00:19, 34.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:40,509 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  24%|â–ˆâ–ˆâ–       | 218M/892M [00:05<00:21, 31.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:40,618 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  25%|â–ˆâ–ˆâ–       | 222M/892M [00:05<00:19, 33.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:40,727 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  25%|â–ˆâ–ˆâ–Œ       | 225M/892M [00:06<00:20, 33.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:40,831 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|â–ˆâ–ˆâ–Œ       | 228M/892M [00:06<00:20, 32.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:40,981 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|â–ˆâ–ˆâ–Œ       | 232M/892M [00:06<00:19, 34.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,082 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|â–ˆâ–ˆâ–‹       | 236M/892M [00:06<00:21, 30.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,182 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  27%|â–ˆâ–ˆâ–‹       | 239M/892M [00:06<00:21, 30.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,357 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  27%|â–ˆâ–ˆâ–‹       | 243M/892M [00:06<00:20, 31.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,514 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|â–ˆâ–ˆâ–Š       | 247M/892M [00:06<00:22, 28.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,615 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|â–ˆâ–ˆâ–Š       | 250M/892M [00:06<00:25, 24.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,724 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|â–ˆâ–ˆâ–Š       | 253M/892M [00:07<00:23, 27.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,827 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|â–ˆâ–ˆâ–Š       | 256M/892M [00:07<00:23, 27.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,927 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|â–ˆâ–ˆâ–‰       | 259M/892M [00:07<00:23, 27.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,027 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|â–ˆâ–ˆâ–‰       | 263M/892M [00:07<00:20, 30.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,149 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  30%|â–ˆâ–ˆâ–ˆ       | 268M/892M [00:07<00:17, 36.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,257 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  30%|â–ˆâ–ˆâ–ˆ       | 272M/892M [00:07<00:17, 34.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,357 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  27%|â–ˆâ–ˆâ–‹       | 243M/892M [00:06<00:20, 31.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,514 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|â–ˆâ–ˆâ–Š       | 247M/892M [00:06<00:22, 28.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,615 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|â–ˆâ–ˆâ–Š       | 250M/892M [00:06<00:25, 24.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,724 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|â–ˆâ–ˆâ–Š       | 253M/892M [00:07<00:23, 27.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,827 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|â–ˆâ–ˆâ–Š       | 256M/892M [00:07<00:23, 27.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,927 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|â–ˆâ–ˆâ–‰       | 259M/892M [00:07<00:23, 27.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,027 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|â–ˆâ–ˆâ–‰       | 263M/892M [00:07<00:20, 30.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,149 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  30%|â–ˆâ–ˆâ–ˆ       | 268M/892M [00:07<00:17, 36.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,257 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  30%|â–ˆâ–ˆâ–ˆ       | 272M/892M [00:07<00:17, 34.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,357 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  31%|â–ˆâ–ˆâ–ˆ       | 275M/892M [00:07<00:18, 34.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,457 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  31%|â–ˆâ–ˆâ–ˆâ–      | 281M/892M [00:07<00:15, 39.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,573 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  32%|â–ˆâ–ˆâ–ˆâ–      | 287M/892M [00:07<00:12, 48.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,673 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 292M/892M [00:07<00:12, 46.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,773 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 298M/892M [00:08<00:12, 48.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,889 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  34%|â–ˆâ–ˆâ–ˆâ–      | 303M/892M [00:08<00:11, 49.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,994 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  35%|â–ˆâ–ˆâ–ˆâ–      | 308M/892M [00:08<00:12, 47.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,113 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 313M/892M [00:08<00:12, 46.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,223 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 317M/892M [00:08<00:12, 44.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,357 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  31%|â–ˆâ–ˆâ–ˆ       | 275M/892M [00:07<00:18, 34.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,457 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  31%|â–ˆâ–ˆâ–ˆâ–      | 281M/892M [00:07<00:15, 39.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,573 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  32%|â–ˆâ–ˆâ–ˆâ–      | 287M/892M [00:07<00:12, 48.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,673 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 292M/892M [00:07<00:12, 46.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,773 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 298M/892M [00:08<00:12, 48.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,889 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  34%|â–ˆâ–ˆâ–ˆâ–      | 303M/892M [00:08<00:11, 49.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,994 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  35%|â–ˆâ–ˆâ–ˆâ–      | 308M/892M [00:08<00:12, 47.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,113 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 313M/892M [00:08<00:12, 46.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,223 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 317M/892M [00:08<00:12, 44.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,323 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 322M/892M [00:08<00:13, 43.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,423 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 326M/892M [00:08<00:12, 44.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,524 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 331M/892M [00:08<00:12, 44.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,651 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 337M/892M [00:08<00:11, 48.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,751 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 342M/892M [00:09<00:12, 45.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,867 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 348M/892M [00:09<00:10, 49.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,995 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 353M/892M [00:09<00:11, 47.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,116 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 358M/892M [00:09<00:11, 44.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,269 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 362M/892M [00:09<00:12, 42.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,323 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 322M/892M [00:08<00:13, 43.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,423 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 326M/892M [00:08<00:12, 44.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,524 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 331M/892M [00:08<00:12, 44.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,651 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 337M/892M [00:08<00:11, 48.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,751 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 342M/892M [00:09<00:12, 45.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,867 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 348M/892M [00:09<00:10, 49.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,995 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 353M/892M [00:09<00:11, 47.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,116 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 358M/892M [00:09<00:11, 44.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,269 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 362M/892M [00:09<00:12, 42.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,370 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 367M/892M [00:09<00:14, 37.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,572 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 373M/892M [00:09<00:11, 43.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,672 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 378M/892M [00:09<00:14, 35.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,782 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 382M/892M [00:10<00:14, 35.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,900 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 385M/892M [00:10<00:14, 35.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,001 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 389M/892M [00:10<00:14, 34.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,101 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 393M/892M [00:10<00:14, 35.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,201 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 397M/892M [00:10<00:13, 37.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,370 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 367M/892M [00:09<00:14, 37.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,572 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 373M/892M [00:09<00:11, 43.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,672 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 378M/892M [00:09<00:14, 35.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,782 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 382M/892M [00:10<00:14, 35.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,900 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 385M/892M [00:10<00:14, 35.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,001 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 389M/892M [00:10<00:14, 34.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,101 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 393M/892M [00:10<00:14, 35.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,201 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 397M/892M [00:10<00:13, 37.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,370 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 401M/892M [00:10<00:12, 38.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,471 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 405M/892M [00:10<00:15, 32.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,571 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 410M/892M [00:10<00:13, 35.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,731 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 415M/892M [00:10<00:12, 39.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,851 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 419M/892M [00:11<00:13, 34.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,951 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 423M/892M [00:11<00:14, 33.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,076 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 427M/892M [00:11<00:12, 35.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,176 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 431M/892M [00:11<00:12, 36.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,287 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 438M/892M [00:11<00:10, 43.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,370 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 401M/892M [00:10<00:12, 38.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,471 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 405M/892M [00:10<00:15, 32.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,571 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 410M/892M [00:10<00:13, 35.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,731 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 415M/892M [00:10<00:12, 39.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,851 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 419M/892M [00:11<00:13, 34.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,951 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 423M/892M [00:11<00:14, 33.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,076 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 427M/892M [00:11<00:12, 35.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,176 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 431M/892M [00:11<00:12, 36.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,287 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 438M/892M [00:11<00:10, 43.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,506 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 443M/892M [00:11<00:10, 42.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,681 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 447M/892M [00:11<00:13, 32.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,781 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 451M/892M [00:12<00:15, 28.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,886 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 455M/892M [00:12<00:14, 31.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,987 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 458M/892M [00:12<00:13, 32.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,087 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 462M/892M [00:12<00:12, 33.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,188 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 467M/892M [00:12<00:11, 37.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,288 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 472M/892M [00:12<00:10, 40.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,506 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 443M/892M [00:11<00:10, 42.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,681 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 447M/892M [00:11<00:13, 32.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,781 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 451M/892M [00:12<00:15, 28.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,886 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 455M/892M [00:12<00:14, 31.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,987 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 458M/892M [00:12<00:13, 32.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,087 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 462M/892M [00:12<00:12, 33.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,188 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 467M/892M [00:12<00:11, 37.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,288 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 472M/892M [00:12<00:10, 40.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,388 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 477M/892M [00:12<00:09, 42.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,488 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 481M/892M [00:12<00:09, 44.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,588 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 486M/892M [00:12<00:08, 45.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,694 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 493M/892M [00:12<00:07, 50.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,797 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 498M/892M [00:13<00:07, 49.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,933 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 503M/892M [00:13<00:07, 49.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,033 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 508M/892M [00:13<00:08, 44.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,144 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 513M/892M [00:13<00:08, 47.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,388 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 477M/892M [00:12<00:09, 42.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,488 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 481M/892M [00:12<00:09, 44.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,588 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 486M/892M [00:12<00:08, 45.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,694 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 493M/892M [00:12<00:07, 50.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,797 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 498M/892M [00:13<00:07, 49.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,933 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 503M/892M [00:13<00:07, 49.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,033 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 508M/892M [00:13<00:08, 44.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,144 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 513M/892M [00:13<00:08, 47.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,271 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 518M/892M [00:13<00:08, 45.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,271 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 518M/892M [00:13<00:08, 45.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,392 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 523M/892M [00:13<00:08, 43.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,492 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 527M/892M [00:13<00:08, 40.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,592 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 532M/892M [00:13<00:08, 42.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,764 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 537M/892M [00:13<00:07, 44.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,900 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 541M/892M [00:14<00:09, 37.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,001 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 545M/892M [00:14<00:10, 34.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,106 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 549M/892M [00:14<00:09, 34.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,214 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 554M/892M [00:14<00:08, 38.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,392 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 523M/892M [00:13<00:08, 43.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,492 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 527M/892M [00:13<00:08, 40.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,592 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 532M/892M [00:13<00:08, 42.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,764 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 537M/892M [00:13<00:07, 44.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,900 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 541M/892M [00:14<00:09, 37.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,001 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 545M/892M [00:14<00:10, 34.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,106 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 549M/892M [00:14<00:09, 34.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,214 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 554M/892M [00:14<00:08, 38.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,314 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 558M/892M [00:14<00:08, 38.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,414 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 563M/892M [00:14<00:07, 41.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,515 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 567M/892M [00:14<00:07, 42.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,714 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 573M/892M [00:14<00:07, 45.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,314 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 558M/892M [00:14<00:08, 38.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,414 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 563M/892M [00:14<00:07, 41.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,515 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 567M/892M [00:14<00:07, 42.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,714 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 573M/892M [00:14<00:07, 45.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,884 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 577M/892M [00:15<00:08, 35.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,983 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 581M/892M [00:15<00:10, 30.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,083 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 585M/892M [00:15<00:09, 32.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,183 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 589M/892M [00:15<00:08, 34.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,286 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 594M/892M [00:15<00:07, 39.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,884 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 577M/892M [00:15<00:08, 35.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,983 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 581M/892M [00:15<00:10, 30.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,083 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 585M/892M [00:15<00:09, 32.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,183 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 589M/892M [00:15<00:08, 34.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,286 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 594M/892M [00:15<00:07, 39.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,387 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 601M/892M [00:15<00:06, 46.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,524 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 606M/892M [00:15<00:06, 47.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,624 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 611M/892M [00:15<00:06, 43.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,724 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 616M/892M [00:16<00:06, 44.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,824 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 620M/892M [00:16<00:05, 45.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,931 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 625M/892M [00:16<00:05, 46.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,032 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 630M/892M [00:16<00:05, 45.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,160 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 635M/892M [00:16<00:05, 47.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,387 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 601M/892M [00:15<00:06, 46.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,524 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 606M/892M [00:15<00:06, 47.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,624 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 611M/892M [00:15<00:06, 43.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,724 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 616M/892M [00:16<00:06, 44.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,824 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 620M/892M [00:16<00:05, 45.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,931 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 625M/892M [00:16<00:05, 46.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,032 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 630M/892M [00:16<00:05, 45.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,160 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 635M/892M [00:16<00:05, 47.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,321 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 640M/892M [00:16<00:05, 44.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,321 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 640M/892M [00:16<00:05, 44.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,422 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 644M/892M [00:16<00:06, 37.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,522 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 649M/892M [00:16<00:06, 38.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,626 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 653M/892M [00:16<00:05, 40.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,742 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 657M/892M [00:17<00:05, 41.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,856 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 662M/892M [00:17<00:05, 39.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,026 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 666M/892M [00:17<00:05, 38.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,126 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 670M/892M [00:17<00:06, 32.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,226 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 676M/892M [00:17<00:05, 39.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,422 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 644M/892M [00:16<00:06, 37.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,522 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 649M/892M [00:16<00:06, 38.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,626 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 653M/892M [00:16<00:05, 40.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,742 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 657M/892M [00:17<00:05, 41.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,856 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 662M/892M [00:17<00:05, 39.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,026 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 666M/892M [00:17<00:05, 38.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,126 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 670M/892M [00:17<00:06, 32.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,226 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 676M/892M [00:17<00:05, 39.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,326 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 680M/892M [00:17<00:05, 41.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,428 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 686M/892M [00:17<00:04, 46.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,528 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 691M/892M [00:17<00:04, 46.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,628 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 697M/892M [00:17<00:03, 49.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,781 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 702M/892M [00:18<00:03, 50.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,902 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 707M/892M [00:18<00:04, 44.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,002 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 712M/892M [00:18<00:04, 42.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,102 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 718M/892M [00:18<00:03, 46.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,213 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 723M/892M [00:18<00:03, 47.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,326 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 680M/892M [00:17<00:05, 41.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,428 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 686M/892M [00:17<00:04, 46.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,528 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 691M/892M [00:17<00:04, 46.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,628 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 697M/892M [00:17<00:03, 49.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,781 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 702M/892M [00:18<00:03, 50.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,902 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 707M/892M [00:18<00:04, 44.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,002 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 712M/892M [00:18<00:04, 42.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,102 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 718M/892M [00:18<00:03, 46.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,213 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 723M/892M [00:18<00:03, 47.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,326 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 728M/892M [00:18<00:03, 46.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,426 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 733M/892M [00:18<00:03, 45.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,526 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 739M/892M [00:18<00:02, 51.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,629 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 746M/892M [00:18<00:02, 55.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,757 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 752M/892M [00:19<00:02, 55.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,857 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 757M/892M [00:19<00:02, 51.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,959 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 763M/892M [00:19<00:02, 53.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:54,157 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 769M/892M [00:19<00:02, 53.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:54,257 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 774M/892M [00:19<00:02, 42.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,326 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 728M/892M [00:18<00:03, 46.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,426 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 733M/892M [00:18<00:03, 45.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,526 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 739M/892M [00:18<00:02, 51.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,629 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 746M/892M [00:18<00:02, 55.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,757 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 752M/892M [00:19<00:02, 55.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,857 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 757M/892M [00:19<00:02, 51.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,959 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 763M/892M [00:19<00:02, 53.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:54,157 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 769M/892M [00:19<00:02, 53.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:54,257 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 774M/892M [00:19<00:02, 42.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:55,362 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 830M/892M [00:20<00:01, 50.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:55,481 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 835M/892M [00:20<00:01, 48.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:55,581 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 840M/892M [00:20<00:01, 46.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:55,698 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 845M/892M [00:20<00:01, 46.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:55,797 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 849M/892M [00:21<00:00, 44.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:55,911 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 856M/892M [00:21<00:00, 50.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:56,012 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 861M/892M [00:21<00:00, 48.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:56,112 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 867M/892M [00:21<00:00, 51.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:56,256 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 872M/892M [00:21<00:00, 51.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:55,362 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 830M/892M [00:20<00:01, 50.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:55,481 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 835M/892M [00:20<00:01, 48.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:55,581 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 840M/892M [00:20<00:01, 46.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:55,698 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 845M/892M [00:20<00:01, 46.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:55,797 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 849M/892M [00:21<00:00, 44.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:55,911 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 856M/892M [00:21<00:00, 50.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:56,012 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 861M/892M [00:21<00:00, 48.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:56,112 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 867M/892M [00:21<00:00, 51.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:56,256 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 872M/892M [00:21<00:00, 51.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:56,361 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 877M/892M [00:21<00:00, 45.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:56,461 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 882M/892M [00:21<00:00, 47.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:56,538 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 887M/892M [00:21<00:00, 47.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:56,361 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 877M/892M [00:21<00:00, 45.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:56,461 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 882M/892M [00:21<00:00, 47.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:56,538 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 887M/892M [00:21<00:00, 47.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:59,605 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 892M/892M [00:21<00:00, 40.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:59,606 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:59,618 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:59,763 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 792k/792k [00:00<00:00, 63.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:59,763 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:59,783 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:00,264 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 35361\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:00,265 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:35615|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707960\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:00,265 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:72|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:59,605 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 892M/892M [00:21<00:00, 40.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:59,606 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:59,618 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:59,763 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 792k/792k [00:00<00:00, 63.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:59,763 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:59,783 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:00,264 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 35361\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:00,265 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:35615|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707960\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:00,265 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:72|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:01,436 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1171\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:01,436 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1171\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:01,436 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1169.13|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:98591bdd-3b5e-4e88-adc1-483f26497e82,timestamp:1660707961\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 36267\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:35087|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:01,436 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1169.13|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:98591bdd-3b5e-4e88-adc1-483f26497e82,timestamp:1660707961\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 36267\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:35087|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1937\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1935.92|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:d284310b-e7e6-43fb-9833-443ad6a93996,timestamp:1660707963\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 1938\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:03,428 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:03,428 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1937\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1935.92|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:d284310b-e7e6-43fb-9833-443ad6a93996,timestamp:1660707963\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 1938\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:03,428 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:03,428 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\n",
      "\u001B[34m2022-08-17 03:46:08,321 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:3398.71|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:42c7ef98-007c-4ebd-89f9-99adcd6c7b53,timestamp:1660707968\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:08,321 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3400\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:08,321 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 3400\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:08,322 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:08,322 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:08,322 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:08,321 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:3398.71|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:42c7ef98-007c-4ebd-89f9-99adcd6c7b53,timestamp:1660707968\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:08,321 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3400\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:08,321 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 3400\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:08,322 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:08,322 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:08,322 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:09,409 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1083\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:09,409 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1083\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:09,409 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1082.82|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:6a9de375-6c75-4741-afe2-d563035262b9,timestamp:1660707969\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 1085\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:09,409 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1082.82|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:6a9de375-6c75-4741-afe2-d563035262b9,timestamp:1660707969\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 1085\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# starts batch transform job and uses S3 data as input\n",
    "batch_job.transform(\n",
    "    data=input_s3_path,\n",
    "    content_type='application/json',    \n",
    "    split_type='Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20ec5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.s3 import S3Downloader\n",
    "from ast import literal_eval\n",
    "# creating s3 uri for result file -> input file + .out\n",
    "output_file = f\"{dataset_jsonl_file}.out\"\n",
    "output_path = s3_path_join(\"s3://sagemaker-us-east-1-726335585155/batch_transform/output\",output_file)\n",
    "\n",
    "local_path = \"output\"  # Where to save the output locally\n",
    "\n",
    "S3Downloader.download(output_path,local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d7ae96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting jsonlines\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jsonlines) (21.2.0)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-3.1.0\n",
      "\u001B[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe820515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": \"(VERY extra large, size)\"}{\"result\": \"(I really liked the look of this dress, style); (It just wasn\\u2019t cute on me, feelings)\"}{\"result\": \"(Beautifully made, quality); (made in China, scene)\"}{\"result\": \"(I went up a size, size); (run a little small, size); (great quality, quality); (lined, fabric); (light weight, fabric); (very happy, feelings); (highly recommend, purchase_behavior)\"}{\"result\": \"(Not true to size, size)\"}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the output\n",
    "\n",
    "import os\n",
    "import jsonlines\n",
    "import json\n",
    "from ast import literal_eval\n",
    "\n",
    "output_file = f\"{dataset_jsonl_file}.out\"\n",
    "\n",
    "batch_transform_result = []\n",
    "\n",
    "path = os.path.join(local_path, output_file)\n",
    "with open(path, \"r\") as f:\n",
    "    for line in f:\n",
    "        print (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5a4de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}